<?xml version="1.0" encoding="utf-8"?>
<!-- Created by Leo: http://leoeditor.com/leo_toc.html -->
<leo_file xmlns:leo="http://leoeditor.com/namespaces/leo-python-editor/1.1" >
<leo_header file_format="2"/>
<globals/>
<preferences/>
<find_panel_settings/>
<vnodes>
<v t="ekr.20160207181637.1"><vh>Startup</vh>
<v t="ekr.20160207181648.1"><vh>@settings</vh>
<v t="ekr.20180706073424.1"><vh>@bool run-pyflakes-on-write = False</vh></v>
<v t="ekr.20160207182535.1"><vh>@bool preload-find-pattern = False</vh></v>
</v>
<v t="ekr.20160207105647.1"><vh>Scripts</vh>
<v t="ekr.20210804025215.1"><vh>@button backup</vh></v>
<v t="ekr.20160206095102.1"><vh>@@@button write-unit-tests</vh>
<v t="ekr.20160206095102.2"><vh>&lt;&lt; docstring &gt;&gt; (write-unit-tests)</vh></v>
<v t="ekr.20160206101802.3"><vh>class TestWriter</vh>
<v t="ekr.20160206101802.4"><vh>&lt;&lt; define file_template &gt;&gt;</vh></v>
<v t="ekr.20160206101802.5"><vh>&lt;&lt; define test_template &gt;&gt;</vh></v>
<v t="ekr.20160206101802.6"><vh> ctor</vh></v>
<v t="ekr.20160206101802.7"><vh>clean</vh></v>
<v t="ekr.20160206101802.8"><vh>get_body</vh></v>
<v t="ekr.20160206101802.9"><vh>run</vh></v>
<v t="ekr.20160206103417.1"><vh>plural</vh></v>
<v t="ekr.20160206101802.10"><vh>test</vh></v>
<v t="ekr.20160206101802.11"><vh>write_file</vh></v>
</v>
</v>
<v t="ekr.20160207105710.1"><vh>@@@button check-leading-lines</vh></v>
<v t="ekr.20210804153200.1"><vh>script convert-at-test</vh></v>
</v>
<v t="ekr.20160126153016.3"><vh>Unused</vh>
<v t="ekr.20160206104033.1"><vh>@@test run all msf unit tests</vh></v>
<v t="ekr.20160208162138.1"><vh>from st.Call (failed experiment)</vh></v>
<v t="ekr.20160202064553.1"><vh>sf.match</vh></v>
<v t="ekr.20160202061118.1"><vh>sf.visit (attempts all matches on all nodes)</vh></v>
<v t="ekr.20160214103050.1"><vh>recent type-reduction stuff</vh>
<v t="ekr.20160214171726.1"><vh>unused code from is_known_type</vh></v>
<v t="ekr.20160214172029.1"><vh>unused code from rt.reduce_unknowns</vh></v>
<v t="ekr.20160214154338.1"><vh>recent, obsolete reduce_types code</vh></v>
</v>
<v t="ekr.20160214043351.1"><vh>rt.make_optional</vh></v>
</v>
</v>
<v t="ekr.20180706073205.1"><vh>Recent Code</vh>
<v t="ekr.20180706071540.1"><vh>#2: Fails to generate valid stubs for empty classes</vh>
<v t="ekr.20180901050914.1"><vh>Changed...</vh>
<v t="ekr.20160318141204.186"><vh>st.visit_ClassDef</vh></v>
<v t="ekr.20160318141204.20"><vh>f.ClassDef (make_stub_files)</vh></v>
</v>
</v>
<v t="ekr.20180831102536.1"><vh>#3: Creates duplicate annotations for function arguments that are already annotated</vh>
<v t="ekr.20160318141204.188"><vh>st.format_arguments &amp; helper</vh>
<v t="ekr.20160318141204.189"><vh>st.munge_arg</vh></v>
</v>
</v>
<v t="ekr.20200402143651.1"><vh>----- errors</vh>
<v t="ekr.20160318141204.171"><vh>st.add_stub</vh></v>
<v t="ekr.20160318141204.110"><vh>pattern.match_balanced</vh></v>
</v>
<v t="ekr.20210803131252.1"><vh>=== #13: None</vh>
<v t="ekr.20160318141204.30"><vh>f.Operands</vh>
<v t="ekr.20160318141204.31"><vh>f.arguments (make_stub_files)</vh></v>
<v t="ekr.20160318141204.32"><vh>f.arg (Python3 only) (make_stub_files)</vh></v>
<v t="ekr.20160318141204.33"><vh>f.Attribute</vh></v>
<v t="ekr.20160318141204.34"><vh>f.Bytes</vh></v>
<v t="ekr.20160318141204.35"><vh>f.Call &amp; f.keyword</vh>
<v t="ekr.20160318141204.36"><vh>f.keyword</vh></v>
</v>
<v t="ekr.20160318141204.37"><vh>f.comprehension</vh></v>
<v t="ekr.20160318141204.38"><vh>f.Dict</vh></v>
<v t="ekr.20160318141204.39"><vh>f.Ellipsis</vh></v>
<v t="ekr.20160318141204.40"><vh>f.ExtSlice</vh></v>
<v t="ekr.20160318141204.41"><vh>f.Index</vh></v>
<v t="ekr.20160318141204.42"><vh>f.List</vh></v>
<v t="ekr.20160318141204.43"><vh>f.ListComp</vh></v>
<v t="ekr.20160318141204.44"><vh>f.Name &amp; NameConstant</vh></v>
<v t="ekr.20160318141204.45"><vh>f.Num</vh></v>
<v t="ekr.20160318141204.46"><vh>f.Repr</vh></v>
<v t="ekr.20160318141204.47"><vh>f.Slice</vh></v>
<v t="ekr.20160318141204.48"><vh>f.Str</vh></v>
<v t="ekr.20160318141204.49"><vh>f.Subscript</vh></v>
<v t="ekr.20160318141204.50"><vh>f.Tuple</vh></v>
</v>
<v t="ekr.20160318141204.147"><vh>class StubFormatter (AstFormatter)</vh>
<v t="ekr.20160318141204.148"><vh>sf.ctor</vh></v>
<v t="ekr.20160318141204.149"><vh>sf.match_all</vh></v>
<v t="ekr.20160318141204.150"><vh>sf.visit</vh></v>
<v t="ekr.20160318141204.151"><vh>sf.trace_visitor</vh></v>
<v t="ekr.20160318141204.152"><vh>sf.Operands</vh>
<v t="ekr.20160318141204.153"><vh>sf.Attribute</vh></v>
<v t="ekr.20160318141204.154"><vh>sf.Constants: Bytes, Num, Str</vh></v>
<v t="ekr.20160318141204.155"><vh>sf.Dict</vh></v>
<v t="ekr.20160318141204.156"><vh>sf.List</vh></v>
<v t="ekr.20160318141204.157"><vh>sf.Name</vh></v>
<v t="ekr.20160318141204.158"><vh>sf.Tuple</vh></v>
</v>
<v t="ekr.20160318141204.159"><vh>sf.Operators</vh>
<v t="ekr.20160318141204.160"><vh>sf.BinOp</vh></v>
<v t="ekr.20160318141204.161"><vh>sf.BoolOp</vh></v>
<v t="ekr.20160318141204.162"><vh>sf.Call &amp; sf.keyword</vh>
<v t="ekr.20160318141204.163"><vh>sf.keyword</vh></v>
</v>
<v t="ekr.20160318141204.164"><vh>sf.Compare</vh></v>
<v t="ekr.20160318141204.165"><vh>sf.IfExp</vh></v>
<v t="ekr.20160318141204.166"><vh>sf.Subscript</vh></v>
<v t="ekr.20160318141204.167"><vh>sf.UnaryOp</vh></v>
</v>
<v t="ekr.20160318141204.168"><vh>sf.Return</vh></v>
</v>
<v t="ekr.20160318141204.14"><vh> class AstFormatter</vh>
<v t="ekr.20160318141204.15"><vh> f.Entries</vh>
<v t="ekr.20160318141204.17"><vh>f.format</vh></v>
<v t="ekr.20160318141204.18"><vh>f.visit</vh></v>
</v>
<v t="ekr.20160318141204.19"><vh>f.Contexts</vh>
<v t="ekr.20160318141204.20"></v>
<v t="ekr.20160318141204.21"><vh>f.FunctionDef (make_stub_files)</vh></v>
<v t="ekr.20160318141204.22"><vh>f.Interactive</vh></v>
<v t="ekr.20160318141204.23"><vh>f.Module</vh></v>
<v t="ekr.20160318141204.24"><vh>f.Lambda</vh></v>
</v>
<v t="ekr.20160318141204.25"><vh>f.Expressions</vh>
<v t="ekr.20160318141204.26"><vh>f.Expr</vh></v>
<v t="ekr.20160318141204.27"><vh>f.Expression</vh></v>
<v t="ekr.20160318141204.28"><vh>f.GeneratorExp</vh></v>
<v t="ekr.20160318141204.29"><vh>f.ctx nodes</vh></v>
</v>
<v t="ekr.20160318141204.30"></v>
<v t="ekr.20160318141204.51"><vh>f.Operators</vh>
<v t="ekr.20160318141204.52"><vh>f.BinOp</vh></v>
<v t="ekr.20160318141204.53"><vh>f.BoolOp</vh></v>
<v t="ekr.20160318141204.54"><vh>f.Compare</vh></v>
<v t="ekr.20160318141204.55"><vh>f.UnaryOp</vh></v>
<v t="ekr.20160318141204.56"><vh>f.ifExp (ternary operator)</vh></v>
</v>
<v t="ekr.20160318141204.57"><vh>f.Statements</vh>
<v t="ekr.20160318141204.58"><vh>f.Assert</vh></v>
<v t="ekr.20160318141204.59"><vh>f.Assign</vh></v>
<v t="ekr.20160318141204.60"><vh>f.AugAssign</vh></v>
<v t="ekr.20160318141204.61"><vh>f.Break</vh></v>
<v t="ekr.20160318141204.62"><vh>f.Continue</vh></v>
<v t="ekr.20160318141204.63"><vh>f.Delete</vh></v>
<v t="ekr.20160318141204.64"><vh>f.ExceptHandler</vh></v>
<v t="ekr.20160318141204.65"><vh>f.Exec</vh></v>
<v t="ekr.20160318141204.66"><vh>f.For</vh></v>
<v t="ekr.20160318141204.67"><vh>f.Global</vh></v>
<v t="ekr.20160318141204.68"><vh>f.If</vh></v>
<v t="ekr.20160318141204.69"><vh>f.Import &amp; helper</vh>
<v t="ekr.20160318141204.70"><vh>f.get_import_names</vh></v>
</v>
<v t="ekr.20160318141204.71"><vh>f.ImportFrom</vh></v>
<v t="ekr.20160318141204.72"><vh>f.Nonlocal (Python 3)</vh></v>
<v t="ekr.20160318141204.73"><vh>f.Pass</vh></v>
<v t="ekr.20160318141204.74"><vh>f.Print</vh></v>
<v t="ekr.20160318141204.75"><vh>f.Raise</vh></v>
<v t="ekr.20160318141204.76"><vh>f.Return</vh></v>
<v t="ekr.20160318141204.77"><vh>f.Starred (Python 3)</vh></v>
<v t="ekr.20160318141204.79"><vh>f.Try (Python 3)</vh></v>
<v t="ekr.20160318141204.80"><vh>f.TryExcept</vh></v>
<v t="ekr.20160318141204.81"><vh>f.TryFinally</vh></v>
<v t="ekr.20160318141204.82"><vh>f.While</vh></v>
<v t="ekr.20160318141204.83"><vh>f.With (make_stub_files)</vh></v>
<v t="ekr.20160318141204.84"><vh>f.Yield</vh></v>
<v t="ekr.20160318141204.85"><vh>f.YieldFrom (Python 3)</vh></v>
</v>
<v t="ekr.20160318141204.86"><vh>f.Utils</vh>
<v t="ekr.20160318141204.87"><vh>f.kind</vh></v>
<v t="ekr.20160318141204.88"><vh>f.indent</vh></v>
<v t="ekr.20160318141204.89"><vh>f.op_name</vh></v>
</v>
</v>
<v t="ekr.20160318141204.21"></v>
</v>
</v>
<v t="ekr.20160128104714.1"><vh>Files</vh>
<v t="ekr.20160128225533.1"><vh>@clean .gitignore</vh></v>
<v t="ekr.20160128102557.1"><vh>@clean example.cfg</vh></v>
<v t="ekr.20160126153220.1"><vh>@clean make_stub_files.cfg</vh></v>
<v t="ekr.20160128104639.1"><vh>@clean msf.cfg</vh></v>
<v t="ekr.20160330201030.1"><vh>@clean PKG-INFO.TXT</vh></v>
<v t="ekr.20160211110739.1"><vh>@clean README.md</vh>
<v t="ekr.20160211110807.1"><vh>Overview</vh></v>
<v t="ekr.20160211113019.1"><vh>Quick start</vh></v>
<v t="ekr.20160211110810.1"><vh>Command-line arguments</vh></v>
<v t="ekr.20160211110810.2"><vh>The configuration file</vh>
<v t="ekr.20160211111807.1"><vh>Patterns</vh></v>
<v t="ekr.20160211111823.1"><vh>[Global]</vh></v>
<v t="ekr.20160211111839.1"><vh>[Def Name Patterns]</vh></v>
<v t="ekr.20160211111901.1"><vh>[General Patterns]</vh></v>
</v>
<v t="ekr.20160211110810.3"><vh>Why this script is important</vh></v>
<v t="ekr.20160211110811.1"><vh>Summary</vh></v>
</v>
<v t="ekr.20160206165507.1"><vh>@clean test.cfg</vh></v>
<v t="ekr.20160207101607.1"><vh>@clean theory.md</vh></v>
</v>
<v t="ekr.20160318141204.1" descendentVnodeUnknownAttributes="7d71005805000000302e362e3571017d71025808000000616e6e6f7461746571037d710473732e"><vh>@file make_stub_files.py</vh></v>
<v t="ekr.20210803131439.1"><vh>=== #10: unit tests</vh>
<v t="ekr.20210804104214.1"><vh>--- no longer used</vh>
<v t="ekr.20160318141204.130"><vh>msf.run_all_unit_tests</vh></v>
<v t="ekr.20160318141204.129"><vh>msf.run</vh></v>
<v t="ekr.20160207051429.1"><vh>@@@test merge_types</vh></v>
<v t="ekr.20160318141204.5"><vh>merge_types (not used)</vh></v>
</v>
<v t="ekr.20210804020706.1"><vh>@button coverage</vh></v>
<v t="ekr.20210804060105.1"><vh>@button unitttest</vh></v>
<v t="ekr.20210804021331.1"><vh>@button msf</vh></v>
<v t="ekr.20210804070157.1"><vh>--- command-line</vh>
<v t="ekr.20160318141204.131"><vh>msf.scan_command_line</vh></v>
<v t="ekr.20160318141204.132"><vh>msf.scan_options &amp; helpers</vh>
<v t="ekr.20160318141204.133"><vh>msf.make_op_name_dict</vh></v>
<v t="ekr.20160318141204.134"><vh>msf.create_parser</vh></v>
<v t="ekr.20160318141204.135"><vh>msf.find_pattern_ops</vh></v>
<v t="ekr.20160318141204.136"><vh>msf.get_config_string</vh></v>
<v t="ekr.20160318141204.137"><vh>msf.init_parser</vh></v>
<v t="ekr.20160318141204.138"><vh>msf.is_section_name</vh></v>
<v t="ekr.20160318141204.139"><vh>msf.make_patterns_dict</vh></v>
<v t="ekr.20160318141204.140"><vh>msf.scan_patterns</vh></v>
</v>
</v>
<v t="ekr.20160318141204.125"><vh>class Controller</vh>
<v t="ekr.20160318141204.126"><vh>msf.ctor</vh></v>
<v t="ekr.20160318141204.127"><vh>msf.finalize</vh></v>
<v t="ekr.20160318141204.128"><vh>msf.make_stub_file</vh></v>
<v t="ekr.20160318141204.131"></v>
<v t="ekr.20160318141204.132"></v>
</v>
<v t="ekr.20210803060400.1"><vh>--- testing</vh>
<v t="ekr.20160630100214.1"><vh>@@@clean test.py</vh></v>
<v t="ekr.20160128154715.1"><vh>@@@clean test/test_msf.py</vh>
<v t="ekr.20160128190252.1"><vh>setUp</vh></v>
<v t="ekr.20160128190112.1"><vh>test_pattern_class</vh></v>
<v t="ekr.20160128190224.1"><vh>test_is_known_type</vh></v>
</v>
<v t="ekr.20160206165656.1"><vh>@@@clean test/test.py</vh></v>
<v t="ekr.20160318141204.195"><vh>class TestClass (not used)</vh>
<v t="ekr.20160318141204.196"><vh>parse_group (Guido)</vh></v>
<v t="ekr.20160318141204.197"><vh>return_all</vh></v>
<v t="ekr.20160318141204.198"><vh>return_array</vh></v>
<v t="ekr.20160318141204.199"><vh>return_list</vh></v>
<v t="ekr.20160318141204.200"><vh>return_two_lists (fails)</vh></v>
</v>
</v>
</v>
<v t="ekr.20210803055042.1"><vh>class TestMakeStubFiles(unittest.TestCase)</vh>
<v t="ekr.20180901040718.1"><vh>test_bug2_empty (rewritten)</vh></v>
<v t="ekr.20180901044640.1"><vh>test_bug2_non_empty (revise)</vh></v>
<v t="ekr.20180901051603.1"><vh>test_bug3 (FAILS) (revise)</vh></v>
<v t="ekr.20210804103146.1"><vh>test_pattern_class</vh></v>
<v t="ekr.20210804105256.1"><vh>test_reduce_numbers</vh></v>
<v t="ekr.20210804111613.1"><vh>test_reduce_types</vh></v>
<v t="ekr.20210804111803.1"><vh>test_split_types</vh></v>
<v t="ekr.20210804111915.1"><vh>test_st_find</vh></v>
<v t="ekr.20210804112211.1"><vh>test_st_flatten_stubs</vh></v>
<v t="ekr.20210804112405.1"><vh>test_st_merge_stubs</vh>
<v t="ekr.20210804112405.3"><vh>&lt;&lt; old_stubs &gt;&gt;</vh></v>
<v t="ekr.20210804112405.4"><vh>&lt;&lt; new_stubs &gt;&gt;</vh></v>
</v>
<v t="ekr.20210804112556.1"><vh>test_stub_class</vh></v>
<v t="ekr.20160207115947.1"><vh>test_truncate</vh>
<v t="ekr.20160207115604.1"><vh>truncate</vh></v>
</v>
</v>
<v t="ekr.20160318141204.128"></v>
<v t="ekr.20160318141204.11"><vh>main</vh></v>
<v t="ekr.20160318141204.169"><vh>class StubTraverser (ast.NodeVisitor)</vh>
<v t="ekr.20160318141204.170"><vh>st.ctor</vh></v>
<v t="ekr.20160318141204.171"></v>
<v t="ekr.20160318141204.172"><vh>st.indent &amp; out</vh></v>
<v t="ekr.20160318141204.173"><vh>st.run (main line) &amp; helpers</vh>
<v t="ekr.20160318141204.174"><vh>st.output_stubs</vh></v>
<v t="ekr.20160318141204.175"><vh>st.output_time_stamp</vh></v>
<v t="ekr.20160318141204.176"><vh>st.update &amp; helpers</vh>
<v t="ekr.20160318141204.177"><vh>st.get_stub_file</vh></v>
<v t="ekr.20160318141204.178"><vh>st.parse_stub_file</vh></v>
<v t="ekr.20160318141204.179"><vh>st.merge_stubs &amp; helpers</vh>
<v t="ekr.20160318141204.180"><vh>st.check_delete</vh></v>
<v t="ekr.20160318141204.181"><vh>st.flatten_stubs</vh></v>
<v t="ekr.20160318141204.182"><vh>st.find_parent_stub</vh></v>
<v t="ekr.20160318141204.183"><vh>st.find_stub</vh></v>
<v t="ekr.20160318141204.184"><vh>st.sort_stubs_by_hierarchy</vh></v>
</v>
<v t="ekr.20160318141204.185"><vh>st.trace_stubs</vh></v>
</v>
</v>
<v t="ekr.20160318141204.186"></v>
<v t="ekr.20160318141204.187"><vh>st.visit_FunctionDef &amp; helpers</vh>
<v t="ekr.20160318141204.188"></v>
<v t="ekr.20160318141204.190"><vh>st.format_returns &amp; helpers</vh>
<v t="ekr.20160318141204.191"><vh>st.format_return_expressions</vh></v>
<v t="ekr.20160318141204.192"><vh>st.get_def_name</vh></v>
<v t="ekr.20160318141204.193"><vh>st.remove_recursive_calls</vh></v>
</v>
</v>
<v t="ekr.20160318141204.194"><vh>st.visit_Return</vh></v>
</v>
<v t="ekr.20160318141204.173"></v>
<v t="ekr.20160318141204.174"></v>
<v t="ekr.20210804161223.1"><vh>--- revise tests</vh>
<v t="ekr.20180901040718.1"></v>
<v t="ekr.20180901044640.1"></v>
<v t="ekr.20180901051603.1"></v>
</v>
<v t="ekr.20210804170546.1"><vh>git diff HEAD </vh>
<v t="ekr.20210804170546.2"><vh>make_stub_files.leo</vh>
<v t="ekr.20210804170546.7"><vh>Added</vh>
<v t="ekr.20160318141204.11"></v>
<v t="ekr.20160318141204.169"></v>
<v t="ekr.20160318141204.170"></v>
<v t="ekr.20160318141204.172"></v>
<v t="ekr.20160318141204.173"></v>
<v t="ekr.20160318141204.174"></v>
<v t="ekr.20160318141204.175"></v>
<v t="ekr.20160318141204.176"></v>
<v t="ekr.20160318141204.177"></v>
<v t="ekr.20160318141204.178"></v>
<v t="ekr.20160318141204.179"></v>
<v t="ekr.20160318141204.180"></v>
<v t="ekr.20160318141204.181"></v>
<v t="ekr.20160318141204.182"></v>
<v t="ekr.20160318141204.183"></v>
<v t="ekr.20160318141204.184"></v>
<v t="ekr.20160318141204.185"></v>
<v t="ekr.20160318141204.187"></v>
<v t="ekr.20160318141204.190"></v>
<v t="ekr.20160318141204.191"></v>
<v t="ekr.20160318141204.192"></v>
<v t="ekr.20160318141204.193"></v>
<v t="ekr.20160318141204.194"></v>
<v t="ekr.20210804161223.1"></v>
</v>
<v t="ekr.20210804170546.8"><vh>Deleted</vh>
<v t="ekr.20210804170546.9"><vh> &lt;&lt; imports &gt;&gt; (make_stub_files.py)</vh></v>
</v>
<v t="ekr.20210804170546.10"><vh>Changed</vh>
<v t="ekr.20210804170546.11"><vh>=== #10: unit tests</vh>
<v t="ekr.20210804170546.12"><vh>Old:=== #10: unit tests</vh></v>
<v t="ekr.20210803131439.1"></v>
</v>
<v t="ekr.20210804170546.13"><vh>@button unitttest</vh>
<v t="ekr.20210804170546.14"><vh>Old:@button unitttest</vh></v>
<v t="ekr.20210804060105.1"></v>
</v>
<v t="ekr.20210804170546.15"><vh>test_bug2_empty (rewritten)</vh>
<v t="ekr.20210804170546.16"><vh>Old:test_bug2_empty (revise)</vh></v>
<v t="ekr.20180901040718.1"></v>
</v>
<v t="ekr.20210804170546.17"><vh>test_bug2_non_empty (revise)</vh>
<v t="ekr.20210804170546.18"><vh>Old:test_bug2_non_empty (revise)</vh></v>
<v t="ekr.20180901044640.1"></v>
</v>
</v>
</v>
<v t="ekr.20210804170546.19"><vh>make_stub_files.py</vh>
<v t="ekr.20210804170546.24"><vh>Changed</vh>
<v t="ekr.20210804170546.25"><vh> &lt;&lt; imports &gt;&gt; (make_stub_files.py)</vh>
<v t="ekr.20210804170546.26"><vh>Old: &lt;&lt; imports &gt;&gt; (make_stub_files.py)</vh></v>
<v t="ekr.20160318141204.2"><vh> &lt;&lt; imports &gt;&gt; (make_stub_files.py)</vh></v>
</v>
<v t="ekr.20210804170546.27"><vh>test_bug2_empty (rewritten)</vh>
<v t="ekr.20210804170546.28"><vh>Old:test_bug2_empty (revise)</vh></v>
<v t="ekr.20180901040718.1"></v>
</v>
<v t="ekr.20210804170546.29"><vh>test_bug2_non_empty (revise)</vh>
<v t="ekr.20210804170546.30"><vh>Old:test_bug2_non_empty (revise)</vh></v>
<v t="ekr.20180901044640.1"></v>
</v>
</v>
</v>
</v>
</vnodes>
<tnodes>
<t tx="ekr.20160126153016.3"></t>
<t tx="ekr.20160126153220.1">@language config

# A configuration file to make stubs for make_stub_files.py itself.

[Global]

files: make_stub_files.py
    
output_directory: .
    
prefix_lines:
    from typing import Any, Dict, Optional, Sequence, Tuple, Union
        # At present, I don't understand how to tell mypy about ast.Node
        # import ast
        # Node = ast.Node
    Node = Any

[Def Name Patterns]

# The returns are inherent in the design of make_stub_files.py:
AstFormatter.do_*: str
StubFormatter.do_*: str
StubTraverser.do_*: str

# Test of regex pattern.
.*__hash__$: int

# Pattern.all_matches: Sequence
# Pattern.full_balanced_match: Optional[int]
# Pattern.match_balanced: int
# Pattern.match_entire_string: bool
# StandAloneMakeStubFile.scan_types: Dict[str, str]

# StubTraverser.format_returns: str
# StubTraverser.match_return_patterns: Tuple[bool,str]
# StubTraverser.match_return_pattern: Optional[str]
# StubTraverser.match_balanced: int

[General Patterns]

# Declarations of names...
NotImplemented: bool
a: str
aList: List[Any]
comments: str
controller: StandAloneMakeStubFile
find_s: str
fn: str
found: str
general_patterns: List[Pattern]
group: str
i1: int
i2: int
i: int
j1: int
j2: int
j: int
n1: int
n2: int
n: int
name: str
ndots: int
node: Node
parser: optparse.OptionParser
patterns: List
repl_s: str
s: str
s1: str
s2: str
# s[1-2]?$: str
strict: bool
trace: bool
# New known functions
endswith(*): bool 

# Known functions...
os.path.basename(*): str
os.sep.join(*): str
sep.join(*): str
self.__eq__(*): bool
self.__ne__(*): bool
self.__gt__(*): bool
self.__lt__(*): bool
all(*): bool
any(*): bool

int(*): int
hash(*): int
len(*): int
repr(*): str
sorted(*): str
str%(*): str
str.join(*): str
r[*]: str
# Put this in the code.
str[*]: str
###.*\.__name__$: str
###.*\.hash()$: int
</t>
<t tx="ekr.20160128102557.1"># An example configuration file for make_stub_files.py.
# By default, make_stub_files.py uses ~/stubs/make_stub_files.cfg.
# Can be changed using the --config=path command-line option.

[Global]

files:
    
    # Files to be used *only* if no files are given on the command line.
    # glob.glob wildcards are supported.
    
output_directory: ~/stubs
    
prefix_lines:
    # Lines to be inserted at the start of each stub file.

    from typing import TypeVar
    T = TypeVar('T', int, float, complex)
    
# Notes about patterns used below:
#
#  **Balanced patterns** contain either (*), [*], or {*}.
#  Unlike regular expressions, balanced patterns match only balanced brackets.
#
#  Both regex and balanced patterns may appear in each section.
#  However, balanced patterns will never match argument names.
#
#  Patterns are matched in the order they appear in each section,
#  but the .* pattern (if present) will match last, regardless of its
#  position in the section.
    
[Def Name Patterns]

# These regex patterns give the return types of functions or methods.
#
# Patterns for methods should match class_name.method_name.
#
# Patterns in this section *override* all other patterns,
# so you should use these patterns only if:
#
# - No other pattern properly handles the function or method, or
#
# - The pattern specifies functions that should all return the same value.
#   For example, all ast tree traversers should have the same signatures.
#
# It may be unwise to use .* in this section, but the choice is yours.

[Argument Patterns]

# The regex patterns in this section apply only when assigning types
# to *arguments* to functions or methods. Patterns match argument names.
# Typically, most patterns can be put [General Patterns] section instead.

[General Patterns]

# The patterns in this section may be either regex or balanced patterns.
# Patterns in this section are applied both to arguments and return expressions.
# These patterns are applied *once* to argument names and *repeatedly* to
# return types until no further matches can be made.

aList[1-3]?: Sequence
i: int
j: int
k: int
node: ast.Ast
s[1-3]?: str

[Return Patterns]

# The patterns in this section may be either regex or balanced patterns.
# Patterns in this section are applied only to return expressions.
# These patterns are applied *repeatedly* to return expressions
# until no further matches can be made.

# Balanced patterns...

repr(*): str
str.join(*): str
str.replace(*): str
str%(*): str
str%str: str

# Regex patterns...

.*__name__: str
</t>
<t tx="ekr.20160128104639.1">@language config

# A configuration file to make stubs for make_stub_files.py itself.

[Global]

files: make_stub_files.py
    
output_directory: .
    
prefix_lines:
    from typing import Any, Dict, Optional, Sequence, Tuple, Union
        # At present, I don't understand how to tell mypy about ast.Node
        # import ast
        # Node = ast.Node
    Node = Any

[Def Name Patterns]

# The returns are inherent in the design of make_stub_files.py:
AstFormatter.do_*: str
StubFormatter.do_*: str
StubTraverser.do_*: str

# Test of regex pattern.
.*__hash__$: int


# Pattern.all_matches: Sequence
# Pattern.full_balanced_match: Optional[int]
# Pattern.match_balanced: int
# Pattern.match_entire_string: bool
# StandAloneMakeStubFile.scan_types: Dict[str, str]

# StubTraverser.format_returns: str
# StubTraverser.match_return_patterns: Tuple[bool,str]
# StubTraverser.match_return_pattern: Optional[str]
# StubTraverser.match_balanced: int

[General Patterns]

# Test of regex patterns
.*\.endswith\(.*\)$: bool

# Declarations of names...
NotImplemented: bool
a: str
aList: List[Any]
comments: str
controller: StandAloneMakeStubFile
find_s: str
fn: str
found: str
general_patterns: List[Pattern]
group: str
i1: int
i2: int
i: int
j1: int
j2: int
j: int
n1: int
n2: int
n: int
name: str
ndots: int
node: Node
parser: optparse.OptionParser
patterns: List
repl_s: str
s: str
s1: str
s2: str
# s[1-2]?$: str
strict: bool
trace: bool

# Known functions...
all(*): bool
any(*): bool
int(*): int
hash(*): int
len(*): int
os.path.basename(*): str
os.sep.join(*): str
repr(*): str
sep.join(*): str
self.__eq__(*): bool
self.__ne__(*): bool
self.__gt__(*): bool
self.__lt__(*): bool
sorted(*): str
str%(*): str
str.endswith(*): bool 
str.join(*): str
str.startswith(*): bool 
r[*]: str
# Put this in the code.
str[*]: str

</t>
<t tx="ekr.20160128104714.1"></t>
<t tx="ekr.20160128154715.1">import pdb
import unittest
import make_stub_files as msf

class TestMakeStubFiles(unittest.TestCase):
    '''Main test class.'''
    @others
    
if __name__ == '__main__':
    unittest.main()

</t>
<t tx="ekr.20160128190112.1">
def test_pattern_class(self):
    table = (
        # regex tests. The pattern must end with $
        ('[str]', r'\[str\]$', 'xxx', 'xxx'), # Guido bug.
        ('s3', r's[1-3]?$', 'str', 'str'), # lengthening bug.
        ('s', 's', 'str', 'str'),
        ('abc', 'abc', 'ABC', 'ABC'),
        ('str(str)', 'str(*)', 'str', 'str'),
        ('[whatever]', '[*]', 'List[*]', 'List[whatever]'), # * on the RHS.
        ('(int,str)', '(*)', 'Tuple[*]', 'Tuple[int,str]'), # Guido bug 2.
        ('abcxyz', 'abc*', 'xxx', 'xxx'), # New test for trailing *.
        ('list(self.regex.finditer(str))','list(*)','List[*]',
         'List[self.regex.finditer(str)]'),
    )
    for s, find, repl, expected in table:
        # pdb.set_trace()
        pattern = msf.Pattern(find, repl)
        result = pattern.match_entire_string(s)
        assert result, (result, s, find, repl, expected)
        aList = pattern.all_matches(s)
        assert len(aList) == 1, aList
        found, s2 = pattern.match(s)
        assert found, 'after pattern.match(s)'
        assert s2 == expected, ('expected', expected, 'got', s2)
    p1 = msf.Pattern('abc','xyz')
    p2 = msf.Pattern('abc','xyz')
    p3 = msf.Pattern('abc','pdq')
    assert p1 == p2
    assert p1 != p3
    assert p2 != p3
    aSet = set()
    aSet.add(p1)
    assert p1 in aSet
    assert p2 in aSet
    assert p3 not in aSet
    assert list(aSet) == [p1] == [p2]
    aSet.add(p3)
</t>
<t tx="ekr.20160128190224.1">
def test_is_known_type(self):
    '''Test that is_known_type handles brackets reasonably.'''
    good = (
        'Any', 'Sequence',
        'Sequence[]',
        'Sequence[List]',
        'Sequence[List[Any]]',
        'Tuple[int,str]',
    )
    bad = (
        'Huh', 'Sequence(List)',
        'List+a',
        'List+List',
    )
    c = msf.StandAloneMakeStubFile()
    for s in good:
        assert msf.is_known_type(s), s
    for s in bad:
        assert not msf.is_known_type(s), s
</t>
<t tx="ekr.20160128190252.1">
# def setUp(self):
    # '''Called before each test.'''
</t>
<t tx="ekr.20160128225533.1">*.pyc
*.pyi
test/*.pyc
__pycache__/
.mypy_cache/
.cache/
.coverage
htmlcov/
</t>
<t tx="ekr.20160202061118.1">
seen_patterns = []

def visit(self, node):
    '''
    Return the formatted version of an Ast node after
    applying all general patterns.
    '''
    # This is the heart of this script.
    trace = False
    s = AstFormatter.visit(self, node)
    if self.fast_match:
        # Match only the patterns associated with this node.
        name = node.__class__.__name__
        for pattern in self.patterns_dict.get(name, []):
            found, s = pattern.match(s)
            if trace and found and pattern not in self.seen_patterns:
                self.seen_patterns.append(pattern)
                g.trace('%10s %s' % (name, pattern))
        if trace:
            # This finds and reports all missed patterns.
            for pattern in self.general_patterns:
                found, s = pattern.match(s)
                if True and found and pattern not in self.seen_patterns:
                    self.seen_patterns.append(pattern)
                    g.trace('**** %5s %s' % (name, pattern))
    else: # Match all general patterns.
        for pattern in self.general_patterns:
            found, s = pattern.match(s)
    return s
</t>
<t tx="ekr.20160202064553.1">
def match(self, patterns, s):
    '''Return s with at most one pattern matched.'''
    assert False, g.callers()
    for pattern in patterns:
        found, s = pattern.match(s)
        if found:
            break
    return s
</t>
<t tx="ekr.20160206095102.1">&lt;&lt; docstring &gt;&gt;
# **Note**: this is a Leo script.
# It **does** have access to c, g and p.
import os
import re
@others
test_dir = os.path.dirname(c.fileName())+os.sep+'test'
assert os.path.exists(test_dir), test_dir
assert os.path.isdir(test_dir), test_dir

if 1:
    # Writes each test to a separate file in the test directory.
    TestWriter(c,path=test_dir).run(fn=None)    
if 0:
    # Writes all tests to a single file: test/unit_tests.py
    TestWriter(c,path=test_dir).run(fn='unit_tests.py')
</t>
<t tx="ekr.20160206095102.2">@
@language rest
'''
This script transliterates @test nodes into .py file. The two main ways of
using this script are as follows::

    TestWriter(c,path='test').run(fn='unit_tests.py') # writes one file
    TestWriter(c,path='test').run(fn=None)            # writes separate files.
     
The first writes all tests to test/unit_tests.py; the second writes each
unit test to a separate .py file in the test directory.

The script imports each written file and reports any syntax errors.

This is a straightforward script; it should be easy to modify it to suit
individual needs.

The &lt;\&lt; file_template &gt;&gt; and &lt;\&lt; test_template &gt;&gt; sections in the TestWriter
class determines exactly what this script writes.
'''
</t>
<t tx="ekr.20160206101802.10">
def test(self,fn):
    '''Test the newly created file.'''
    import imp
    import sys

    if self.path not in sys.path:
        sys.path.append(self.path)
    assert fn.endswith('.py')
    name = fn[:-3]
    try:
        f,path,desc = imp.find_module(name,[self.path])
        imp.load_module(name,f,path,desc)
        # print('imported %s' % (name))
    except Exception:
        print('can not import: %s' % (name))
        g.es_print_exception()
</t>
<t tx="ekr.20160206101802.11">
def write_file(self,fn):

    assert g.os_path_exists(self.path),self.path
    fn = g.os_path_finalize_join(self.path,fn)
    f = open(fn,'w')
    f.write(self.file_template)
    # g.trace(''.join([z.h for z in self.nodes]))
    for p in self.nodes:
        f.write(self.test_template % (self.clean(p.h),self.get_body(p)))
    f.close()
    g.trace('wrote', fn)
</t>
<t tx="ekr.20160206101802.3">

class TestWriter:
    
    &lt;&lt; define file_template &gt;&gt;
    &lt;&lt; define test_template &gt;&gt;

    @others
</t>
<t tx="ekr.20160206101802.4"># Add any other common imports here.

file_template = '''\
import unittest
from make_stub_files import *
'''

file_template = g.adjustTripleString(file_template,c.tab_width)
</t>
<t tx="ekr.20160206101802.5">test_template = '''
class %s (unittest.TestCase):
    def runTest(self):
%s
'''

test_template = g.adjustTripleString(test_template,c.tab_width)
</t>
<t tx="ekr.20160206101802.6">
def __init__(self,c,path=''):
    '''TestWriter ctor.'''
    self.c = c
    load_dir = g.os_path_dirname(c.fileName())
    self.path = g.os_path_finalize_join(load_dir,path)
    self.nodes = []
    assert g.os_path_exists(self.path),self.path
</t>
<t tx="ekr.20160206101802.7">
def clean(self,s):
    '''Munge s so that it can be used as a file name.'''
    result,tag = [],'@test'
    if s.startswith(tag):
        s = s[len(tag):]
    for ch in s.strip():
        if ch.isalnum():
            result.append(ch)
        else:
            result.append('_')
        # elif ch.isspace():
            # result.append('_')
    s = ''.join(result)
    if s.endswith('.py'):
        s = s[:-3]
    if not s.startswith('test'):
        s = 'test_' + s
    return s.replace('__','_').strip()
</t>
<t tx="ekr.20160206101802.8">
def get_body(self, p):
    '''Convert p.b to a valid script.'''
    s_old = p.b
    # Suppress @others but not section references.
    p.b = p.b.replace('@others', '')
    assert p.b.find('@others') == -1
    s = g.getScript(c, p,
                    useSelectedText=False,
                    forcePythonSentinels=True,
                    useSentinels=False)
    p.b = s_old
    s = ''.join([' '*8+z for z in g.splitLines(s) if z.strip()])
            # Add leading indentation needed by test_template.
    return s.rstrip()+'\n'
</t>
<t tx="ekr.20160206101802.9">
def run(self,fn=None):
    
    n, p = 0, c.rootPosition()
    while p:
        if p.h.startswith('@ignore '):
            p.moveToNodeAfterTree()
        elif p.h.startswith('@test '):
            self.nodes.append(p.copy())
            if not fn:
                fn2 = self.clean(p.h)+'.py'
                self.write_file(fn2)
                self.test(fn2)
                self.nodes=[]
            n += 1
            p.moveToThreadNext()
        else:
            p.moveToThreadNext()
    if n == 0:
        print('no @file or @suite nodes found.')
    else:
        if fn:
            self.write_file(fn)
            self.test(fn)
        dest = g.os_path_join(self.path, fn) if fn else self.path
        print('wrote %s test%s to %s' % (n,self.plural(n), dest))
</t>
<t tx="ekr.20160206103417.1">
def plural(self, n):
    return 's' if n &gt; 1 else ''
</t>
<t tx="ekr.20160206104033.1"># pylint: disable=relative-import
g.cls()
import test_msf
import unittest
loader = unittest.TestLoader()
suite = loader.loadTestsFromTestCase(test_msf.TestMakeStubFiles)
unittest.TextTestRunner(verbosity=0).run(suite)
</t>
<t tx="ekr.20160206165507.1">@language config

# A configuration file to make stubs for make_stub_files.py itself.

[Global]

files: test/test.py
output_directory: ./test
# prefix_lines:

[Def Name Patterns]

[General Patterns]

# Declarations of names..
a: Any
s: str
aList: List[Any]
is_known_type(*): bool

# Known functions...
all(*): bool
any(*): bool
endswith(*): bool
g.match_word(*): bool
hash(*): int
hasattr(*): bool
int(*): int
len(*): int
os.path.basename(*): str
os.sep.join(*): str
repr(*): str
sep.join(*): str
self.__eq__(*): bool
self.__ne__(*): bool
self.__gt__(*): bool
self.__lt__(*): bool
sorted(*): str
str%(*): str
str.join(*): str
str.isspace(*): str
str[*]: str
sum(*): number
</t>
<t tx="ekr.20160206165656.1">"""A test file containing code that caused mypy errors."""

def is_known_type(s):
    '''
    Return True if s is nothing but a single known type.
    Recursively test inner types in square brackets.
    '''
    trace = False
    s1 = s
    s = s.strip()
    table = (
        # None,
        'self', # Experimental.
        'None', 
        'complex', 'float', 'int', 'long', 'number',
        'dict', 'list', 'tuple',
        'bool', 'bytes', 'str', 'unicode',
    )
    for s2 in table:
        if s2 == s:
            return True
        elif Pattern(s2+'(*)', s).match_entire_string(s):
            return True
    if s.startswith('[') and s.endswith(']'):
        inner = s[1:-1]
        return is_known_type(inner) if inner else True
    elif s.startswith('(') and s.endswith(')'):
        inner = s[1:-1]
        return is_known_type(inner) if inner else True
    elif s.startswith('{') and s.endswith('}'):
        return True ### Not yet.
        # inner = s[1:-1]
        # return is_known_type(inner) if inner else True
    table = (
        # Pep 484: https://www.python.org/dev/peps/pep-0484/
        # typing module: https://docs.python.org/3/library/typing.html
        'AbstractSet', 'Any', 'AnyMeta', 'AnyStr',
        'BinaryIO', 'ByteString',
        'Callable', 'CallableMeta', 'Container',
        'Dict', 'Final', 'Generic', 'GenericMeta', 'Hashable',
        'IO', 'ItemsView', 'Iterable', 'Iterator',
        'KT', 'KeysView', 'List',
        'Mapping', 'MappingView', 'Match',
        'MutableMapping', 'MutableSequence', 'MutableSet',
        'NamedTuple', 'Optional', 'OptionalMeta',
        # 'POSIX', 'PY2', 'PY3',
        'Pattern', 'Reversible',
        'Sequence', 'Set', 'Sized',
        'SupportsAbs', 'SupportsFloat', 'SupportsInt', 'SupportsRound',
        'T', 'TextIO', 'Tuple', 'TupleMeta',
        'TypeVar', 'TypingMeta',
        'Undefined', 'Union', 'UnionMeta',
        'VT', 'ValuesView', 'VarBinding',
    )
    for s2 in table:
        if s2 == s:
            return True
        pattern = Pattern(s2+'[*]', s)
        if pattern.match_entire_string(s):
            # Look inside the square brackets.
            # if s.startswith('Dict[List'): g.pdb()
            brackets = s[len(s2):]
            assert brackets and brackets[0] == '[' and brackets[-1] == ']'
            s3 = brackets[1:-1]
            if s3:
                return all([is_known_type(z.strip())
                    for z in split_types(s3)])
            else:
                return True
    if trace: g.trace('Fail:', s1)
    return False


def return_every_kind(a, b):
    # pylint: disable=unreachable
    return 1
    return 1.0
    return float(1.0)
    return complex(2.0,3.0)
    return long(1)
    return ('a','b')
    return [1, 2]
    return {}
    return {'x': 'y',}
    return dict(['p', 'q'])
    return list(1,2)
    return int(0.5)
    return tuple('a1', 'b1')
    return True and False
    return True or False
    return 1 and 0
    return 1 or -1
    return not True
    return not 1
    return 1 if False else 2
    
def match_entire_string(self, s):
    '''Return True if s matches self.find_s'''
    if self.is_balanced():
        j = self.full_balanced_match(s, 0)
        return j is not None
    else:
        m = self.regex.match(s)
        return m and m.group(0) == s

def splitLines(self, s):
    '''Split s into lines, preserving trailing newlines.'''
    return s.splitlines(True) if s else []
    
def sum_test(n):
    '''An common recursive pattern.'''
    if n == 1:
        return 1
    else:
        return 1 + sum(n-1)
        
def not_test(a):
    return not a
    
def optional_any(a):
    if a:
        return a
    else:
        return None
        
def optional_any2(a):
    if a:
        return a
    else:
        return
</t>
<t tx="ekr.20160207051429.1">a, c, f, i, l, n = ('Any', 'complex', 'float', 'int', 'long', 'number')
none = 'None'
La, Lc = ['Any'], ['complex']
Lac, Lai, Lan = ['Any', 'complex'], ['Any', 'int'], ['Any', 'None']
Laci = ['Any', 'complex', 'int']
Lnone = ['None']
table = (
    (none, Lnone,   Lnone),
    (none, none,    Lnone),
    (a, none,       Lan),
    (a, a,          La),
    (La, a,         La),
    (Lac, a,        Lac),
    (Lac, i,        Laci),
    (Lac, Lai,      Laci),
)
@others
for a1, a2, expected in table:
    got = merge_types(a1, a2)
    assert expected == got, (a1, a2, 'expected:', expected, 'got', got)
</t>
<t tx="ekr.20160207101607.1">@language rest
@wrap

This is the theory-of-operation document for the `make_stub_files` script. It is intentionally brief. Please [ask questions](#summary) if anything is unclear.

### Prerequisites

Maintainers should be familiar with the following:

- The [Python 3 ast class](https://docs.python.org/3/library/ast.html).
  You should know what a tree traversal is.
- [Pep 484](https://www.python.org/dev/peps/pep-0484/) and
  [Python's typing module](https://docs.python.org/3/library/typing.html).
  Having a clear **target language** greatly simplifies this project.
  
You don't need to know anything about type inference.

### High level description

This is, truly, a *very* simple script. Indeed, this is just a modified code formatter. This script traverses the incoming ast tree *once* from the top down, generating results from the bottom up. There is only a *single* traversal, composed of four traversal classes. (See [below](#traversers) for details). This traversal produces a stub for every class and def line. To do this, it **replaces expressions with type hints**. In other words, the goal is to **reduce** expressions to **known types**, as defined by Pep 484.

The StubFormatter visitors do most of the work of type reduction. They are simple because they delegate type reduction to the following helpers:

1. **`ReduceTypes.reduce_types(aList)`** reduces a *list* of 0 or more types to a *string* representing a type hint. It returns 'Any' for unknown types. At the top of the traversal, StubTraverser.do_FunctionDef also calls reduce_types (via helpers) on the list of all return expressions.

2. **`StubFormatter.match_all(node, s)`** applies all user-patterns to s and returns the result.

3. **`ReduceTypes.is_known_type(s)`** embodies the known types as defined in Pep 484 and the typing module.

In short, visitors are hardly more complex than the corresponding AstFormatter methods.

**Notes**:

- The `sf.do_Attribute` and `sf.do_Name` visitors look up names in `sf.names_dict`. This is much faster than matching patterns.

- `sf.match_all` is very fast because it only applies patterns that *could possibly* match at the node being visited. Those patterns are:

        self.patterns_dict.get(node.__class__.__name__, []) + self.regex_patterns
        
  That is, all regex patterns are applied "everywhere" in return expressions.

- The startup code create `names_dict`, `patterns_dict` and `regex_patterns` data structures. That's all you have to know about the startup code.

- The Pattern class handles almost all details of pattern matching. This shields the rest of the code from knowledge of patterns. In particular, `sf.match_all` knows nothing about patterns.

### Examples

The previous section is really you should need to know about this program.  However, a few examples may make this script's operation clearer. The --trace-matches and --trace-reduce switches turn on detailed traces that show exactly when and where reductions happen, and what the resulting type hints are. These traces are the truth.  Believe them, not words here.

Given the file truncate.py:

    def truncate(s, n):
        '''Return s truncated to n characters.'''
        return s if len(s) &lt;= n else s[:n-3] + '...'
        
The script produces this output with the --verbose option in effect:

    def truncate(s: str, n: int) -&gt; str: ...
        #   0: return s if len(s)&lt;=n else s[:n-3]+'...'
        #   0: return str
        
Here is the output with --trace-reduce --trace-matches in effect:

    make_stub_files.py -c msf.cfg truncate.py -v -o --trace-reduce --trace-matches
    
    callers                     pattern                types ==&gt; hint    
    =======                     =======         ========================
    reduce_types: do_BinOp                      [int, number] ==&gt; number
    match_all:    do_Subscript  str[*]: str      str[:number] ==&gt; str
    reduce_types: do_IfExp                               str] ==&gt; str

Finally, here is *part* of the result of tracing make_stub_files.py itself:

          context                   pattern                                                          types ==&gt; hint    
    =============================== ================ =========================================================================
    reduce_types: do_IfExp                                                    [bool, is_known_type(inner)] ==&gt; ? Any
    reduce_types: do_IfExp                                                    [bool, is_known_type(inner)] ==&gt; ? Any
    match_all:    do_Call           all(*): bool                  all(is_known_type(z.strip()) for z in... ==&gt; bool
    reduce_types: is_known_type                                                                [Any, bool] ==&gt; Union[Any, bool]
    match_all:    do_Call           sorted(*): str                                      sorted(Set[r1+r2]) ==&gt; str
    reduce_types: show                                  [show_helper(List[Any][:], known, str, str, bool)] ==&gt; ? Any
    match_all:    do_Subscript      r[*]: str                                                    r[number] ==&gt; str
    match_all:    do_Call           str.join(*): str                                         str.join(str) ==&gt; str
    reduce_types: reduce_types                       [show(str), show(str, known=bool), show_helper(Li...] ==&gt; ? Any
    reduce_types: do_BinOp                                                                   [int, number] ==&gt; number
    match_all:    do_Subscript      str[*]: str                                               str[:number] ==&gt; str
    reduce_types: do_IfExp                                                                           [str] ==&gt; str
    
    class AstFormatter
    
    reduce_types: do_BoolOp                                                              [val, val.strip()] ==&gt; ? Any
    reduce_types: do_BoolOp                                                                      [Any, str] ==&gt; Union[Any, str]
    reduce_types: visit                                                                               [str] ==&gt; str
    reduce_types: do_IfExp                                                                            [str] ==&gt; str
    match_all:    do_Call           repr(*): str                                               repr(Node.n) ==&gt; str
    reduce_types: get_import_names                                                                 [result] ==&gt; ? Any
    reduce_types: kind                                                            [Node.__class__.__name__] ==&gt; ? Any
    
This trace contains pretty much everything you need to know about pattern matching and type reduction.

Enable tracing in various visitors if you need more data.

&lt;a name="traversers"/&gt;
### Traversers

As stated above, this script traverses the parse tree *once*, using four different traversal classes. Each traverser produces the results needed at a particular point of the traversal. Imo, using separate traversal classes is good style, even though it would be straightforward to use a single class. Indeed, each class has a distinct purpose...

#### AstFormatter

This is the base formatter class. It defines the default formatting for each kind of node. More importantly, it emphasizes that subclasses must return strings, *never* lists. The `AstFormatter.visit` method checks that this is so. This assertion guarantees that subclasses must call `st.reduce_types` to convert a list of possible types into a single string representing their union.

#### StubTraverser

This class drives the traversal. It is a subclass of ast.NodeVisitor. No custom visit method is needed. Visitors are *not* formatters--they *use* formatters to produce stubs. This class overrides only the visitors for ClassDef, FunctionDef and Return ast nodes. The FunctionDef visitor invokes the StubFormatter class to format all the functions return statements. The FunctionDef visitor invokes the AstArgFormatter to format names in argument lists.

#### StubFormatter

This class formats return statements. The overridden visitors of this class replace constants and operators with their corresponding type hints. The do_BinOp method contains hard-coded patterns for creating type hints. More could be added. The script is truly simple because the visitor methods of this class are hardly more complex than the corresponding methods of the AstFormatter class.

### AstArgFormatter

This class works just like the StubFormatter class except that does *not* apply patterns to Name nodes. As the name implies, it is used to format arguments in function definitions. It could easily be merged into the StubFormatter class, but imo having a separate class is cleaner and even a bit safer.

### Unit testing

The easy way to do unit testing is from within Leo:

- Alt-6 runs all unit tests in @test nodes.
- Alt-5 runs all *marked* @test nodes. Super convenient while developing code.

The `@button write-unit-test` script writes all @test nodes to `make_stub_files/test`.

The `--test` option runs all test files in `make_stub_files/test`.

The following also runs all test files in `make_stub_files/test`:

    cd make_stub_files
    python -m unittest discover -s test

&lt;a name="summary"/&gt;
### Summary

This script is a straightforward tree traversal. Or so it seems to me.
Please feel free to ask questions.

Edward K. Ream  
edreamleo@gmail.com  
(608) 886-5730
</t>
<t tx="ekr.20160207105647.1"></t>
<t tx="ekr.20160207105710.1">g.cls()
for p1 in c.all_unique_positions():
    if p1.h.startswith('@clean'):
        for p in p1.subtree():
            if (not p.h.strip().startswith('&lt;&lt;') and
                p.b.strip() and not p.b.startswith('\n')
            ):
                print(repr(p.b[:3]), p.h)
print('done')
</t>
<t tx="ekr.20160207115604.1">
def truncate(s, n):
    '''Return s truncated to n characters.'''
    return s if len(s) &lt;= n else s[:n-3] + '...'
</t>
<t tx="ekr.20160207115947.1">def test_truncate(self):
    table = (
        ('abc',     'abc'),
        ('abcd',    'abcd'),
        ('abcde',   'abcde'),
        ('abcdef',  'ab...'),
        ('abcdefg', 'ab...'),
    )
    for s1, s2 in table:
        got = truncate(s1, 5)
        self.assertEqual(s2, got, msg=f"s1: {s1!r}")
</t>
<t tx="ekr.20160207181637.1"></t>
<t tx="ekr.20160207181648.1"></t>
<t tx="ekr.20160207182535.1"></t>
<t tx="ekr.20160208162138.1">
    # First, look at the [Def Name Patterns]
    if 0: # This never seems to match anything.
        stack = self.traverser.class_name_stack
        if stack:
            name = '%s.%s' % (stack[-1], func)
        else:
            name = func
        for pattern in self.def_patterns:
            found, s = pattern.match(name)
            if found:
                if trace: g.trace('%s: %s -&gt; %s' % (pattern.find_s, name, s))
                return s</t>
<t tx="ekr.20160211110739.1">@language rest
@wrap

This is the readme file for `make_stub_files.py`. This file explains what the script does, how it works and why it is important. After a brief overview, a step-by-step section will get you started. Full source code for the script is in its [github repository](https://github.com/edreamleo/make-stub-files). This script is in the public domain.

@others
</t>
<t tx="ekr.20160211110807.1">
### Overview

This script makes a stub (.pyi) file in the **output directory** for each **source file** listed on the command line (wildcard file names are supported). This script never creates directories automatically, nor does it overwrite stub files unless the --overwrite command-line option is in effect.

GvR says, "We actually do have a [stub generator](https://github.com/JukkaL/mypy/blob/master/mypy/stubgen.py) as part of mypy now (it has a few options) but yours has the advantage of providing a way to tune the generated signatures...This allows for a nice iterative way of developing stubs."

The script does no type inference. Instead, the user supplies **patterns** in a configuration file. The script matches these patterns to:

1. The names of arguments in functions and methods and

2. The text of **return expressions**. Return expressions are the actual text of whatever follows the "return" keyword. The script removes all comments in return expressions and converts all strings to "str". This **preprocessing** greatly simplifies pattern matching.

As a first example, given the method:

    def foo(self, i, s):
        if i:
            return "abc" # a comment
        else:
            return s
        
and the patterns:

    i: int
    s: str
    
the script produces the stub:

    def foo(i: int, s: str) --&gt; str: ...

The `make_stub_files` script eliminates much of the drudgery of creating [python stub (.pyi) files](https://www.python.org/dev/peps/pep-0484/#stub-files) from python source files. This script should encourage more people to use mypy. Stub files can be used by people who use Python 2.x code bases.

</t>
<t tx="ekr.20160211110810.1">
### Command-line arguments

    Usage: make_stub_files.py [options] file1, file2, ...
    
    Options:
      -h, --help          show this help message and exit
      -c FN, --config=FN  full path to configuration file
      -d DIR, --dir=DIR   full path to the output directory
      -o, --overwrite     overwrite existing stub (.pyi) files
      -t, --test          run unit tests on startup
      --trace-matches     trace Pattern.matches
      --trace-patterns    trace pattern creation
      --trace-reduce      trace st.reduce_types
      --trace-visitors    trace visitor methods
      -u, --update        update stubs in existing stub file
      -v, --verbose       verbose output in .pyi file
      -w, --warn          warn about unannotated args

*Note*: glob.glob wildcards can be used in file1, file2, ...
</t>
<t tx="ekr.20160211110810.2">
### The configuration file

The --config command-line option specifies the full path to the optional configuration file. The configuration file uses the .ini format. It has several configuration sections, all optional.

</t>
<t tx="ekr.20160211110810.3">
### Why this script is important

The script eliminates most of the drudgery from creating stub files. The script produces syntactically and semantically correct stub files without any patterns at all. Patterns make it easy to make stubs more specific.

Once we create stub files, mypy will check them by doing real type inference. This will find errors both in the stub files and in the program under test. There is now an easy way to use mypy!

Stubs express design intentions and intuitions as well as types. Until now, there has been no practical way of expressing and *testing* these assumptions. Now there is.

Using mypy, we can be as specific as we like about types. We can simply annotate that d is a dict, or we can say that d is a dict whose keys are strings and whose values are executables with a union of possible signatures. Stubs are the easy way to play with type inference.

Stub files clarify long-standing questions about types. To what extent *do* we understand types? How dynamic (RPython-like) *are* our programs? mypy will tell us where are stub files are dubious. Could we use type annotation to convert our programs to C? Not likely, but now there is a way to know where things get sticky.

Finally, stubs can simplify the general type inference problem. Without type hints or annotations, the type of everything depends on the type of everything else. Stubs could allow robust, maybe even complete, type inference to be done locally. Stubs help mypy to work faster.
</t>
<t tx="ekr.20160211110811.1">
### Summary

The make-stub-files script does for type/design analysis what Leo's c2py command did for converting C sources to python. It eliminates much of the drudgery associated with creating stub files, leaving the programmer to make non-trivial inferences.

Stub files allow us to explore type checking using mypy as a guide and helper. Stub files are both a design document and an executable, checkable, type specification. Stub files allow those with a Python 2 code base to use mypy.

One could imagine a similar insert_annotations script that would inject function annotations into source files using stub files as data. The "reverse" script should be more straightforward than this script.

Edward K. Ream  
January 25 to February 15, 2016
</t>
<t tx="ekr.20160211111807.1">
#### Patterns

The [Def Name Patterns] and [General Patterns] configuration sections
specify patterns. All patterns have the form:

    find-string: replacement-string
    
Colons are not allowed in the find-string. This is a limitation of .ini files.

There are three kinds of patterns: balanced, regex and plain.

**Balanced patterns** are patterns whose find string that:

A: contain either `(*)`, `[*]`, or `{*}` or

B: ends with `*`.

Unlike regular expressions, `(*)`, `[*]`, or `{*}` match only
balanced brackets. A trailing `*` matches the rest of the string.

Examples:

    str(*): str
    StubTraverser.do_*
    
Balanced patterns such as:

    [*]: List[*]

work as expected. The script replaces the `*` in replacement-strings with
whatever matched `*` in the find-string.

**Regex patterns** (regular expression patterns) are denoted by a
find-string that ends with `$`. The trailing `$` does not become part of
the find-string. For example:

    ab(.*)de$: de\1\1ab

A pattern is a **plain pattern** if it is neither a balanced nor a regex
pattern.

The script matches patterns to *all parts* of return expressions.

*Important*: The script applies patterns *separately* to each return
expression. Comments never appear in return expressions, and all strings in
return values appear as str. As a result, there is no context to worry
about context in which patterns are matched. Very short patterns suffice.

</t>
<t tx="ekr.20160211111823.1">
#### [Global]

This configuration section specifies the files list, prefix lines and
output directory. For example:

    [Global]

    files:
        # Files to be used *only* if no files are given on the command line.
        # glob.glob wildcards are supported.
        ~/leo-editor/leo/core/*.py
        
    output_directory:
        # The output directory to be used if no --dir option is given.
        ~/stubs
        
    prefix:
        # Lines to be inserted at the start of each stub file.
        from typing import TypeVar, Iterable, Tuple
        T = TypeVar('T', int, float, complex)
</t>
<t tx="ekr.20160211111839.1">
#### [Def Name Patterns]

The script matches the find-strings in this section against names of
functions and methods. For methods, the script matches find-strings against
names of the form:

    class_name.method_name

When a find-string matches, the replacement-string becomes the return type
in the stub, without any further pattern matching. That is, this section
*overrides* [General Patterns].

Example 1:

    [Def Name Patterns]
    myFunction: List[str]
    
Any function named myFunction returns List[str].

Example 2:

    [Def Name Patterns]
    MyClass.myMethod: str
    
The myMethod method of the MyClass class returns str.

Example 3:

    [Def Name Patterns]
    MyClass.do_*: str
    
All methods of the MyClass class whose names start with "do_" return str.
</t>
<t tx="ekr.20160211111901.1">
#### [General Patterns]

For each function or method, the script matches the patterns in this
section against **all parts** of all return expressions in each function or method.

The intent of the patterns in this section should be to **reduce** return
expressions to **known types**. A known type is a either a name of a type
class, such as int, str, long, etc. or a **type hint**, as per
[Pep 484](https://www.python.org/dev/peps/pep-0484/).

The script *always* produces a syntactically correct stub, even if the
patterns do not reduce the return expression to a known type. For unknown
types, the script does the following:

1. Uses Any as the type of the function or method.

2. Follows the stub with a list of comments giving all the return
   expressions in the function or method.
   
For example, suppose that the patterns are not sufficient to resolve the
return type of:

    def foo(a):
        if a:
            return a+frungify(a)
        else:
            return defrungify(a)
         
The script will create this stub:

    def foo(a) --&gt; Any: ...
        # return a+frungify(a)
        # return defrungify(a)
        
The comments preserve maximal information about return types, which should
help the user to supply a more specific return type. The user can do this
in two ways by altering the stub files by hand or by adding new patterns to
the config file.
</t>
<t tx="ekr.20160211113019.1">
### Quick Start

1. Put `make_stub_files.py` on your path.

2. Enter a directory containing .py files:

        cd myDirectory
    
3. Generate stubs for foo.py in foo.pyi:

        make_stub_files foo.py

4. Look at foo.pyi to see the generated stubs.

5. Regenerate foo.pyi with more verbose output:

        make_stub_files foo.py -o -v

   The -o (--overwrite) option allows the script to overwrite foo.pyi.  
   The -v (--verbose) options generates return comments for all stubs in foo.pyi.
   
6. Update foo.pyi:

        make_stub_files -o -u
        
   The -u (--update) options updates foo.pyi as follows:
   
   - adds stubs to foo.pyi for classes and defs that are new in foo.py.
   - deletes stubs in foo.pyi for classes and defs that no longer exist in foo.py.
   - leaves all other stubs in foo.pyi unchanged.
   
7. Specify a configuration file containing patterns:

        make_stub_files -c myConfigFile.cfg -o
</t>
<t tx="ekr.20160214043351.1">
def make_optional(self,r):
    
    if r and 'None' in r:
        r = [z for z in r if z != 'None']
        r = self.show('Optional[%s]' % r[0]) if r else self.show('None')
    return r</t>
<t tx="ekr.20160214103050.1"></t>
<t tx="ekr.20160214154338.1">    r = sorted(set(aList))
    if trace: g.trace('1', r)
    table = (
        self.reduce_unknowns,
        self.reduce_numbers,
        self.merge_tuples,
        self.merge_dicts,
        self.merge_lists,
        self.make_optional,
    )
    # Apply all reductions even on lists of length one.
    for f in table:
        r = f(r)
    if trace: g.trace('2', r)
    if not r:
        return 'None'
    elif len(r) == 1:
        return self.show(r[0])
    elif 'None' in r:
        r = [z for z in aList if z != 'None']
        if len(r) == 0:
            return self.show('None')
        elif len(r) == 1:
            return self.show('Optional[%s]' % r[0])
        else:
            return self.show('Optional[Union[%s]]' % (', '.join(sorted(r))))
    else:
        return self.show('Union[%s]' % (', '.join(sorted(r))))
</t>
<t tx="ekr.20160214171726.1">    # Look inside the square brackets.
    brackets = s[len(s2):]
    if brackets and brackets[0] == '[' and brackets[-1] == ']':
        s3 = brackets[1:-1]
        if s3:
            return all([self.is_known_type(z.strip())
                for z in self.split_types(s3)])
        else:
            return True
    else:
        s3 = brackets[1:-1]
        g.trace('can not happen:\ns2: %s\ns3: %s\npattern: %s' % (
            ' '*5+s2, ' '*5+s3, pattern))
    </t>
<t tx="ekr.20160214172029.1">    result = []
    for z in aList:
        for kind in ('Dict', 'List', 'Optional', 'Tuple', 'Union'):
            if z.startswith(kind):
                result.append(z)
                break
        else:
            result.append(z if self.is_known_type(z) else 'Any')
    g.trace(aList, result)
    return result
</t>
<t tx="ekr.20160318141204.11">def main():
    '''
    The driver for the stand-alone version of make-stub-files.
    All options come from ~/stubs/make_stub_files.cfg.
    '''
    controller = Controller()
    controller.scan_command_line()
    controller.scan_options()
    for fn in controller.files:
        controller.make_stub_file(fn)
</t>
<t tx="ekr.20160318141204.110">def match_balanced(self, delim, s, i):
    '''
    delim == s[i] and delim is in '([{'
    Return the index of the end of the balanced parenthesized string, or len(s)+1.
    '''
    global g_input_file_name
    assert s[i] == delim, s[i]
    assert delim in '([{'
    delim2 = ')]}'['([{'.index(delim)]
    assert delim2 in ')]}'
    level = 0
    while i &lt; len(s):
        progress = i
        ch = s[i]
        i += 1
        if ch == delim:
            level += 1
        elif ch == delim2:
            level -= 1
            if level == 0:
                return i
        assert progress &lt; i
    # Unmatched: a syntax error.
    print('%20s: unmatched %s in %s' % (g_input_file_name, delim, s))
    # print('called from:', g.callers(4))
    return len(s) + 1
</t>
<t tx="ekr.20160318141204.125">class Controller:
    '''
    A class to make Python stub (.pyi) files in the ~/stubs directory for
    every file mentioned in the [Source Files] section of
    ~/stubs/make_stub_files.cfg.
    '''
    @others
</t>
<t tx="ekr.20160318141204.126">def __init__(self):
    '''Ctor for Controller class.'''
    self.options = {}
    # Ivars set on the command line...
    self.config_fn = None
    self.enable_coverage_tests = False
    self.enable_unit_tests = False
    self.files = []
    # Ivars set in the config file...
    self.output_fn = None
    self.output_directory = None
    self.overwrite = False
    self.prefix_lines = []
    self.silent = False
    self.trace_matches = False
    self.trace_patterns = False
    self.trace_reduce = False
    self.trace_visitors = False
    self.update_flag = False
    self.verbose = False  # Trace config arguments.
    self.warn = False
    # Pattern lists, set by config sections...
    self.section_names = ('Global', 'Def Name Patterns', 'General Patterns')
    self.def_patterns = []  # [Def Name Patterns]
    self.general_patterns = []  # [General Patterns]
    self.names_dict = {}
    self.op_name_dict = self.make_op_name_dict()
    self.patterns_dict = {}
    self.regex_patterns = []
</t>
<t tx="ekr.20160318141204.127">def finalize(self, fn):
    '''Finalize and regularize a filename.'''
    return os.path.normpath(os.path.abspath(os.path.expanduser(fn)))
</t>
<t tx="ekr.20160318141204.128">directory_warning_given = False

def make_stub_file(self, fn):
    '''
    Make a stub file in ~/stubs for all source files mentioned in the
    [Source Files] section of ~/stubs/make_stub_files.cfg
    '''
    global g_input_file_name
    extension = fn[fn.rfind('.'):]
    if not extension == '.py' and not (self.force_pyx and extension == '.pyx'):
        print('not a python file', fn)
        return
    #
    # Read the input file.
    if not os.path.exists(fn):
        print('not found', fn)
        return
    # Set g_input_file_name for error messages.
    g_input_file_name = g.shortFileName(fn)
    try:
        with open(fn, 'r') as f:
            s = f.read()
    except UnicodeDecodeError:  # Python 3 only, try utf-8 encoding.
        with open(fn, 'r', encoding='utf-8') as f:
            s = f.read()
    #
    # Compute the output file name.
    if self.output_directory:
        if not os.path.exists(self.output_directory):
            if not self.directory_warning_given:
                self.directory_warning_given = True
                print('output directory not found:', repr(self.output_directory))
            return
        base_fn = os.path.basename(fn)
        out_fn = os.path.join(self.output_directory, base_fn)
        out_fn = out_fn[:-len(extension)] + '.pyi'
    else:
        out_fn = fn[:-len(extension)] + '.pyi'
    self.output_fn = os.path.normpath(out_fn)
    #
    # Process s.
    node = ast.parse(s, filename=fn, mode='exec')
    StubTraverser(controller=self).run(node)
</t>
<t tx="ekr.20160318141204.129">def run(self):
    """Make stubs for all files."""
    for fn in self.files:
        self.make_stub_file(fn)
</t>
<t tx="ekr.20160318141204.130">def run_all_unit_tests(self):
    '''Run all unit tests in the make_stub_files/test directory.'''
    import unittest
    loader = unittest.TestLoader()
    suite = loader.discover(os.path.abspath('.'),
                            pattern='test*.py',
                            top_level_dir=None)
    unittest.TextTestRunner(verbosity=1).run(suite)
</t>
<t tx="ekr.20160318141204.131">def scan_command_line(self):
    '''Set ivars from command-line arguments.'''
    # The parser implements the --help option.
    description='make_stub_file: Create stub (.pyi) files from python files'
    usage = 'make_stub_files.py [options] file1, file2, ...'
    parser = argparse.ArgumentParser(description=description, usage=usage)
    add = parser.add_argument
    add('files', metavar='FILE', type=str, nargs='+',
        help='input files')
    add('-c', '--config', dest='fn', metavar='FILE',
        help='full path to configuration file')
    add('-d', '--dir', dest='dir',
        help='full path to the output directory')
    add('-f', '--force-pyx', action='store_true', default=False,
        help='force the parsing of .pyx files')
    add('-o', '--overwrite', action='store_true', default=False,
        help='overwrite existing stub (.pyi) files')
    add('-s', '--silent', action='store_true', default=False,
        help='run without messages')
    add('--trace-matches', action='store_true', default=False,
        help='trace Pattern.matches')
    add('--trace-patterns', action='store_true', default=False,
        help='trace pattern creation')
    add('--trace-reduce', action='store_true', default=False,
        help='trace st.reduce_types')
    add('--trace-visitors', action='store_true', default=False,
        help='trace visitor methods')
    add('-u', '--update', action='store_true', default=False,
        help='update stubs in existing stub file')
    add('-v', '--verbose', action='store_true', default=False,
        help='verbose output in .pyi file')
    add('-w', '--warn', action='store_true', default=False,
        help='warn about unannotated args')
    # Parse.
    args = parser.parse_args()
    # Handle the args...
    self.overwrite = args.overwrite
    self.silent = args.silent
    self.trace_matches = args.trace_matches
    self.trace_patterns = args.trace_patterns
    self.trace_reduce = args.trace_reduce
    self.trace_visitors = args.trace_visitors
    self.update_flag = args.update
    self.verbose = args.verbose
    self.warn = args.warn
    self.force_pyx = args.force_pyx
    if args.fn:
        self.config_fn = args.fn
    if args.dir:
        dir_ = args.dir and args.dir.strip()
        dir_ = self.finalize(dir_)
        g.trace('dir', dir_)
        if os.path.exists(dir_):
            self.output_directory = dir_
        else:
            print('--dir: directory does not exist: %s' % dir_)
            print('exiting')
            sys.exit(1)
    if args.force_pyx:
        print('--force-pyx: .pyx files will be parsed as regular python, cython syntax is not supported')
    self.files = args.files
</t>
<t tx="ekr.20160318141204.132">def scan_options(self):
    '''Set all configuration-related ivars.'''
    if self.verbose:
        print('')
        print(f"configuration file: {self.config_fn}")
    if not self.config_fn:
        return
    self.parser = parser = self.create_parser()
    s = self.get_config_string()
    self.init_parser(s)
    if self.files:
        files_source = 'command-line'
        files = self.files
        if isinstance(files, str):
            files = [files]
    elif parser.has_section('Global'):
        files_source = 'config file'
        files = parser.get('Global', 'files')
        files = [z.strip() for z in files.split('\n') if z.strip()]
    else:
        return
    if self.verbose:
        print(f"Files (from {files_source})...")
    files2 = []
    not_found = []
    for z in files:
        # 2021/08/04: Warn if z does not exist.
        files3 = glob.glob(self.finalize(z))
        if files3:
            if self.verbose:
                for z in files3:
                    print(f"  {z}")
            files2.extend(files3)
        else:
            not_found.append(z)
    if not_found:
        print('Not found...')
        for z in not_found:
            print(f"  {z}")
    self.files = files2
    if 'output_directory' in parser.options('Global'):
        s = parser.get('Global', 'output_directory').strip()
        output_dir = self.finalize(s)
        if os.path.exists(output_dir):
            self.output_directory = output_dir
            if self.verbose:
                print(f"output directory: {output_dir}")
        else:
            print(f"output directory not found: {output_dir}")
            self.output_directory = None  # inhibit run().
    if 'prefix_lines' in parser.options('Global'):
        prefix = parser.get('Global', 'prefix_lines')
        prefix_lines = prefix.split('\n')
            # The parser does not preserve leading whitespace.
        self.prefix_lines = [z for z in prefix_lines if z.strip()]
        # Annoying
        # if self.verbose:
            # print('Prefix lines...\n')
            # for z in self.prefix_lines:
                # print('  %s' % z)
            # print('')
    if self.verbose:
        print('')
    self.def_patterns = self.scan_patterns('Def Name Patterns')
    self.general_patterns = self.scan_patterns('General Patterns')
    self.make_patterns_dict()
</t>
<t tx="ekr.20160318141204.133">def make_op_name_dict(self):
    '''
    Make a dict whose keys are operators ('+', '+=', etc),
    and whose values are lists of values of ast.Node.__class__.__name__.
    '''
    d = {
        '.': ['Attr',],
        '(*)': ['Call', 'Tuple',],
        '[*]': ['List', 'Subscript',],
        '{*}': ['???',],
        # 'and': 'BoolOp',
        # 'or':  'BoolOp',
    }
    for op in (
        '+', '-', '*', '/', '%', '**', '&lt;&lt;',
        '&gt;&gt;', '|', '^', '&amp;', '//',
    ):
        d[op] = ['BinOp',]
    for op in (
        '==', '!=', '&lt;', '&lt;=', '&gt;', '&gt;=',
        'is', 'is not', 'in', 'not in',
    ):
        d[op] = ['Compare',]
    return d
</t>
<t tx="ekr.20160318141204.134">def create_parser(self):
    '''Create a RawConfigParser and return it.'''
    parser = configparser.RawConfigParser(dict_type=OrderedDict)
        # Requires Python 2.7
    parser.optionxform = str
    return parser
</t>
<t tx="ekr.20160318141204.135">def find_pattern_ops(self, pattern):
    '''Return a list of operators in pattern.find_s.'''
    trace = False or self.trace_patterns
    if pattern.is_regex():
        # Add the pattern to the regex patterns list.
        g.trace(pattern)
        self.regex_patterns.append(pattern)
        return []
    d = self.op_name_dict
    keys1, keys2, keys3, keys9 = [], [], [], []
    for op in d:
        aList = d.get(op)
        if op.replace(' ', '').isalnum():
            # an alpha op, like 'not, 'not in', etc.
            keys9.append(op)
        elif len(op) == 3:
            keys3.append(op)
        elif len(op) == 2:
            keys2.append(op)
        elif len(op) == 1:
            keys1.append(op)
        else:
            g.trace('bad op', op)
    ops = []
    s = s1 = pattern.find_s
    for aList in (keys3, keys2, keys1):
        for op in aList:
            # Must match word here!
            if s.find(op) &gt; -1:
                s = s.replace(op, '')
                ops.append(op)
    # Handle the keys9 list very carefully.
    for op in keys9:
        target = ' %s ' % op
        if s.find(target) &gt; -1:
            ops.append(op)
            break  # Only one match allowed.
    if trace and ops: g.trace(s1, ops)
    return ops
</t>
<t tx="ekr.20160318141204.136">def get_config_string(self):
    """Read the configuration file."""
    fn = self.finalize(self.config_fn)
    if os.path.exists(fn):
        with open(fn, 'r') as f:
            return f.read()
    print(f"\nconfiguration file not found: {fn}")
    return ''

</t>
<t tx="ekr.20160318141204.137">def init_parser(self, s):
    '''Add double back-slashes to all patterns starting with '['.'''
    if not s:
        return
    aList = []
    for s in s.split('\n'):
        if self.is_section_name(s):
            aList.append(s)
        elif s.strip().startswith('['):
            aList.append(r'\\' + s[1:])
        else:
            aList.append(s)
    s = '\n'.join(aList) + '\n'
    file_object = io.StringIO(s)
    self.parser.read_file(file_object)
</t>
<t tx="ekr.20160318141204.138">def is_section_name(self, s):

    def munge(s):
        return s.strip().lower().replace(' ', '')

    s = s.strip()
    if s.startswith('[') and s.endswith(']'):
        s = munge(s[1:-1])
        for s2 in self.section_names:
            if s == munge(s2):
                return True
    return False
</t>
<t tx="ekr.20160318141204.139">def make_patterns_dict(self):
    '''Assign all patterns to the appropriate ast.Node.'''
    for pattern in self.general_patterns:
        ops = self.find_pattern_ops(pattern)
        if ops:
            for op in ops:
                # Add the pattern to op's list.
                op_names = self.op_name_dict.get(op)
                for op_name in op_names:
                    aList = self.patterns_dict.get(op_name, [])
                    aList.append(pattern)
                    self.patterns_dict[op_name] = aList
        else:
            # Enter the name in self.names_dict.
            name = pattern.find_s
            # Special case for 'number'
            if name == 'number':
                aList = self.patterns_dict.get('Num', [])
                aList.append(pattern)
                self.patterns_dict['Num'] = aList
            elif name in self.names_dict:
                g.trace('duplicate pattern', pattern)
            else:
                self.names_dict[name] = pattern.repl_s
    if 0:
        g.trace('names_dict...')
        for z in sorted(self.names_dict):
            print('  %s: %s' % (z, self.names_dict.get(z)))
    if 0:
        g.trace('patterns_dict...')
        for z in sorted(self.patterns_dict):
            aList = self.patterns_dict.get(z)
            print(z)
            for pattern in sorted(aList):
                print('  ' + repr(pattern))
    # Note: retain self.general_patterns for use in argument lists.
</t>
<t tx="ekr.20160318141204.14">class AstFormatter:
    '''
    A class to recreate source code from an AST.
    
    This does not have to be perfect, but it should be close.
    '''
    # pylint: disable=consider-using-enumerate
    @others
</t>
<t tx="ekr.20160318141204.140">def scan_patterns(self, section_name):
    '''Parse the config section into a list of patterns, preserving order.'''
    trace = False or self.trace_patterns
    parser = self.parser
    aList = []
    if parser.has_section(section_name):
        seen = set()
        for key in parser.options(section_name):
            value = parser.get(section_name, key)
            # A kludge: strip leading \\ from patterns.
            if key.startswith(r'\\'):
                key = '[' + key[2:]
            if key in seen:
                g.trace('duplicate key', key)
            else:
                seen.add(key)
                aList.append(Pattern(key, value))
        if trace:
            g.trace('%s...\n' % section_name)
            for z in aList:
                print(z)
            print('')
    return aList
</t>
<t tx="ekr.20160318141204.147">class StubFormatter(AstFormatter):
    '''
    Formats an ast.Node and its descendants,
    making pattern substitutions in Name and operator nodes.
    '''
    @others
</t>
<t tx="ekr.20160318141204.148">def __init__(self, controller, traverser):
    '''Ctor for StubFormatter class.'''
    self.controller = x = controller
    self.traverser = traverser
        # 2016/02/07: to give the formatter access to the class_stack.
    self.def_patterns = x.def_patterns
    self.general_patterns = x.general_patterns
    self.names_dict = x.names_dict
    self.patterns_dict = x.patterns_dict
    self.raw_format = AstFormatter().format
    self.regex_patterns = x.regex_patterns
    self.trace_matches = x.trace_matches
    self.trace_patterns = x.trace_patterns
    self.trace_reduce = x.trace_reduce
    self.trace_visitors = x.trace_visitors
    self.verbose = x.verbose
    # mypy workarounds
    self.seen_names = []
</t>
<t tx="ekr.20160318141204.149">matched_d = {}

def match_all(self, node, s, trace=False):
    '''Match all the patterns for the given node.'''
    trace = trace or self.trace_matches
    # verbose = True
    d = self.matched_d
    name = node.__class__.__name__
    s1 = truncate(s, 40)
    caller = g.callers(2).split(',')[1].strip()
        # The direct caller of match_all.
    patterns = self.patterns_dict.get(name, []) + self.regex_patterns
    for pattern in patterns:
        found, s = pattern.match(s, trace=False)
        if found:
            if trace:
                aList = d.get(name, [])
                if pattern not in aList:
                    aList.append(pattern)
                    d[name] = aList
                    print('match_all:    %-12s %26s %40s ==&gt; %s' % (caller, pattern, s1, s))
            break
    return s
</t>
<t tx="ekr.20160318141204.15">
# Entries...
</t>
<t tx="ekr.20160318141204.150">def visit(self, node):
    '''StubFormatter.visit: supports --verbose tracing.'''
    s = AstFormatter.visit(self, node)
    return s
</t>
<t tx="ekr.20160318141204.151">def trace_visitor(self, node, op, s):
    '''Trace node's visitor.'''
    if self.trace_visitors:
        caller = g.callers(2).split(',')[1]
        s1 = AstFormatter().format(node).strip()
        print('%12s op %-6s: %s ==&gt; %s' % (caller, op.strip(), s1, s))
</t>
<t tx="ekr.20160318141204.152"># StubFormatter visitors for operands...
</t>
<t tx="ekr.20160318141204.153"># Attribute(expr value, identifier attr, expr_context ctx)

attrs_seen = []

def do_Attribute(self, node):
    '''StubFormatter.do_Attribute.'''
    s = '%s.%s' % (
        self.visit(node.value),
        node.attr)  # Don't visit node.attr: it is always a string.
    s2 = self.names_dict.get(s)
    if False and s2 and s2 not in self.attrs_seen:
        self.attrs_seen.append(s2)
        g.trace(s, '==&gt;', s2)
    return s2 or s
</t>
<t tx="ekr.20160318141204.154"># Return generic markers to allow better pattern matches.

def do_Bytes(self, node):  # Python 3.x only.
    return 'bytes'  # return str(node.s)

def do_Num(self, node):
    # make_patterns_dict treats 'number' as a special case.
    # return self.names_dict.get('number', 'number')
    return 'number'  # return repr(node.n)

def do_Str(self, node):
    '''This represents a string constant.'''
    return 'str'  # return repr(node.s)
</t>
<t tx="ekr.20160318141204.155">def do_Dict(self, node):
    result = []
    keys = [self.visit(z) for z in node.keys]
    values = [self.visit(z) for z in node.values]
    if len(keys) == len(values):
        result.append('{')
        items = []
        # pylint: disable=consider-using-enumerate
        for i in range(len(keys)):
            items.append('%s:%s' % (keys[i], values[i]))
        result.append(', '.join(items))
        result.append('}')
    else:
        print('Error: f.Dict: len(keys) != len(values)\nkeys: %s\nvals: %s' % (
            repr(keys), repr(values)))
    return 'Dict[%s]' % ''.join(result) if result else 'Dict'
</t>
<t tx="ekr.20160318141204.156">def do_List(self, node):
    '''StubFormatter.List.'''
    elts = [self.visit(z) for z in node.elts]
    elts = [z for z in elts if z]  # Defensive.
    return 'List[%s]' % ', '.join(elts) if elts else 'List'
</t>
<t tx="ekr.20160318141204.157"># seen_names = [] # t--ype: List[str]

def do_Name(self, node):
    '''StubFormatter ast.Name visitor.'''
    d = self.names_dict
    name = d.get(node.id, node.id)
    s = 'bool' if name in ('True', 'False') else name
    if False and node.id not in self.seen_names:
        self.seen_names.append(node.id)
        if d.get(node.id):
            g.trace(node.id, '==&gt;', d.get(node.id))
        elif node.id == 'aList':
            g.trace('**not found**', node.id)
    return s
</t>
<t tx="ekr.20160318141204.158">def do_Tuple(self, node):
    '''StubFormatter.Tuple.'''
    elts = [self.visit(z) for z in node.elts]
    return 'Tuple[%s]' % ', '.join(elts)
</t>
<t tx="ekr.20160318141204.159"># StubFormatter visitors for operators...
</t>
<t tx="ekr.20160318141204.160"># BinOp(expr left, operator op, expr right)

def do_BinOp(self, node):
    '''StubFormatter.BinOp visitor.'''
    trace = self.trace_reduce
    numbers = ['number', 'complex', 'float', 'long', 'int',]
    op = self.op_name(node.op)
    lhs = self.visit(node.left)
    rhs = self.visit(node.right)
    if op.strip() in ('is', 'is not', 'in', 'not in'):
        s = 'bool'
    elif lhs == rhs:
        s = lhs
            # Perhaps not always right,
            # but it is correct for Tuple, List, Dict.
    elif lhs in numbers and rhs in numbers:
        s = reduce_types([lhs, rhs], trace=trace)
            # reduce_numbers would be wrong: it returns a list.
    elif lhs == 'str' and op in '%+*':
        # str + any implies any is a string.
        s = 'str'
    else:
        # Fall back to the base-class behavior.
        s = '%s%s%s' % (
            self.visit(node.left),
            op,
            self.visit(node.right))
    s = self.match_all(node, s)
    self.trace_visitor(node, op, s)
    return s
</t>
<t tx="ekr.20160318141204.161"># BoolOp(boolop op, expr* values)

def do_BoolOp(self, node):  # Python 2.x only.
    '''StubFormatter.BoolOp visitor for 'and' and 'or'.'''
    trace = self.trace_reduce
    op = self.op_name(node.op)
    values = [self.visit(z).strip() for z in node.values]
    s = reduce_types(values, trace=trace)
    s = self.match_all(node, s)
    self.trace_visitor(node, op, s)
    return s
</t>
<t tx="ekr.20160318141204.162"># Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)

def do_Call(self, node):
    '''StubFormatter.Call visitor.'''
    func = self.visit(node.func)
    args = [self.visit(z) for z in node.args]
    for z in node.keywords:
        # Calls f.do_keyword.
        args.append(self.visit(z))
    if getattr(node, 'starargs', None):
        args.append('*%s' % (self.visit(node.starargs)))
    if getattr(node, 'kwargs', None):
        args.append('**%s' % (self.visit(node.kwargs)))
    args = [z for z in args if z]  # Kludge: Defensive coding.
    # Explicit pattern:
    if func in ('dict', 'list', 'set', 'tuple',):
        if args:
            s = '%s[%s]' % (func.capitalize(), ', '.join(args))
        else:
            s = '%s' % func.capitalize()
    else:
        s = '%s(%s)' % (func, ', '.join(args))
    s = self.match_all(node, s, trace=False)
    self.trace_visitor(node, 'call', s)
    return s
</t>
<t tx="ekr.20160318141204.163"># keyword = (identifier arg, expr value)

def do_keyword(self, node):
    # node.arg is a string.
    value = self.visit(node.value)
    # This is a keyword *arg*, not a Python keyword!
    return '%s=%s' % (node.arg, value)
</t>
<t tx="ekr.20160318141204.164"># Compare(expr left, cmpop* ops, expr* comparators)

def do_Compare(self, node):
    '''
    StubFormatter ast.Compare visitor for these ops:
    '==', '!=', '&lt;', '&lt;=', '&gt;', '&gt;=', 'is', 'is not', 'in', 'not in',
    '''
    s = 'bool'  # Correct regardless of arguments.
    ops = ','.join([self.op_name(z) for z in node.ops])
    self.trace_visitor(node, ops, s)
    return s
</t>
<t tx="ekr.20160318141204.165"># If(expr test, stmt* body, stmt* orelse)

def do_IfExp(self, node):
    '''StubFormatterIfExp (ternary operator).'''
    trace = self.trace_reduce
    aList = [
        self.match_all(node, self.visit(node.body)),
        self.match_all(node, self.visit(node.orelse)),
    ]
    s = reduce_types(aList, trace=trace)
    s = self.match_all(node, s)
    self.trace_visitor(node, 'if', s)
    return s
</t>
<t tx="ekr.20160318141204.166"># Subscript(expr value, slice slice, expr_context ctx)

def do_Subscript(self, node):
    '''StubFormatter.Subscript.'''
    s = '%s[%s]' % (
        self.visit(node.value),
        self.visit(node.slice))
    s = self.match_all(node, s)
    self.trace_visitor(node, '[]', s)
    return s
</t>
<t tx="ekr.20160318141204.167"># UnaryOp(unaryop op, expr operand)

def do_UnaryOp(self, node):
    '''StubFormatter.UnaryOp for unary +, -, ~ and 'not' operators.'''
    op = self.op_name(node.op)
    if op.strip() == 'not':
        return 'bool'
    s = self.visit(node.operand)
    s = self.match_all(node, s)
    self.trace_visitor(node, op, s)
    return s
</t>
<t tx="ekr.20160318141204.168">def do_Return(self, node):
    '''
    StubFormatter ast.Return vsitor.
    Return only the return expression itself.
    '''
    s = AstFormatter.do_Return(self, node)
    assert s.startswith('return'), repr(s)
    return s[len('return') :].strip()
</t>
<t tx="ekr.20160318141204.169">class StubTraverser(ast.NodeVisitor):
    '''
    An ast.Node traverser class that outputs a stub for each class or def.
    Names of visitors must start with visit_. The order of traversal does
    not matter, because so few visitors do anything.
    '''
    @others
</t>
<t tx="ekr.20160318141204.17">def format(self, node):
    '''Format the node (or list of nodes) and its descendants.'''
    self.level = 0
    val = self.visit(node)
    # pylint: disable=consider-using-ternary
    return val and val.strip() or ''
</t>
<t tx="ekr.20160318141204.170">def __init__(self, controller):
    '''Ctor for StubTraverser class.'''
    self.controller = x = controller  # A Controller instance.
    # Internal state ivars...
    self.class_name_stack = []
    self.class_defs_count = 0
        # The number of defs seen for this class.
    self.context_stack = []
    sf = StubFormatter(controller=controller, traverser=self)
    self.format = sf.format
    self.arg_format = AstArgFormatter().format
    self.level = 0
    self.output_file = None
    self.parent_stub = None
    self.raw_format = AstFormatter().format
    self.returns = []
    self.stubs_dict = {}
        # Keys are stub.full_name's.  Values are stubs.
    self.warn_list = []
    # Copies of controller ivars...
    self.output_fn = x.output_fn
    self.overwrite = x.overwrite
    self.prefix_lines = x.prefix_lines
    self.silent = x.silent
    self.regex_patterns = x.regex_patterns
    self.update_flag = x.update_flag
    self.trace_matches = x.trace_matches
    self.trace_patterns = x.trace_patterns
    self.trace_reduce = x.trace_reduce
    self.trace_visitors = x.trace_visitors
    self.verbose = x.verbose
    self.warn = x.warn
    # Copies of controller patterns...
    self.def_patterns = x.def_patterns
    self.names_dict = x.names_dict
    self.general_patterns = x.general_patterns
    self.patterns_dict = x.patterns_dict
</t>
<t tx="ekr.20160318141204.171">def add_stub(self, d, stub):
    '''Add the stub to d, checking that it does not exist.'''
    global g_input_file_name
    key = stub.full_name
    assert key
    if key in d:
        # caller = g.callers(2).split(',')[1]
        print('%20s: ignoring duplicate entry for %s' % (g_input_file_name, key))
    else:
        d[key] = stub
</t>
<t tx="ekr.20160318141204.172">def indent(self, s):
    '''Return s, properly indented.'''
    # This version of indent *is* used.
    return '%s%s' % (' ' * 4 * self.level, s)

def out(self, s):
    '''Output the string to the console or the file.'''
    s = self.indent(s)
    if self.parent_stub:
        self.parent_stub.out_list.append(s)
    elif self.output_file:
        self.output_file.write(s + '\n')
    else:
        print(s)
</t>
<t tx="ekr.20160318141204.173">def run(self, node):
    '''StubTraverser.run: write the stubs in node's tree to self.output_fn.'''
    fn = self.output_fn
    dir_ = os.path.dirname(fn)
    if os.path.exists(fn) and not self.overwrite:
        print('file exists: %s' % fn)
        return
    if dir_ and not os.path.exists(dir_):
        print('output directory not not found: %s' % dir_)
        return
    # Create parent_stub.out_list.
    self.parent_stub = Stub(kind='root', name='&lt;new-stubs&gt;')
    for z in self.prefix_lines or []:
        self.parent_stub.out_list.append(z)
    self.visit(node)
    if self.update_flag:
        self.parent_stub = self.update(fn, new_root=self.parent_stub)
    # Output the stubs.
    self.output_file = open(fn, 'w')
    self.output_time_stamp()
    self.output_stubs(self.parent_stub)
    self.output_file.close()
    self.output_file = None
    self.parent_stub = None
    if self.verbose:
        print('wrote: %s' % fn)
</t>
<t tx="ekr.20160318141204.174">def output_stubs(self, stub):
    '''Output this stub and all its descendants.'''
    for s in stub.out_list or []:
        # Indentation must be present when an item is added to stub.out_list.
        if self.output_file:
            self.output_file.write(s.rstrip() + '\n')
        else:
            print(s)
    # Recursively print all children.
    for child in stub.children:
        self.output_stubs(child)
</t>
<t tx="ekr.20160318141204.175">def output_time_stamp(self):
    '''Put a time-stamp in the output file.'''
    if self.output_file:
        self.output_file.write('# make_stub_files: %s\n' %
            time.strftime("%a %d %b %Y at %H:%M:%S"))
</t>
<t tx="ekr.20160318141204.176">def update(self, fn, new_root):
    '''
    Merge the new_root tree with the old_root tree in fn (a .pyi file).

    new_root is the root of the stub tree from the .py file.
    old_root (read below) is the root of stub tree from the .pyi file.
    
    Return old_root, or new_root if there are any errors.
    '''
    s = self.get_stub_file(fn)
    if not s or not s.strip():
        return new_root
    if '\t' in s:
        # Tabs in stub files make it impossible to parse them reliably.
        g.trace('Can not update stub files containing tabs.')
        return new_root
    # Read old_root from the .pyi file.
    old_d, old_root = self.parse_stub_file(s, root_name='&lt;old-stubs&gt;')
    if old_root:
        # Merge new stubs into the old tree.
        if 0:
            print(self.trace_stubs(old_root, header='old_root'))
            print(self.trace_stubs(new_root, header='new_root'))
        print('***** updating stubs from %s *****' % fn)
        self.merge_stubs(self.stubs_dict.values(), old_root, new_root)
        # print(self.trace_stubs(old_root, header='updated_root'))
        return old_root
    return new_root
</t>
<t tx="ekr.20160318141204.177">def get_stub_file(self, fn):
    '''Read the stub file into s.'''
    if os.path.exists(fn):
        try:
            s = open(fn, 'r').read()
        except Exception:
            print('--update: error reading %s' % fn)
            s = None
        return s
    print('--update: not found: %s' % fn)
    return None
</t>
<t tx="ekr.20160318141204.178">def parse_stub_file(self, s, root_name):
    '''
    Parse s, the contents of a stub file, into a tree of Stubs.
    
    Parse by hand, so that --update can be run with Python 2.
    '''
    assert '\t' not in s
    d = {}
    root = Stub(kind='root', name=root_name)
    indent_stack = [-1]  # To prevent the root from being popped.
    stub_stack = [root]
    lines = []
    pat = re.compile(r'^([ ]*)(def|class)\s+([a-zA-Z_]+)(.*)')
    for line in g.splitLines(s):
        m = pat.match(line)
        if m:
            indent, kind, name = (len(m.group(1)), m.group(2), m.group(3))
            old_indent = indent_stack[-1]
            # Terminate any previous lines.
            old_stub = stub_stack[-1]
            old_stub.out_list.extend(lines)
            lines = [line]
            # Adjust the stacks.
            if indent == old_indent:
                stub_stack.pop()
            elif indent &gt; old_indent:
                indent_stack.append(indent)
            else:  # indent &lt; old_indent
                # The indent_stack can't underflow because
                # indent &gt;= 0 and indent_stack[0] &lt; 0
                assert indent &gt;= 0
                while indent &lt;= indent_stack[-1]:
                    indent_stack.pop()
                    old_stub = stub_stack.pop()
                    assert old_stub != root
                indent_stack.append(indent)
            # Create and push the new stub *after* adjusting the stacks.
            assert stub_stack
            parent = stub_stack[-1]
            stack = [z.name for z in stub_stack[1:]]
            parent = stub_stack[-1]
            stub = Stub(kind, name, parent, stack)
            self.add_stub(d, stub)
            stub_stack.append(stub)
        else:
            parent = stub_stack[-1]
            lines.append(line)
    # Terminate the last stub.
    old_stub = stub_stack[-1]
    old_stub.out_list.extend(lines)
    return d, root
</t>
<t tx="ekr.20160318141204.179">def merge_stubs(self, new_stubs, old_root, new_root, trace=False):
    '''
    Merge the new_stubs *list* into the old_root *tree*.
    - new_stubs is a list of Stubs from the .py file.
    - old_root is the root of the stubs from the .pyi file.
    - new_root is the root of the stubs from the .py file.
    '''
    # Part 1: Delete old stubs do *not* exist in the *new* tree.
    aList = self.check_delete(new_stubs, old_root, new_root, trace)
        # Checks that all ancestors of deleted nodes will be deleted.
    aList = list(reversed(self.sort_stubs_by_hierarchy(aList)))
        # Sort old stubs so that children are deleted before parents.
    for stub in aList:
        if trace: g.trace('deleting  %s' % stub)
        parent = self.find_parent_stub(stub, old_root) or old_root
        parent.children.remove(stub)
        assert not self.find_stub(stub, old_root), stub
    # Part 2: Insert new stubs that *not* exist in the *old* tree.
    aList = [z for z in new_stubs if not self.find_stub(z, old_root)]
    aList = self.sort_stubs_by_hierarchy(aList)
        # Sort new stubs so that parents are created before children.
    for stub in aList:
        if trace: g.trace('inserting %s' % stub)
        parent = self.find_parent_stub(stub, old_root) or old_root
        parent.children.append(stub)
        assert self.find_stub(stub, old_root), stub
</t>
<t tx="ekr.20160318141204.18">def visit(self, node):
    '''Return the formatted version of an Ast node, or list of Ast nodes.'''
    if isinstance(node, (list, tuple)):
        return ','.join([self.visit(z) for z in node])
    if node is None:
        return 'None'
    assert isinstance(node, ast.AST), node.__class__.__name__
    method_name = 'do_' + node.__class__.__name__
    try:
        method = getattr(self, method_name)
    except AttributeError:
        return ''

    s = method(node)
    # assert type(s) == type('abc'), (node, type(s))
    assert g.isString(s), type(s)
    return s
</t>
<t tx="ekr.20160318141204.180">def check_delete(self, new_stubs, old_root, new_root, trace):
    '''Return a list of nodes that can be deleted.'''
    old_stubs = self.flatten_stubs(old_root)
    old_stubs.remove(old_root)
    aList = [z for z in old_stubs if z not in new_stubs]
    if trace:
        dump_list('old_stubs', old_stubs)
        dump_list('new_stubs', new_stubs)
        dump_list('to-be-deleted stubs', aList)
    delete_list = []
    # Check that all parents of to-be-delete nodes will be deleted.
    for z in aList:
        z1 = z
        for i in range(20):
            z = z.parent
            if not z:
                g.trace('can not append: new root not found', z)
                break
            elif z == old_root:
                delete_list.append(z1)
                break
            elif z not in aList:
                g.trace("can not delete %s because of %s" % (z1, z))
                break
        else:
            g.trace('can not happen: parent loop')
    if trace:
        dump_list('delete_list', delete_list)
    return delete_list
</t>
<t tx="ekr.20160318141204.181">def flatten_stubs(self, root):
    '''Return a flattened list of all stubs in root's tree.'''
    aList = [root]
    for child in root.children:
        self.flatten_stubs_helper(child, aList)
    return aList

def flatten_stubs_helper(self, root, aList):
    '''Append all stubs in root's tree to aList.'''
    aList.append(root)
    for child in root.children:
        self.flatten_stubs_helper(child, aList)
</t>
<t tx="ekr.20160318141204.182">def find_parent_stub(self, stub, root):
    '''Return stub's parent **in root's tree**.'''
    return self.find_stub(stub.parent, root) if stub.parent else None
</t>
<t tx="ekr.20160318141204.183">def find_stub(self, stub, root):
    '''Return the stub **in root's tree** that matches stub.'''
    if stub == root:  # Must use Stub.__eq__!
        return root  # not stub!
    for child in root.children:
        stub2 = self.find_stub(stub, child)
        if stub2: return stub2
    return None
</t>
<t tx="ekr.20160318141204.184">def sort_stubs_by_hierarchy(self, stubs1):
    '''
    Sort the list of Stubs so that parents appear before all their
    descendants.
    '''
    stubs, result = stubs1[:], []
    for i in range(50):
        if stubs:
            # Add all stubs with i parents to the results.
            found = [z for z in stubs if z.level() == i]
            result.extend(found)
            for z in found:
                stubs.remove(z)
        else:
            return result
    g.trace('can not happen: unbounded stub levels.')
    return []  # Abort the merge.
</t>
<t tx="ekr.20160318141204.185">def trace_stubs(self, stub, aList=None, header=None, level=-1):
    '''Return a trace of the given stub and all its descendants.'''
    indent = ' ' * 4 * max(0, level)
    if level == -1:
        aList = ['===== %s...\n' % (header) if header else '']
    for s in stub.out_list:
        aList.append('%s%s' % (indent, s.rstrip()))
    for child in stub.children:
        self.trace_stubs(child, level=level + 1, aList=aList)
    if level == -1:
        return '\n'.join(aList) + '\n'
    return ''
</t>
<t tx="ekr.20160318141204.186"># 2: ClassDef(identifier name, expr* bases,
#             stmt* body, expr* decorator_list)
# 3: ClassDef(identifier name, expr* bases,
#             keyword* keywords, expr? starargs, expr? kwargs
#             stmt* body, expr* decorator_list)
#
# keyword arguments supplied to call (NULL identifier for **kwargs)
# keyword = (identifier? arg, expr value)

def visit_ClassDef(self, node):

    # Create the stub in the old context.
    old_stub = self.parent_stub
    self.class_defs_count = 0
    self.parent_stub = Stub('class', node.name, old_stub, self.context_stack)
    self.add_stub(self.stubs_dict, self.parent_stub)
    # Enter the new context.
    self.class_name_stack.append(node.name)
    self.context_stack.append(node.name)
    if self.trace_matches or self.trace_reduce:
        print('\nclass %s\n' % node.name)
    #
    # Fix issue #2: look ahead to see if there are any functions in this class.
    empty = not any(isinstance(z, ast.FunctionDef) for z in node.body)
    tail = ' ...' if empty else ''
    #
    # Format...
    bases = [self.visit(z) for z in node.bases] if node.bases else []
    if getattr(node, 'keywords', None):  # Python 3
        for keyword in node.keywords:
            bases.append('%s=%s' % (keyword.arg, self.visit(keyword.value)))
    if getattr(node, 'starargs', None):  # Python 3
        bases.append('*%s', self.visit(node.starargs))
    if getattr(node, 'kwargs', None):  # Python 3
        bases.append('*%s', self.visit(node.kwargs))
    if not node.name.startswith('_'):
        if node.bases:
            s = '(%s)' % ', '.join([self.format(z) for z in node.bases])
        else:
            s = ''
        self.out('class %s%s:%s' % (node.name, s, tail))
    # Visit...
    self.level += 1
    for z in node.body:
        self.visit(z)
    # Restore the context
    self.context_stack.pop()
    self.class_name_stack.pop()
    self.level -= 1
    self.parent_stub = old_stub
</t>
<t tx="ekr.20160318141204.187"># 2: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list)
# 3: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list,
#                expr? returns)

def visit_FunctionDef(self, node):

    # Create the stub in the old context.
    old_stub = self.parent_stub
    self.parent_stub = Stub('def', node.name, old_stub, self.context_stack)
    self.add_stub(self.stubs_dict, self.parent_stub)
    # Enter the new context.
    self.returns = []
    self.level += 1
    self.context_stack.append(node.name)
    for z in node.body:
        self.visit(z)
    self.context_stack.pop()
    self.level -= 1
    # Format *after* traversing
    # if self.trace_matches or self.trace_reduce:
        # if not self.class_name_stack:
            # print('def %s\n' % node.name)
    self.out('def %s(%s) -&gt; %s' % (
        node.name,
        self.format_arguments(node.args),
        self.format_returns(node)))
    self.parent_stub = old_stub
</t>
<t tx="ekr.20160318141204.188"># arguments = (expr* args, identifier? vararg, identifier? kwarg, expr* defaults)

def format_arguments(self, node):
    '''
    Format the arguments node.
    Similar to AstFormat.do_arguments, but it is not a visitor!
    '''
    assert isinstance(node, ast.arguments), node
    args = [self.raw_format(z) for z in node.args]
    defaults = [self.raw_format(z) for z in node.defaults]
    # Assign default values to the last args.
    result = []
    n_plain = len(args) - len(defaults)
    for i, arg in enumerate(args):
        s = self.munge_arg(arg)
        if i &lt; n_plain:
            result.append(s)
        else:
            result.append('%s=%s' % (s, defaults[i - n_plain]))
    # Now add the vararg and kwarg args.
    name = getattr(node, 'vararg', None)
    if name:
        if hasattr(ast, 'arg'):  # python 3:
            name = self.raw_format(name)
        result.append('*' + name)
    name = getattr(node, 'kwarg', None)
    if name:
        if hasattr(ast, 'arg'):  # python 3:
            name = self.raw_format(name)
        result.append('**' + name)
    return ', '.join(result)
</t>
<t tx="ekr.20160318141204.189">type_pattern = re.compile(r'.*:.*')

def munge_arg(self, s):
    '''Add an annotation for s if possible.'''
    if s == 'self':
        return s
    for pattern in self.general_patterns:
        if pattern.match_entire_string(s):
            return '%s: %s' % (s, pattern.repl_s)
    if self.warn and s not in self.warn_list:
        self.warn_list.append(s)
        print('no annotation for %s' % s)
    # Fix issue #3.
    if self.type_pattern.match(s):
        return s
    return s + ': Any'
</t>
<t tx="ekr.20160318141204.19">
# Contexts...
</t>
<t tx="ekr.20160318141204.190">def format_returns(self, node):
    '''
    Calculate the return type:
    - Return None if there are no return statements.
    - Patterns in [Def Name Patterns] override all other patterns.
    - Otherwise, return a list of return values.
    '''
    name = self.get_def_name(node)
    raw = [self.raw_format(z) for z in self.returns]
    # Allow StubFormatter.do_Return to do the hack.
    r = [self.format(z) for z in self.returns]
    # Step 1: Return None if there are no return statements.
    if not [z for z in self.returns if z.value is not None]:
        empty = not any(isinstance(z, ast.FunctionDef) for z in node.body)
        tail = ': ...' if empty else ':'
        return 'None' + tail
    # Step 2: [Def Name Patterns] override all other patterns.
    for pattern in self.def_patterns:
        found, s = pattern.match(name)
        if found:
            return s + ': ...'
    # Step 3: remove recursive calls.
    raw, r = self.remove_recursive_calls(name, raw, r)
    # Step 4: Calculate return types.
    return self.format_return_expressions(node, name, raw, r)
</t>
<t tx="ekr.20160318141204.191">def format_return_expressions(self, node, name, raw_returns, reduced_returns):
    '''
    aList is a list of maximally reduced return expressions.
    For each expression e in Alist:
    - If e is a single known type, add e to the result.
    - Otherwise, add Any # e to the result.
    Return the properly indented result.
    '''
    assert len(raw_returns) == len(reduced_returns)
    lws = '\n' + ' ' * 4
    n = len(raw_returns)
    known = all(is_known_type(e) for e in reduced_returns)
    empty = not any(isinstance(z, ast.FunctionDef) for z in node.body)
    tail = ': ...' if empty else ':'
    if not known or self.verbose:
        # First, generate the return lines.
        aList = []
        for i in range(n):
            e, raw = reduced_returns[i], raw_returns[i]
            known = ' ' if is_known_type(e) else '?'
            aList.append('# %s %s: %s' % (' ', i, raw))
            aList.append('# %s %s: return %s' % (known, i, e))
        results = ''.join([lws + self.indent(z) for z in aList])
        # Put the return lines in their proper places.
        if known:
            s = reduce_types(reduced_returns, name=name, trace=self.trace_reduce)
            return s + tail + results
        return 'Any' + tail + results
    s = reduce_types(reduced_returns, name=name, trace=self.trace_reduce)
    return s + tail
</t>
<t tx="ekr.20160318141204.192">def get_def_name(self, node):
    '''Return the representaion of a function or method name.'''
    if self.class_name_stack:
        name = '%s.%s' % (self.class_name_stack[-1], node.name)
        # All ctors should return None
        if node.name == '__init__':
            name = 'None'
    else:
        name = node.name
    return name
</t>
<t tx="ekr.20160318141204.193">def remove_recursive_calls(self, name, raw, reduced):
    '''Remove any recursive calls to name from both lists.'''
    # At present, this works *only* if the return is nothing but the recursive call.
    assert len(raw) == len(reduced)
    pattern = Pattern('%s(*)' % name)
    n = len(reduced)
    raw_result, reduced_result = [], []
    for i in range(n):
        if pattern.match_entire_string(reduced[i]):
            pass
        else:
            raw_result.append(raw[i])
            reduced_result.append(reduced[i])
    return raw_result, reduced_result
</t>
<t tx="ekr.20160318141204.194">def visit_Return(self, node):

    self.returns.append(node)
        # New: return the entire node, not node.value.
</t>
<t tx="ekr.20160318141204.195">

class TestClass:
    '''
    A class containing constructs that have caused difficulties.
    This is in the make_stub_files directory, not the test directory.
    '''
    # pylint: disable=no-member
    # pylint: disable=undefined-variable
    # pylint: disable=no-self-argument
    # pylint: disable=no-method-argument
    # pylint: disable=unsubscriptable-object
    @others
</t>
<t tx="ekr.20160318141204.196">
def parse_group(group):
    # pylint: disable=unsupported-delete-operation
    if len(group) &gt;= 3 and group[-2] == 'as':
        del group[-2:]
    ndots = 0
    i = 0
    while len(group) &gt; i and group[i].startswith('.'):
        ndots += len(group[i])
        i += 1
    assert ''.join(group[:i]) == '.' * ndots, group
    del group[:i]
    assert all(g == '.' for g in group[1::2]), group
    return ndots, os.sep.join(group[::2])
</t>
<t tx="ekr.20160318141204.197">
def return_all(self):
    return all([is_known_type(z) for z in s3.split(',')])
    # return all(['abc'])
</t>
<t tx="ekr.20160318141204.198">
def return_array(self):
    return f(s[1:-1])
</t>
<t tx="ekr.20160318141204.199">
def return_list(self, a):
    return [a]
</t>
<t tx="ekr.20160318141204.2">import argparse
import ast
from collections import OrderedDict
    # Requires Python 2.7 or above. Without OrderedDict
    # the configparser will give random order for patterns.
try:
    import ConfigParser as configparser  # Python 2
except ImportError:
    import configparser  # Python 3
import glob
import os
import re
import subprocess
import sys
import time
import types
import unittest
try:
    import StringIO as io  # Python 2
except ImportError:
    import io  # Python 3</t>
<t tx="ekr.20160318141204.20"># 2: ClassDef(identifier name, expr* bases,
#             stmt* body, expr* decorator_list)
# 3: ClassDef(identifier name, expr* bases,
#             keyword* keywords, expr? starargs, expr? kwargs
#             stmt* body, expr* decorator_list)
#
# keyword arguments supplied to call (NULL identifier for **kwargs)
# keyword = (identifier? arg, expr value)

def do_ClassDef(self, node):
    result = []
    name = node.name  # Only a plain string is valid.
    bases = [self.visit(z) for z in node.bases] if node.bases else []
    if getattr(node, 'keywords', None):  # Python 3
        for keyword in node.keywords:
            bases.append('%s=%s' % (keyword.arg, self.visit(keyword.value)))
    if getattr(node, 'starargs', None):  # Python 3
        bases.append('*%s', self.visit(node.starargs))
    if getattr(node, 'kwargs', None):  # Python 3
        bases.append('*%s', self.visit(node.kwargs))
    #
    # Fix issue #2: look ahead to see if there are any functions in this class.
    empty = not any(isinstance(z, ast.FunctionDef) for z in node.body)
    tail = ' ...' if empty else ''
    if bases:
        result.append(
            self.indent('class %s(%s):%s\n' % (name, ','.join(bases), tail)))
    else:
        result.append(self.indent('class %s:%s\n' % (name, tail)))
            # Fix #2
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.200">
def return_two_lists(s):
    # pylint: disable=no-else-return
    if 1:
        return aList
    else:
        return list(self.regex.finditer(s))
</t>
<t tx="ekr.20160318141204.21"># 2: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list)
# 3: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list,
#                expr? returns)

def do_FunctionDef(self, node):
    '''Format a FunctionDef node.'''
    result = []
    if node.decorator_list:
        for z in node.decorator_list:
            result.append('@%s\n' % self.visit(z))
    name = node.name  # Only a plain string is valid.
    args = self.visit(node.args) if node.args else ''
    if getattr(node, 'returns', None):  # Python 3.
        returns = self.visit(node.returns)
        result.append(self.indent('def %s(%s): -&gt; %s\n' % (name, args, returns)))
    else:
        result.append(self.indent('def %s(%s):\n' % (name, args)))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.22">def do_Interactive(self, node):
    for z in node.body:
        self.visit(z)

</t>
<t tx="ekr.20160318141204.23">def do_Module(self, node):
    assert 'body' in node._fields
    result = ''.join([self.visit(z) for z in node.body])
    return result  # 'module:\n%s' % (result)

</t>
<t tx="ekr.20160318141204.24">def do_Lambda(self, node):
    return self.indent('lambda %s: %s' % (
        self.visit(node.args),
        self.visit(node.body)))
</t>
<t tx="ekr.20160318141204.25">
# Expressions...

</t>
<t tx="ekr.20160318141204.26">def do_Expr(self, node):
    '''An outer expression: must be indented.'''
    return self.indent('%s\n' % self.visit(node.value))

</t>
<t tx="ekr.20160318141204.27">def do_Expression(self, node):
    '''An inner expression: do not indent.'''
    return '%s\n' % self.visit(node.body)

</t>
<t tx="ekr.20160318141204.28">def do_GeneratorExp(self, node):
    elt = self.visit(node.elt) or ''
    gens = [self.visit(z) for z in node.generators]
    gens = [z if z else '&lt;**None**&gt;' for z in gens]  # Kludge: probable bug.
    return '&lt;gen %s for %s&gt;' % (elt, ','.join(gens))

</t>
<t tx="ekr.20160318141204.29">def do_AugLoad(self, node):
    return 'AugLoad'

def do_Del(self, node):
    return 'Del'

def do_Load(self, node):
    return 'Load'

def do_Param(self, node):
    return 'Param'

def do_Store(self, node):
    return 'Store'
</t>
<t tx="ekr.20160318141204.30">
# Operands...

</t>
<t tx="ekr.20160318141204.31"># 2: arguments = (expr* args, identifier? vararg, identifier? kwarg, expr* defaults)
# 3: arguments = (arg*  args, arg? vararg,
#                arg* kwonlyargs, expr* kw_defaults,
#                arg? kwarg, expr* defaults)

def do_arguments(self, node):
    '''Format the arguments node.'''
    kind = self.kind(node)
    assert kind == 'arguments', kind
    args = [self.visit(z) for z in node.args]
    defaults = [self.visit(z) for z in node.defaults]
    # Assign default values to the last args.
    args2 = []
    n_plain = len(args) - len(defaults)
    for i in range(len(args)):
        if i &lt; n_plain:
            args2.append(args[i])
        else:
            args2.append('%s=%s' % (args[i], defaults[i - n_plain]))
    if isPython3:
        args = [self.visit(z) for z in node.kwonlyargs]
        defaults = [self.visit(z) for z in node.kw_defaults]
        n_plain = len(args) - len(defaults)
        for i in range(len(args)):
            if i &lt; n_plain:
                args2.append(args[i])
            else:
                args2.append('%s=%s' % (args[i], defaults[i - n_plain]))
        # Add the vararg and kwarg expressions.
        vararg = getattr(node, 'vararg', None)
        if vararg: args2.append('*' + self.visit(vararg))
        kwarg = getattr(node, 'kwarg', None)
        if kwarg: args2.append('**' + self.visit(kwarg))
    else:
        # Add the vararg and kwarg names.
        name = getattr(node, 'vararg', None)
        if name: args2.append('*' + name)
        name = getattr(node, 'kwarg', None)
        if name: args2.append('**' + name)
    return ','.join(args2)
</t>
<t tx="ekr.20160318141204.32"># 3: arg = (identifier arg, expr? annotation)

def do_arg(self, node):
    if getattr(node, 'annotation', None):
        return '%s: %s' % (node.arg, self.visit(node.annotation))
    return node.arg
</t>
<t tx="ekr.20160318141204.33"># Attribute(expr value, identifier attr, expr_context ctx)

def do_Attribute(self, node):
    return '%s.%s' % (
        self.visit(node.value),
        node.attr)  # Don't visit node.attr: it is always a string.

</t>
<t tx="ekr.20160318141204.34">def do_Bytes(self, node):  # Python 3.x only.
    return str(node.s)

</t>
<t tx="ekr.20160318141204.35"># Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)

def do_Call(self, node):
    func = self.visit(node.func)
    args = [self.visit(z) for z in node.args]
    for z in node.keywords:
        # Calls f.do_keyword.
        args.append(self.visit(z))
    if getattr(node, 'starargs', None):
        args.append('*%s' % (self.visit(node.starargs)))
    if getattr(node, 'kwargs', None):
        args.append('**%s' % (self.visit(node.kwargs)))
    args = [z for z in args if z]  # Kludge: Defensive coding.
    return '%s(%s)' % (func, ','.join(args))

</t>
<t tx="ekr.20160318141204.36"># keyword = (identifier arg, expr value)

def do_keyword(self, node):
    # node.arg is a string.
    value = self.visit(node.value)
    # This is a keyword *arg*, not a Python keyword!
    return '%s=%s' % (node.arg, value)

</t>
<t tx="ekr.20160318141204.37">def do_comprehension(self, node):
    result = []
    name = self.visit(node.target)  # A name.
    it = self.visit(node.iter)  # An attribute.
    result.append('%s in %s' % (name, it))
    ifs = [self.visit(z) for z in node.ifs]
    if ifs:
        result.append(' if %s' % (''.join(ifs)))
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.38">def do_Dict(self, node):
    result = []
    keys = [self.visit(z) for z in node.keys]
    values = [self.visit(z) for z in node.values]
    if len(keys) == len(values):
        # result.append('{\n' if keys else '{')
        result.append('{')
        items = []
        for i in range(len(keys)):
            items.append('%s:%s' % (keys[i], values[i]))
        result.append(', '.join(items))
        result.append('}')
        # result.append(',\n'.join(items))
        # result.append('\n}' if keys else '}')
    else:
        print('Error: f.Dict: len(keys) != len(values)\nkeys: %s\nvals: %s' % (
            repr(keys), repr(values)))
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.39">def do_Ellipsis(self, node):
    return '...'

</t>
<t tx="ekr.20160318141204.40">def do_ExtSlice(self, node):
    return ':'.join([self.visit(z) for z in node.dims])

</t>
<t tx="ekr.20160318141204.41">def do_Index(self, node):
    return self.visit(node.value)

</t>
<t tx="ekr.20160318141204.42">def do_List(self, node):
    # Not used: list context.
    # self.visit(node.ctx)
    elts = [self.visit(z) for z in node.elts]
    elts = [z for z in elts if z]  # Defensive.
    return '[%s]' % ','.join(elts)

</t>
<t tx="ekr.20160318141204.43">def do_ListComp(self, node):
    elt = self.visit(node.elt)
    gens = [self.visit(z) for z in node.generators]
    gens = [z if z else '&lt;**None**&gt;' for z in gens]  # Kludge: probable bug.
    return '%s for %s' % (elt, ''.join(gens))

</t>
<t tx="ekr.20160318141204.44">def do_Name(self, node):
    return node.id

def do_NameConstant(self, node):  # Python 3 only.
    s = repr(node.value)
    return 'bool' if s in ('True', 'False') else s

</t>
<t tx="ekr.20160318141204.45">def do_Num(self, node):
    return repr(node.n)

</t>
<t tx="ekr.20160318141204.46">def do_Repr(self, node):  # Python 2.x only
    return 'repr(%s)' % self.visit(node.value)

</t>
<t tx="ekr.20160318141204.47">def do_Slice(self, node):
    lower, upper, step = '', '', ''
    if getattr(node, 'lower', None) is not None:
        lower = self.visit(node.lower)
    if getattr(node, 'upper', None) is not None:
        upper = self.visit(node.upper)
    if getattr(node, 'step', None) is not None:
        step = self.visit(node.step)
    if step:
        return '%s:%s:%s' % (lower, upper, step)
    return '%s:%s' % (lower, upper)

</t>
<t tx="ekr.20160318141204.48">def do_Str(self, node):
    '''This represents a string constant.'''
    return repr(node.s)

</t>
<t tx="ekr.20160318141204.49"># Subscript(expr value, slice slice, expr_context ctx)

def do_Subscript(self, node):
    value = self.visit(node.value)
    the_slice = self.visit(node.slice)
    return '%s[%s]' % (value, the_slice)

</t>
<t tx="ekr.20160318141204.5">def merge_types(a1, a2):
    '''
    a1 and a2 may be strings or lists.
    return a list containing both of them, flattened, without duplicates.
    '''
    # Only useful if visitors could return either lists or strings.
    assert a1 is not None
    assert a2 is not None
    r1 = a1 if isinstance(a1, (list, tuple)) else [a1]
    r2 = a2 if isinstance(a2, (list, tuple)) else [a2]
    return sorted(set(r1 + r2))

</t>
<t tx="ekr.20160318141204.50">def do_Tuple(self, node):
    elts = [self.visit(z) for z in node.elts]
    return '(%s)' % ', '.join(elts)
</t>
<t tx="ekr.20160318141204.51">
# Operators...

</t>
<t tx="ekr.20160318141204.52">def do_BinOp(self, node):
    return '%s%s%s' % (
        self.visit(node.left),
        self.op_name(node.op),
        self.visit(node.right))

</t>
<t tx="ekr.20160318141204.53">def do_BoolOp(self, node):
    op_name = self.op_name(node.op)
    values = [self.visit(z) for z in node.values]
    return op_name.join(values)

</t>
<t tx="ekr.20160318141204.54">def do_Compare(self, node):
    result = []
    lt = self.visit(node.left)
    ops = [self.op_name(z) for z in node.ops]
    comps = [self.visit(z) for z in node.comparators]
    result.append(lt)
    if len(ops) == len(comps):
        for i in range(len(ops)):
            result.append('%s%s' % (ops[i], comps[i]))
    else:
        print('can not happen: ops', repr(ops), 'comparators', repr(comps))
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.55">def do_UnaryOp(self, node):
    return '%s%s' % (
        self.op_name(node.op),
        self.visit(node.operand))

</t>
<t tx="ekr.20160318141204.56">def do_IfExp(self, node):
    return '%s if %s else %s ' % (
        self.visit(node.body),
        self.visit(node.test),
        self.visit(node.orelse))
</t>
<t tx="ekr.20160318141204.57">
# Statements...

</t>
<t tx="ekr.20160318141204.58">def do_Assert(self, node):
    test = self.visit(node.test)
    if getattr(node, 'msg', None):
        message = self.visit(node.msg)
        return self.indent('assert %s, %s' % (test, message))
    return self.indent('assert %s' % test)

</t>
<t tx="ekr.20160318141204.59">def do_Assign(self, node):
    return self.indent('%s=%s\n' % (
        '='.join([self.visit(z) for z in node.targets]),
        self.visit(node.value)))

</t>
<t tx="ekr.20160318141204.60">def do_AugAssign(self, node):
    return self.indent('%s%s=%s\n' % (
        self.visit(node.target),
        self.op_name(node.op),  # Bug fix: 2013/03/08.
        self.visit(node.value)))

</t>
<t tx="ekr.20160318141204.61">def do_Break(self, node):
    return self.indent('break\n')

</t>
<t tx="ekr.20160318141204.62">def do_Continue(self, node):
    return self.indent('continue\n')

</t>
<t tx="ekr.20160318141204.63">def do_Delete(self, node):
    targets = [self.visit(z) for z in node.targets]
    return self.indent('del %s\n' % ','.join(targets))

</t>
<t tx="ekr.20160318141204.64">def do_ExceptHandler(self, node):
    result = []
    result.append(self.indent('except'))
    if getattr(node, 'type', None):
        result.append(' %s' % self.visit(node.type))
    if getattr(node, 'name', None):
        if isinstance(node.name, ast.AST):
            result.append(' as %s' % self.visit(node.name))
        else:
            result.append(' as %s' % node.name)  # Python 3.x.
    result.append(':\n')
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.65">def do_Exec(self, node):  # Python 2.x only
    body = self.visit(node.body)
    args = []  # Globals before locals.
    if getattr(node, 'globals', None):
        args.append(self.visit(node.globals))
    if getattr(node, 'locals', None):
        args.append(self.visit(node.locals))
    if args:
        return self.indent('exec %s in %s\n' % (
            body, ','.join(args)))
    return self.indent('exec %s\n' % (body))

</t>
<t tx="ekr.20160318141204.66">def do_For(self, node):
    result = []
    result.append(self.indent('for %s in %s:\n' % (
        self.visit(node.target),
        self.visit(node.iter))))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        result.append(self.indent('else:\n'))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.67">def do_Global(self, node):
    return self.indent('global %s\n' % (
        ','.join(node.names)))

</t>
<t tx="ekr.20160318141204.68">def do_If(self, node):
    result = []
    result.append(self.indent('if %s:\n' % (
        self.visit(node.test))))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        result.append(self.indent('else:\n'))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.69">def do_Import(self, node):
    names = []
    for fn, asname in self.get_import_names(node):
        if asname:
            names.append('%s as %s' % (fn, asname))
        else:
            names.append(fn)
    return self.indent('import %s\n' % (
        ','.join(names)))

</t>
<t tx="ekr.20160318141204.70">def get_import_names(self, node):
    '''Return a list of the the full file names in the import statement.'''
    result = []
    for ast2 in node.names:
        if self.kind(ast2) == 'alias':
            data = ast2.name, ast2.asname
            result.append(data)
        else:
            print('unsupported kind in Import.names list', self.kind(ast2))
    return result

</t>
<t tx="ekr.20160318141204.71">def do_ImportFrom(self, node):
    names = []
    for fn, asname in self.get_import_names(node):
        if asname:
            names.append('%s as %s' % (fn, asname))
        else:
            names.append(fn)
    return self.indent('from %s import %s\n' % (
        node.module,
        ','.join(names)))
</t>
<t tx="ekr.20160318141204.72"># Nonlocal(identifier* names)

def do_Nonlocal(self, node):

    return self.indent('nonlocal %s\n' % ', '.join(node.names))
</t>
<t tx="ekr.20160318141204.73">def do_Pass(self, node):
    return self.indent('pass\n')

</t>
<t tx="ekr.20160318141204.74">def do_Print(self, node):  # Python 2.x only
    vals = []
    for z in node.values:
        vals.append(self.visit(z))
    if getattr(node, 'dest', None):
        vals.append('dest=%s' % self.visit(node.dest))
    if getattr(node, 'nl', None):
        vals.append('nl=%s' % node.nl)
    return self.indent('print(%s)\n' % (
        ','.join(vals)))

</t>
<t tx="ekr.20160318141204.75">def do_Raise(self, node):
    args = []
    for attr in ('type', 'inst', 'tback'):
        if getattr(node, attr, None) is not None:
            args.append(self.visit(getattr(node, attr)))
    if args:
        return self.indent('raise %s\n' % (
            ','.join(args)))
    return self.indent('raise\n')

</t>
<t tx="ekr.20160318141204.76">def do_Return(self, node):
    if node.value:
        return self.indent('return %s\n' % (
            self.visit(node.value).strip()))
    return self.indent('return\n')

</t>
<t tx="ekr.20160318141204.77"># Starred(expr value, expr_context ctx)

def do_Starred(self, node):

    return '*' + self.visit(node.value)
</t>
<t tx="ekr.20160318141204.79"># Try(stmt* body, excepthandler* handlers, stmt* orelse, stmt* finalbody)

def do_Try(self, node):  # Python 3

    result = []
    result.append(self.indent('try:\n'))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.handlers:
        for z in node.handlers:
            result.append(self.visit(z))
    if node.orelse:
        result.append(self.indent('else:\n'))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    if node.finalbody:
        result.append(self.indent('finally:\n'))
        for z in node.finalbody:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160318141204.80">def do_TryExcept(self, node):
    result = []
    result.append(self.indent('try:\n'))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.handlers:
        for z in node.handlers:
            result.append(self.visit(z))
    if node.orelse:
        result.append('else:\n')
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.81">def do_TryFinally(self, node):
    result = []
    result.append(self.indent('try:\n'))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    result.append(self.indent('finally:\n'))
    for z in node.finalbody:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.82">def do_While(self, node):
    result = []
    result.append(self.indent('while %s:\n' % (
        self.visit(node.test))))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        result.append('else:\n')
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.83"># 2:  With(expr context_expr, expr? optional_vars,
#          stmt* body)
# 3:  With(withitem* items,
#          stmt* body)
# withitem = (expr context_expr, expr? optional_vars)

def do_With(self, node):
    result = []
    result.append(self.indent('with '))
    vars_list = []
    if getattr(node, 'context_expression', None):
        result.append(self.visit(node.context_expresssion))
    if getattr(node, 'optional_vars', None):
        try:
            for z in node.optional_vars:
                vars_list.append(self.visit(z))
        except TypeError:  # Not iterable.
            vars_list.append(self.visit(node.optional_vars))
    if getattr(node, 'items', None):  # Python 3.
        for item in node.items:
            result.append(self.visit(item.context_expr))
            if getattr(item, 'optional_vars', None):
                try:
                    for z in item.optional_vars:
                        vars_list.append(self.visit(z))
                except TypeError:  # Not iterable.
                    vars_list.append(self.visit(item.optional_vars))
    result.append(','.join(vars_list))
    result.append(':\n')
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    result.append('\n')
    return ''.join(result)
</t>
<t tx="ekr.20160318141204.84">def do_Yield(self, node):
    if getattr(node, 'value', None):
        return self.indent('yield %s\n' % (
            self.visit(node.value)))
    return self.indent('yield\n')
</t>
<t tx="ekr.20160318141204.85"># YieldFrom(expr value)

def do_YieldFrom(self, node):

    return self.indent('yield from %s\n' % (
        self.visit(node.value)))
</t>
<t tx="ekr.20160318141204.86">
# Utils...

</t>
<t tx="ekr.20160318141204.87">def kind(self, node):
    '''Return the name of node's class.'''
    return node.__class__.__name__
</t>
<t tx="ekr.20160318141204.88">def indent(self, s):
    return '%s%s' % (' ' * 4 * self.level, s)
</t>
<t tx="ekr.20160318141204.89">@nobeautify

def op_name(self, node, strict=True):
    '''Return the print name of an operator node.'''
    d = {
        # Binary operators.
        'Add': '+',
        'BitAnd': '&amp;',
        'BitOr': '|',
        'BitXor': '^',
        'Div': '/',
        'FloorDiv': '//',
        'LShift': '&lt;&lt;',
        'Mod': '%',
        'Mult': '*',
        'Pow': '**',
        'RShift': '&gt;&gt;',
        'Sub': '-',
        # Boolean operators.
        'And': ' and ',
        'Or': ' or ',
        # Comparison operators
        'Eq': '==',
        'Gt': '&gt;',
        'GtE': '&gt;=',
        'In': ' in ',
        'Is': ' is ',
        'IsNot': ' is not ',
        'Lt': '&lt;',
        'LtE': '&lt;=',
        'NotEq': '!=',
        'NotIn': ' not in ',
        # Context operators.
        'AugLoad': '&lt;AugLoad&gt;',
        'AugStore': '&lt;AugStore&gt;',
        'Del': '&lt;Del&gt;',
        'Load': '&lt;Load&gt;',
        'Param': '&lt;Param&gt;',
        'Store': '&lt;Store&gt;',
        # Unary operators.
        'Invert': '~',
        'Not': ' not ',
        'UAdd': '+',
        'USub': '-',
    }
    name = d.get(self.kind(node), '&lt;%s&gt;' % node.__class__.__name__)
    if strict: assert name, self.kind(node)
    return name
</t>
<t tx="ekr.20160330201030.1">Metadata-Version: 1.0
Name: make_stub_files
Version: 0.1
Summary: make stub files for mypy
Home-page: https://github.com/edreamleo/make-stub-files
Author: Edward K. Ream
Author-email: edreamleo@gmail.com
License: MIT
Description:
    Usage: make_stub_files.py [options] file1, file2, ...
    
    Options:
      -h, --help          show this help message and exit
      -c FN, --config=FN  full path to configuration file
      -d DIR, --dir=DIR   full path to the output directory
      -o, --overwrite     overwrite existing stub (.pyi) files
      -t, --test          run unit tests on startup
      --trace-matches     trace Pattern.matches
      --trace-patterns    trace pattern creation
      --trace-reduce      trace st.reduce_types
      --trace-visitors    trace visitor methods
      -u, --update        update stubs in existing stub file
      -v, --verbose       verbose output in .pyi file
      -w, --warn          warn about unannotated args

Download URL: https://github.com/edreamleo/make-stub-files
Keywords: mypy, type checking, stub, Python
Platform: Windows, Linux, MacOS
Categories:
    Development Status :: 4 - Beta
    License :: OSI Approved :: MIT License
    Operating System :: MacOS
    Operating System :: Microsoft :: Windows
    Operating System :: POSIX :: Linux
    Programming Language :: Python
    Topic :: Software Development
</t>
<t tx="ekr.20160630100214.1">class aClass:
    aList = []
    def foo(self):
        print(self.aList)

class aClass2:
    def __init__(self):
        self.aList = []
    def foo(self):
        print(self.aList)
        
i1, i2 = aClass(), aClass2()
i1.foo()
i2.foo()

</t>
<t tx="ekr.20180706071540.1">@language rest
@wrap

https://github.com/edreamleo/make-stub-files/issues/2

Added --silent flag.
Added "tail" logic in st.visit_ClassDef and f.ClassDef.
Added two new unit tests.

@language python</t>
<t tx="ekr.20180706073205.1">### To be deleted.
@nosearch</t>
<t tx="ekr.20180706073424.1"># pyflakes complains about the TestClass class.</t>
<t tx="ekr.20180831102536.1">@language rest
@wrap

https://github.com/edreamleo/make-stub-files/issues/3

Input:

class UnsupportedAlgorithm(Exception):
    def __init__(self, message: Any, reason: Optional[str]=None) -&gt; None:
        pass

Output:

class UnsupportedAlgorithm(Exception):
    def __init__(self, message: Any: Any, reason: Optional[str]: Any=None) -&gt; None: ...
    
Expected output:

class UnsupportedAlgorithm(Exception):
    def __init__(self, message: Any, reason: Optional[str]=None) -&gt; None: ...

@language python
</t>
<t tx="ekr.20180901040718.1">def test_bug2_empty(self):
    # https://github.com/edreamleo/make-stub-files/issues/2
    tag = 'test_bug2_empty'
    s = 'class InvalidTag(Exception):\n    pass'
    controller = Controller()
    node = ast.parse(s, filename=tag, mode='exec')
    st = StubTraverser(controller=controller)
    # From StubTraverser.run.
    st.parent_stub = Stub(kind='root', name='&lt;new-stubs&gt;')
    st.visit(node)
    # Allocate a StringIo file for output_stubs.
    st.output_file = io.StringIO()
    st.output_stubs(st.parent_stub)
    s = st.output_file.getvalue()
    lines = g.splitLines(s)
    # Test.
    expected = ['class InvalidTag(Exception): ...\n']
    self.assertEqual(lines, expected)
</t>
<t tx="ekr.20180901044640.1">def test_bug2_non_empty(self):
    # https://github.com/edreamleo/make-stub-files/issues/2
    commands = [
        # 'cls',
        'python make_stub_files.py -o -s bug2a.py',
    ]
    g.execute_shell_commands(commands, trace=True)
    with open('bug2a.pyi') as f:
        s = f.read()
    lines = g.splitLines(s)
    expected = 'class NonEmptyClass:\n'
    got = lines[1]
    self.assertEqual(got, expected)
</t>
<t tx="ekr.20180901050914.1"></t>
<t tx="ekr.20180901051603.1">def test_bug3(self):
    # https://github.com/edreamleo/make-stub-files/issues/3
    commands = [
        # 'cls',
        'python make_stub_files.py -c make_stub_files.cfg -o -s bug3.py',
    ]
    g.execute_shell_commands(commands, trace=True)
    with open('bug3.pyi') as f:
        s = f.read()
    lines = g.splitLines(s)
    # Test only the last two linse of the generated .pyi file.
    got = ''.join(lines[-2:])
    # The input file
    expected = (
        'class UnsupportedAlgorithm(Exception):\n'
        '    def __init__(self, message: Any, reason: Optional[str]=None) -&gt; None: ...\n'
    )
    self.assertEqual(got, expected)
</t>
<t tx="ekr.20200402143651.1"></t>
<t tx="ekr.20210803055042.1">class TestMakeStubFiles(unittest.TestCase):
    """Unit tests for make_stub_files"""
    @others</t>
<t tx="ekr.20210803060400.1"></t>
<t tx="ekr.20210803131252.1">@language rest
@wrap

https://github.com/edreamleo/make-stub-files/issues/13

@language python
</t>
<t tx="ekr.20210803131439.1">@language rest
@wrap

https://github.com/edreamleo/make-stub-files/issues/13

*** Remove all bug*.pyi files.
*** Fix failing unit test.
*** Create coverage tests: Suppress coverage of tests themselves.

Later:
- Rewrite the readme.
- Why are there two .cfg files??

@language python
@nosearch</t>
<t tx="ekr.20210804020706.1">g.cls()
command = r"python -m pytest --cov-report html --cov-report term-missing --cov make_stub_files make_stub_files.py"
g.execute_shell_commands(command, trace=False)
</t>
<t tx="ekr.20210804021331.1">g.cls()
"""Run make_stub_files with the given set of arguments."""
cfg = r'c:\users\Edward~1\make_stub_files.cfg'
msf = 'make_stub_files.py'
src = 'make_stub_files.py'
command = f"python {msf} -c {cfg} -o -v {src}"
g.execute_shell_commands(command, trace=False)</t>
<t tx="ekr.20210804025215.1">c.backup_helper(sub_dir='MakeStubFiles')
</t>
<t tx="ekr.20210804060105.1">g.cls()
test = '.TestMakeStubFiles.test_bug2_empty' # Run all tests.
command = f"python -m unittest make_stub_files{test}"
g.execute_shell_commands(command, trace=False)</t>
<t tx="ekr.20210804070157.1"></t>
<t tx="ekr.20210804103146.1">def test_pattern_class(self):
    g = LeoGlobals() # Use the g available to the script.
    table = (
        # s,  Pattern.find_s, Pattern.repl_s, expected
        ('aabbcc', '(a+)(b+)(c+)$', r'\3\2\1', 'ccbbaa'),
        ('[str]', r'\[str\]$', 'xxx', 'xxx'), # Guido bug.
        ('s3', r's[1-3]?\b$', 'str', 'str'), # lengthening bug.
        ('s', 's', 'str', 'str'),
        ('abc', 'abc', 'ABC', 'ABC'),
        ('str(str)', 'str(*)', 'str', 'str'),
        ('[whatever]', '[*]', 'List[*]', 'List[whatever]'), # * on the RHS.
        ('(int,str)', '(*)', 'Tuple[*]', 'Tuple[int,str]'), # Guido bug 2.
        ('abcxyz', 'abc*', 'xxx', 'xxx'), # New test for trailing *.
        ('list(self.regex.finditer(str))','list(*)','List[*]',
         'List[self.regex.finditer(str)]'),
    )
    for s, find, repl, expected in table:
        pattern = Pattern(find, repl)
        result = pattern.match_entire_string(s)
        self.assertTrue(result, msg=repr(s))
        aList = pattern.all_matches(s)
        self.assertTrue(len(aList) == 1, msg=repr(aList))
        found, s2 = pattern.match(s)
        self.assertTrue(found, msg=f"after pattern.match({s!r})")
        assert s2 == expected, (s, pattern, 'expected', expected, 'got', s2)
    p1 = Pattern('abc','xyz')
    p2 = Pattern('abc','xyz')
    p3 = Pattern('abc','pdq')
    self.assertEqual(p1, p2)
    self.assertNotEqual(p1, p3)
    self.assertNotEqual(p2, p3)
    aSet = set()
    aSet.add(p1)
    self.assertTrue(p1 in aSet)
    self.assertTrue(p2 in aSet)
    self.assertFalse(p3 in aSet)
    self.assertEqual(list(aSet), [p1])
    self.assertEqual(list(aSet), [p2])
    aSet.add(p3)
    self.assertTrue(p1.match_entire_string('abc'))
    self.assertFalse(p1.match_entire_string('abcx'))
</t>
<t tx="ekr.20210804104214.1"></t>
<t tx="ekr.20210804105256.1">def test_reduce_numbers(self):
    a, c, f, i, l, n = ('Any', 'complex', 'float', 'int', 'long', 'number')
    table = (
        ([i,i],     [i]),
        ([i],       [i]),
        ([f, i],    [f]),
        ([c, i],    [c]),
        ([l, a],    [a, l]),
    )
    for aList, expected in table:
        got = ReduceTypes().reduce_numbers(aList)
        self.assertEqual(expected, got, msg=repr(aList))
</t>
<t tx="ekr.20210804111613.1">def test_reduce_types(self):

    a, c, f, i, l, n = ('Any', 'complex', 'float', 'int', 'long', 'number')
    none = 'None'
    x = 'xyzzy'
    y = 'pdq'
    table = (
        ([i,i],         i),
        ([i],           i),
        ([f, i],        f),
        ([c, i],        c),
        ([l, a],        'Union[Any, long]'),
        # Handle None
        ([None],        none),
        ([None, None],  none),
        ([None, a, c],  'Optional[Union[Any, complex]]'),
        # Handle unknown types, and special cases
        ([i, x],        'Union[Any, int]'),
        ([None, x],     'Optional[Any]'),
        ([none, x],     'Optional[Any]'),
        (['', x],       'Optional[Any]'),
        ([none, x, c],  'Optional[Union[Any, complex]]'),
        ([x, y],        'Any'),
        # Collection merging.  More could be done...
        (['Dict[int, str]', 'Dict[Any, str]'],          'Union[Dict[Any, str], Dict[int, str]]'),
        (['List[int, str]', 'List[Any, str]'],          'Union[List[Any, str], List[int, str]]'),
        (['Union[int, str]', 'Union[Any, str]'],        'Union[Union[Any, str], Union[int, str]]'),
        (['Union[int, str]', 'int', 'Union[Any, str]'], 'Union[Union[Any, str], Union[int, str], int]'),
        (['Tuple[xyz, pdq]'],                           'Tuple[Any, Any]'),
    )
    for aList, expected in table:
        got = ReduceTypes(aList).reduce_types()
        self.assertEqual(expected, got, msg=repr(aList))
</t>
<t tx="ekr.20210804111803.1">def test_split_types(self):
    table = (
        ('list',                    ['list']),
        ('List[a,b]',               ['List[a,b]']),
        ('List[a,b], List[c,d]',    ['List[a,b]', 'List[c,d]']),
    )
    for s, expected in table:
        got = ReduceTypes().split_types(s)
        self.assertEqual(expected, got, msg=repr(s))
</t>
<t tx="ekr.20210804111915.1">def test_st_find(self):

    s = '''\
def is_known_type(s: str) -&gt; Union[Any,bool]: ...
def main() -&gt; None: ...
def merge_types(a1: Any, a2: Any) -&gt; str: ...

class AstFormatter:
    def format(self, node: Node) -&gt; Union[Any,str]: ...
        def helper(self): -&gt; None
    def visit(self, node: Node) -&gt; str: ...
    def do_ClassDef(self, node: Node) -&gt; str: ...
    def do_FunctionDef(self, node: Node) -&gt; str: ...
'''
    g = LeoGlobals() # Use the g available to the script.
    st = StubTraverser(controller=g.NullObject())
    d, root = st.parse_stub_file(s, root_name='&lt;root&gt;')  # Root *is* used below.
    if 0:
        print(st.trace_stubs(root, header='root'))
    stub1 = Stub(kind='class', name='AstFormatter')
    stub2 = Stub(kind='def', name='format', parent=stub1, stack=['AstFormatter'])
    stub3 = Stub(kind='def', name='helper', parent = stub2, stack=['AstFormatter', 'format'])
    # stub4 = Stub(kind='def', name='main')
    for stub in (stub1, stub2, stub3,):  # (stub1, stub2, stub3):
        found = st.find_stub(stub, root)
        id_found = found and id(found) or None
        if 0:
            print('found  %s =&gt; %9s %35s ==&gt; %s' % (id(stub), id_found, stub, found))
        found = st.find_parent_stub(stub, root)
        id_found = found and id(found) or None
        if 0:
            print('parent %s =&gt; %9s %35s ==&gt; %s' % (id(stub), id_found, stub, found))
</t>
<t tx="ekr.20210804112211.1">def test_st_flatten_stubs(self):
    s = '''\
    def is_known_type(s: str) -&gt; Union[Any,bool]: ...
    def main() -&gt; None: ...
    def merge_types(a1: Any, a2: Any) -&gt; str: ...
    
    class AstFormatter:
        def format(self, node: Node) -&gt; Union[Any,str]: ...
            def helper(self): -&gt; None
        def visit(self, node: Node) -&gt; str: ...
        def do_ClassDef(self, node: Node) -&gt; str: ...
        def do_FunctionDef(self, node: Node) -&gt; str: ...
    '''
    g = LeoGlobals()  # Use the g available to the script.
    st = StubTraverser(controller=g.NullObject())
    d, root = st.parse_stub_file(s, root_name='&lt;root&gt;')
    if 0:
        print(st.trace_stubs(root, header='root'))
    aList = st.flatten_stubs(root)
    self.assertTrue(aList)
    if 0:
        for i, stub in enumerate(aList):
            print('%2s %s' % (i, stub))
    for stub in aList:
        found = st.find_stub(stub, root)
        self.assertTrue(found, msg=repr(stub))
</t>
<t tx="ekr.20210804112405.1">def test_st_merge_stubs(self):
    # To do:
    # - Test between-stub lines and leading lines.
    # - Round-trip tests!
    &lt;&lt; old_stubs &gt;&gt;
    &lt;&lt; new_stubs &gt;&gt;
    g = LeoGlobals() # Use the g available to the script.
    st = StubTraverser(controller=g.NullObject())
    # dump('old_s', old_s)
    # dump('new_s', new_s)
    old_d, old_root = st.parse_stub_file(old_s, root_name='&lt;old-root&gt;')
    new_d, new_root = st.parse_stub_file(new_s, root_name='&lt;new-root&gt;')
    if 0:
        dump_dict('old_d', old_d)
        dump_dict('new_d', new_d)
        print(st.trace_stubs(old_root, header='trace_stubs(old_root)'))
        print(st.trace_stubs(new_root, header='trace_stubs(new_root)'))
    if 0:  # separate unit test. Passed.
        aList = st.sort_stubs_by_hierarchy(new_root)
        dump_list(aList, 'after sort_stubs_by_hierarcy')
    new_stubs = new_d.values()
    st.merge_stubs(new_stubs, old_root, new_root, trace=False)
    if 0:
        print(st.trace_stubs(old_root, header='trace_stubs(old_root)'))
</t>
<t tx="ekr.20210804112405.3"># To be INSERTED (They exist in new stubs, but not here.)
# def is_known_type(s: str) -&gt; Union[Any,bool]: ...
# def reduce_numbers(aList: List[Any]) -&gt; List[Any]: ...
# class AstFormatter:
    # def format(self, node: Node) -&gt; Union[Any,str]: ...
    # def visit(self, node: Node) -&gt; str: ...
    # def do_ClassDef(self, node: Node) -&gt; str: ...
    # def do_FunctionDef(self, node: Node) -&gt; str: ...
old_s = '''\
def main() -&gt; None: ...
def merge_types(a1: Any, a2: Any) -&gt; str: ...
def pdb(self) -&gt; None: ...
def reduce_types(aList: List[Any], name: str=None, trace: bool=False) -&gt; Any: ...
class Pattern(object):
    def __init__(self, find_s: str, repl_s: str='') -&gt; None: ...
    def __eq__(self, obj: Any) -&gt; bool: ...
    def __ne__(self, obj: Any) -&gt; bool: ...
    def __hash__(self) -&gt; int: ...
    def __repr__(self) -&gt; str: ...
    def is_balanced(self) -&gt; bool: ...
    def is_regex(self) -&gt; Any: ...
        #   0: return self.find_s.endswith('$')
        # ? 0: return self.find_s.endswith(str)
'''
</t>
<t tx="ekr.20210804112405.4"># To be DELETED (They exist in old_stubs, but not here)
# class Pattern(object):
    # def __init__(self, find_s: str, repl_s: str='') -&gt; None: ...
    # def __eq__(self, obj: Any) -&gt; bool: ...
    # def __ne__(self, obj: Any) -&gt; bool: ...
    # def __hash__(self) -&gt; int: ...
    # def __repr__(self) -&gt; str: ...
    # def is_balanced(self) -&gt; bool: ...
    # def is_regex(self) -&gt; Any: ...
        # #   0: return self.find_s.endswith('$')
        # # ? 0: return self.find_s.endswith(str)
new_s = '''\
def is_known_type(s: str) -&gt; Union[Any,bool]: ...
def main() -&gt; None: ...
def merge_types(a1: Any, a2: Any) -&gt; str: ...
def pdb(self) -&gt; None: ...
def reduce_numbers(aList: List[Any]) -&gt; List[Any]: ...
def reduce_types(aList: List[Any], name: str=None, trace: bool=False) -&gt; Any: ...

class AstFormatter:
    def format(self, node: Node) -&gt; Union[Any,str]: ...
    def visit(self, node: Node) -&gt; str: ...
    def do_ClassDef(self, node: Node) -&gt; str: ...
    def do_FunctionDef(self, node: Node) -&gt; str: ...
'''
</t>
<t tx="ekr.20210804112556.1">def test_stub_class(self):
    g = LeoGlobals()  # Use the g available to the script.
    # Test equality...
    stub1 = Stub(kind='def', name='foo')
    stub2 = Stub(kind='class', name='foo')
    stub3 = Stub(kind='def', name='bar')
    stub4 = Stub(kind='def', name='foo')
    stub4.out_list = ['xyzzy']  # Contents of out_list must not affect equality!
    aList = [stub1, stub3]
    self.assertNotEqual(stub1, stub2)
    self.assertNotEqual(stub1, stub3)
    self.assertEqual(stub1, stub4)
    self.assertTrue(stub1 in aList)
    self.assertFalse(stub2 in aList)
    self.assertTrue(stub3 in aList)
    # Test __hash__
    d = {stub1: 'stub1'}
    self.assertTrue(stub1 in d)
    self.assertFalse(stub2 in d)
    # Test parents and level.
    stub_1 = Stub(kind='def', name='stub_1')
    stub_2 = Stub(kind='def', name='stub_2', parent=stub_1, stack=['stub_1'])
    stub_3 = Stub(kind='def', name='stub_3', parent=stub_2, stack=['stub_1', 'stub_2'])
    self.assertEqual(stub_1.parents(), [], msg=repr(stub_1.parents()))
    self.assertEqual(stub_2.parents(), ['stub_1'], msg=repr(stub_2.parents()))
    self.assertEqual(stub_3.parents(), ['stub_1', 'stub_2'], msg=repr(stub_3.parents()))
    self.assertEqual(stub_1.level(), 0)
    self.assertEqual(stub_2.level(), 1)
    self.assertEqual(stub_3.level(), 2)
</t>
<t tx="ekr.20210804153200.1">"""Convert all following @test nodes."""
g.cls()

def body(p):
    def_s = f"def {headline(p)}(self):\n"
    lines = [' '*4 + z.rstrip()+'\n' for z in g.splitLines(p.b) if '@others' not in z]
    return def_s + ''.join(lines)

def headline(p):
    return p.h[1:].replace('-','_').replace(' ','_').replace('__', '_')

while p:
    if p.h.startswith('@test'):
        if 1:  # Change.
            print(p.h)
            p.b = body(p)  # body first, to use original headline.
            p.h = headline(p)
            p.setDirty()
        else:  # Report.
            h = headline(p)
            b = body(p)
            print(h.rstrip())
            print(b.rstrip())
            print('-'*40)
    p.moveToThreadNext()
c.redraw()
</t>
<t tx="ekr.20210804161223.1"># Found 3 marked nodes</t>
<t tx="ekr.20210804170546.1">@ignore
@nosearch
HEAD=f014a40</t>
<t tx="ekr.20210804170546.10"></t>
<t tx="ekr.20210804170546.11">@ignore
@nosearch
@language patch
--- HEAD
+++ uncommitted
@@ -3,11 +3,9 @@
 
 https://github.com/edreamleo/make-stub-files/issues/13
 
-Create coverage tests:
-- For *Formatter classes.
-- For ReduceTypes class.
-- For Stub* classes.
-- Convert all old tests.
+*** Remove all bug*.pyi files.
+*** Fix failing unit test.
+*** Create coverage tests: Suppress coverage of tests themselves.
 
 Later:
 - Rewrite the readme.
@language python
</t>
<t tx="ekr.20210804170546.12">@language rest
@wrap

https://github.com/edreamleo/make-stub-files/issues/13

Create coverage tests:
- For *Formatter classes.
- For ReduceTypes class.
- For Stub* classes.
- Convert all old tests.

Later:
- Rewrite the readme.
- Why are there two .cfg files??

@language python
@nosearch</t>
<t tx="ekr.20210804170546.13">@ignore
@nosearch
@language patch
--- HEAD
+++ uncommitted
@@ -1,4 +1,4 @@
 g.cls()
-test = '' # Run all tests.
+test = '.TestMakeStubFiles.test_bug2_empty' # Run all tests.
 command = f"python -m unittest make_stub_files{test}"
 g.execute_shell_commands(command, trace=False)@language python
</t>
<t tx="ekr.20210804170546.14">g.cls()
test = '' # Run all tests.
command = f"python -m unittest make_stub_files{test}"
g.execute_shell_commands(command, trace=False)</t>
<t tx="ekr.20210804170546.15">@ignore
@nosearch
@language patch
--- HEAD
+++ uncommitted
@@ -1,13 +1,18 @@
 def test_bug2_empty(self):
     # https://github.com/edreamleo/make-stub-files/issues/2
-    commands = [
-        # 'cls',
-        'python make_stub_files.py -o -s bug2.py',
-    ]
-    g.execute_shell_commands(commands, trace=True)
-    with open('bug2.pyi') as f:
-        s = f.read()
+    tag = 'test_bug2_empty'
+    s = 'class InvalidTag(Exception):\n    pass'
+    controller = Controller()
+    node = ast.parse(s, filename=tag, mode='exec')
+    st = StubTraverser(controller=controller)
+    # From StubTraverser.run.
+    st.parent_stub = Stub(kind='root', name='&lt;new-stubs&gt;')
+    st.visit(node)
+    # Allocate a StringIo file for output_stubs.
+    st.output_file = io.StringIO()
+    st.output_stubs(st.parent_stub)
+    s = st.output_file.getvalue()
     lines = g.splitLines(s)
-    expected = 'class InvalidTag(Exception): ...\n'
-    got = lines[1]
-    self.assertEqual(got, expected)
+    # Test.
+    expected = ['class InvalidTag(Exception): ...\n']
+    self.assertEqual(lines, expected)
@language python
</t>
<t tx="ekr.20210804170546.16">def test_bug2_empty(self):
    # https://github.com/edreamleo/make-stub-files/issues/2
    commands = [
        # 'cls',
        'python make_stub_files.py -o -s bug2.py',
    ]
    g.execute_shell_commands(commands, trace=True)
    with open('bug2.pyi') as f:
        s = f.read()
    lines = g.splitLines(s)
    expected = 'class InvalidTag(Exception): ...\n'
    got = lines[1]
    self.assertEqual(got, expected)
</t>
<t tx="ekr.20210804170546.17">@ignore
@nosearch
@language patch
--- HEAD
+++ uncommitted
@@ -10,5 +10,4 @@
     lines = g.splitLines(s)
     expected = 'class NonEmptyClass:\n'
     got = lines[1]
-    ### assert got == expected, 'expected: %r\ngot:    %r' % (expected, got)
     self.assertEqual(got, expected)
@language python
</t>
<t tx="ekr.20210804170546.18">def test_bug2_non_empty(self):
    # https://github.com/edreamleo/make-stub-files/issues/2
    commands = [
        # 'cls',
        'python make_stub_files.py -o -s bug2a.py',
    ]
    g.execute_shell_commands(commands, trace=True)
    with open('bug2a.pyi') as f:
        s = f.read()
    lines = g.splitLines(s)
    expected = 'class NonEmptyClass:\n'
    got = lines[1]
    ### assert got == expected, 'expected: %r\ngot:    %r' % (expected, got)
    self.assertEqual(got, expected)
</t>
<t tx="ekr.20210804170546.19">@ignore
@nosearch
@language patch
--- HEAD
+++ uncommitted
@@ -34,12 +34,6 @@
     import StringIO as io  # Python 2
 except ImportError:
     import io  # Python 3
-###
-    # # Third party imports.
-    # try:
-        # import pytest
-    # except Exception:
-        # pytest = None  # type:ignore
 #@-&lt;&lt; imports &gt;&gt;
 isPython3 = sys.version_info &gt;= (3, 0, 0)
 #@+others
@@ -2784,20 +2778,25 @@
 class TestMakeStubFiles(unittest.TestCase):
     """Unit tests for make_stub_files"""
     #@+others
-    #@+node:ekr.20180901040718.1: *3* test_bug2_empty (revise)
+    #@+node:ekr.20180901040718.1: *3* test_bug2_empty (rewritten)
     def test_bug2_empty(self):
         # https://github.com/edreamleo/make-stub-files/issues/2
-        commands = [
-            # 'cls',
-            'python make_stub_files.py -o -s bug2.py',
-        ]
-        g.execute_shell_commands(commands, trace=True)
-        with open('bug2.pyi') as f:
-            s = f.read()
+        tag = 'test_bug2_empty'
+        s = 'class InvalidTag(Exception):\n    pass'
+        controller = Controller()
+        node = ast.parse(s, filename=tag, mode='exec')
+        st = StubTraverser(controller=controller)
+        # From StubTraverser.run.
+        st.parent_stub = Stub(kind='root', name='&lt;new-stubs&gt;')
+        st.visit(node)
+        # Allocate a StringIo file for output_stubs.
+        st.output_file = io.StringIO()
+        st.output_stubs(st.parent_stub)
+        s = st.output_file.getvalue()
         lines = g.splitLines(s)
-        expected = 'class InvalidTag(Exception): ...\n'
-        got = lines[1]
-        self.assertEqual(got, expected)
+        # Test.
+        expected = ['class InvalidTag(Exception): ...\n']
+        self.assertEqual(lines, expected)
     #@+node:ekr.20180901044640.1: *3* test_bug2_non_empty (revise)
     def test_bug2_non_empty(self):
         # https://github.com/edreamleo/make-stub-files/issues/2
@@ -2811,7 +2810,6 @@
         lines = g.splitLines(s)
         expected = 'class NonEmptyClass:\n'
         got = lines[1]
-        ### assert got == expected, 'expected: %r\ngot:    %r' % (expected, got)
         self.assertEqual(got, expected)
     #@+node:ekr.20180901051603.1: *3* test_bug3 (FAILS) (revise)
     def test_bug3(self):
@language python
</t>
<t tx="ekr.20210804170546.2">@ignore
@nosearch
@language patch
--- HEAD
+++ uncommitted
@@ -28,6 +28,7 @@
 &lt;/v&gt;
 &lt;/v&gt;
 &lt;v t="ekr.20160207105710.1"&gt;&lt;vh&gt;@@@button check-leading-lines&lt;/vh&gt;&lt;/v&gt;
+&lt;v t="ekr.20210804153200.1"&gt;&lt;vh&gt;script convert-at-test&lt;/vh&gt;&lt;/v&gt;
 &lt;/v&gt;
 &lt;v t="ekr.20160126153016.3"&gt;&lt;vh&gt;Unused&lt;/vh&gt;
 &lt;v t="ekr.20160206104033.1"&gt;&lt;vh&gt;@@test run all msf unit tests&lt;/vh&gt;&lt;/v&gt;
@@ -196,7 +197,6 @@
 &lt;v t="ekr.20160207101607.1"&gt;&lt;vh&gt;@clean theory.md&lt;/vh&gt;&lt;/v&gt;
 &lt;/v&gt;
 &lt;v t="ekr.20160318141204.1" descendentVnodeUnknownAttributes="7d71005805000000302e362e3571017d71025808000000616e6e6f7461746571037d710473732e"&gt;&lt;vh&gt;@file make_stub_files.py&lt;/vh&gt;&lt;/v&gt;
-&lt;v t="ekr.20160318141204.2"&gt;&lt;vh&gt; &amp;lt;&amp;lt; imports &amp;gt;&amp;gt; (make_stub_files.py)&lt;/vh&gt;&lt;/v&gt;
 &lt;v t="ekr.20210803131439.1"&gt;&lt;vh&gt;=== #10: unit tests&lt;/vh&gt;
 &lt;v t="ekr.20210804104214.1"&gt;&lt;vh&gt;--- no longer used&lt;/vh&gt;
 &lt;v t="ekr.20160318141204.130"&gt;&lt;vh&gt;msf.run_all_unit_tests&lt;/vh&gt;&lt;/v&gt;
@@ -244,9 +244,8 @@
 &lt;/v&gt;
 &lt;/v&gt;
 &lt;/v&gt;
-&lt;v t="ekr.20210804153200.1"&gt;&lt;vh&gt;script convert-at-test&lt;/vh&gt;&lt;/v&gt;
 &lt;v t="ekr.20210803055042.1"&gt;&lt;vh&gt;class TestMakeStubFiles(unittest.TestCase)&lt;/vh&gt;
-&lt;v t="ekr.20180901040718.1"&gt;&lt;vh&gt;test_bug2_empty (revise)&lt;/vh&gt;&lt;/v&gt;
+&lt;v t="ekr.20180901040718.1"&gt;&lt;vh&gt;test_bug2_empty (rewritten)&lt;/vh&gt;&lt;/v&gt;
 &lt;v t="ekr.20180901044640.1"&gt;&lt;vh&gt;test_bug2_non_empty (revise)&lt;/vh&gt;&lt;/v&gt;
 &lt;v t="ekr.20180901051603.1"&gt;&lt;vh&gt;test_bug3 (FAILS) (revise)&lt;/vh&gt;&lt;/v&gt;
 &lt;v t="ekr.20210804103146.1"&gt;&lt;vh&gt;test_pattern_class&lt;/vh&gt;&lt;/v&gt;
@@ -263,6 +262,46 @@
 &lt;v t="ekr.20160207115947.1"&gt;&lt;vh&gt;test_truncate&lt;/vh&gt;
 &lt;v t="ekr.20160207115604.1"&gt;&lt;vh&gt;truncate&lt;/vh&gt;&lt;/v&gt;
 &lt;/v&gt;
+&lt;/v&gt;
+&lt;v t="ekr.20160318141204.128"&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.11"&gt;&lt;vh&gt;main&lt;/vh&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.169"&gt;&lt;vh&gt;class StubTraverser (ast.NodeVisitor)&lt;/vh&gt;
+&lt;v t="ekr.20160318141204.170"&gt;&lt;vh&gt;st.ctor&lt;/vh&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.171"&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.172"&gt;&lt;vh&gt;st.indent &amp;amp; out&lt;/vh&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.173"&gt;&lt;vh&gt;st.run (main line) &amp;amp; helpers&lt;/vh&gt;
+&lt;v t="ekr.20160318141204.174"&gt;&lt;vh&gt;st.output_stubs&lt;/vh&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.175"&gt;&lt;vh&gt;st.output_time_stamp&lt;/vh&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.176"&gt;&lt;vh&gt;st.update &amp;amp; helpers&lt;/vh&gt;
+&lt;v t="ekr.20160318141204.177"&gt;&lt;vh&gt;st.get_stub_file&lt;/vh&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.178"&gt;&lt;vh&gt;st.parse_stub_file&lt;/vh&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.179"&gt;&lt;vh&gt;st.merge_stubs &amp;amp; helpers&lt;/vh&gt;
+&lt;v t="ekr.20160318141204.180"&gt;&lt;vh&gt;st.check_delete&lt;/vh&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.181"&gt;&lt;vh&gt;st.flatten_stubs&lt;/vh&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.182"&gt;&lt;vh&gt;st.find_parent_stub&lt;/vh&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.183"&gt;&lt;vh&gt;st.find_stub&lt;/vh&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.184"&gt;&lt;vh&gt;st.sort_stubs_by_hierarchy&lt;/vh&gt;&lt;/v&gt;
+&lt;/v&gt;
+&lt;v t="ekr.20160318141204.185"&gt;&lt;vh&gt;st.trace_stubs&lt;/vh&gt;&lt;/v&gt;
+&lt;/v&gt;
+&lt;/v&gt;
+&lt;v t="ekr.20160318141204.186"&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.187"&gt;&lt;vh&gt;st.visit_FunctionDef &amp;amp; helpers&lt;/vh&gt;
+&lt;v t="ekr.20160318141204.188"&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.190"&gt;&lt;vh&gt;st.format_returns &amp;amp; helpers&lt;/vh&gt;
+&lt;v t="ekr.20160318141204.191"&gt;&lt;vh&gt;st.format_return_expressions&lt;/vh&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.192"&gt;&lt;vh&gt;st.get_def_name&lt;/vh&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.193"&gt;&lt;vh&gt;st.remove_recursive_calls&lt;/vh&gt;&lt;/v&gt;
+&lt;/v&gt;
+&lt;/v&gt;
+&lt;v t="ekr.20160318141204.194"&gt;&lt;vh&gt;st.visit_Return&lt;/vh&gt;&lt;/v&gt;
+&lt;/v&gt;
+&lt;v t="ekr.20160318141204.173"&gt;&lt;/v&gt;
+&lt;v t="ekr.20160318141204.174"&gt;&lt;/v&gt;
+&lt;v t="ekr.20210804161223.1"&gt;&lt;vh&gt;--- revise tests&lt;/vh&gt;
+&lt;v t="ekr.20180901040718.1"&gt;&lt;/v&gt;
+&lt;v t="ekr.20180901044640.1"&gt;&lt;/v&gt;
+&lt;v t="ekr.20180901051603.1"&gt;&lt;/v&gt;
 &lt;/v&gt;
 &lt;/vnodes&gt;
 &lt;tnodes&gt;
@@ -1585,6 +1624,17 @@
             result.append(z if self.is_known_type(z) else 'Any')
     g.trace(aList, result)
     return result
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.11"&gt;def main():
+    '''
+    The driver for the stand-alone version of make-stub-files.
+    All options come from ~/stubs/make_stub_files.cfg.
+    '''
+    controller = Controller()
+    controller.scan_command_line()
+    controller.scan_options()
+    for fn in controller.files:
+        controller.make_stub_file(fn)
 &lt;/t&gt;
 &lt;t tx="ekr.20160318141204.110"&gt;def match_balanced(self, delim, s, i):
     '''
@@ -2299,12 +2349,58 @@
     assert s.startswith('return'), repr(s)
     return s[len('return') :].strip()
 &lt;/t&gt;
+&lt;t tx="ekr.20160318141204.169"&gt;class StubTraverser(ast.NodeVisitor):
+    '''
+    An ast.Node traverser class that outputs a stub for each class or def.
+    Names of visitors must start with visit_. The order of traversal does
+    not matter, because so few visitors do anything.
+    '''
+    @others
+&lt;/t&gt;
 &lt;t tx="ekr.20160318141204.17"&gt;def format(self, node):
     '''Format the node (or list of nodes) and its descendants.'''
     self.level = 0
     val = self.visit(node)
     # pylint: disable=consider-using-ternary
     return val and val.strip() or ''
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.170"&gt;def __init__(self, controller):
+    '''Ctor for StubTraverser class.'''
+    self.controller = x = controller  # A Controller instance.
+    # Internal state ivars...
+    self.class_name_stack = []
+    self.class_defs_count = 0
+        # The number of defs seen for this class.
+    self.context_stack = []
+    sf = StubFormatter(controller=controller, traverser=self)
+    self.format = sf.format
+    self.arg_format = AstArgFormatter().format
+    self.level = 0
+    self.output_file = None
+    self.parent_stub = None
+    self.raw_format = AstFormatter().format
+    self.returns = []
+    self.stubs_dict = {}
+        # Keys are stub.full_name's.  Values are stubs.
+    self.warn_list = []
+    # Copies of controller ivars...
+    self.output_fn = x.output_fn
+    self.overwrite = x.overwrite
+    self.prefix_lines = x.prefix_lines
+    self.silent = x.silent
+    self.regex_patterns = x.regex_patterns
+    self.update_flag = x.update_flag
+    self.trace_matches = x.trace_matches
+    self.trace_patterns = x.trace_patterns
+    self.trace_reduce = x.trace_reduce
+    self.trace_visitors = x.trace_visitors
+    self.verbose = x.verbose
+    self.warn = x.warn
+    # Copies of controller patterns...
+    self.def_patterns = x.def_patterns
+    self.names_dict = x.names_dict
+    self.general_patterns = x.general_patterns
+    self.patterns_dict = x.patterns_dict
 &lt;/t&gt;
 &lt;t tx="ekr.20160318141204.171"&gt;def add_stub(self, d, stub):
     '''Add the stub to d, checking that it does not exist.'''
@@ -2316,6 +2412,186 @@
         print('%20s: ignoring duplicate entry for %s' % (g_input_file_name, key))
     else:
         d[key] = stub
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.172"&gt;def indent(self, s):
+    '''Return s, properly indented.'''
+    # This version of indent *is* used.
+    return '%s%s' % (' ' * 4 * self.level, s)
+
+def out(self, s):
+    '''Output the string to the console or the file.'''
+    s = self.indent(s)
+    if self.parent_stub:
+        self.parent_stub.out_list.append(s)
+    elif self.output_file:
+        self.output_file.write(s + '\n')
+    else:
+        print(s)
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.173"&gt;def run(self, node):
+    '''StubTraverser.run: write the stubs in node's tree to self.output_fn.'''
+    fn = self.output_fn
+    dir_ = os.path.dirname(fn)
+    if os.path.exists(fn) and not self.overwrite:
+        print('file exists: %s' % fn)
+        return
+    if dir_ and not os.path.exists(dir_):
+        print('output directory not not found: %s' % dir_)
+        return
+    # Create parent_stub.out_list.
+    self.parent_stub = Stub(kind='root', name='&amp;lt;new-stubs&amp;gt;')
+    for z in self.prefix_lines or []:
+        self.parent_stub.out_list.append(z)
+    self.visit(node)
+    if self.update_flag:
+        self.parent_stub = self.update(fn, new_root=self.parent_stub)
+    # Output the stubs.
+    self.output_file = open(fn, 'w')
+    self.output_time_stamp()
+    self.output_stubs(self.parent_stub)
+    self.output_file.close()
+    self.output_file = None
+    self.parent_stub = None
+    if self.verbose:
+        print('wrote: %s' % fn)
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.174"&gt;def output_stubs(self, stub):
+    '''Output this stub and all its descendants.'''
+    for s in stub.out_list or []:
+        # Indentation must be present when an item is added to stub.out_list.
+        if self.output_file:
+            self.output_file.write(s.rstrip() + '\n')
+        else:
+            print(s)
+    # Recursively print all children.
+    for child in stub.children:
+        self.output_stubs(child)
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.175"&gt;def output_time_stamp(self):
+    '''Put a time-stamp in the output file.'''
+    if self.output_file:
+        self.output_file.write('# make_stub_files: %s\n' %
+            time.strftime("%a %d %b %Y at %H:%M:%S"))
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.176"&gt;def update(self, fn, new_root):
+    '''
+    Merge the new_root tree with the old_root tree in fn (a .pyi file).
+
+    new_root is the root of the stub tree from the .py file.
+    old_root (read below) is the root of stub tree from the .pyi file.
+    
+    Return old_root, or new_root if there are any errors.
+    '''
+    s = self.get_stub_file(fn)
+    if not s or not s.strip():
+        return new_root
+    if '\t' in s:
+        # Tabs in stub files make it impossible to parse them reliably.
+        g.trace('Can not update stub files containing tabs.')
+        return new_root
+    # Read old_root from the .pyi file.
+    old_d, old_root = self.parse_stub_file(s, root_name='&amp;lt;old-stubs&amp;gt;')
+    if old_root:
+        # Merge new stubs into the old tree.
+        if 0:
+            print(self.trace_stubs(old_root, header='old_root'))
+            print(self.trace_stubs(new_root, header='new_root'))
+        print('***** updating stubs from %s *****' % fn)
+        self.merge_stubs(self.stubs_dict.values(), old_root, new_root)
+        # print(self.trace_stubs(old_root, header='updated_root'))
+        return old_root
+    return new_root
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.177"&gt;def get_stub_file(self, fn):
+    '''Read the stub file into s.'''
+    if os.path.exists(fn):
+        try:
+            s = open(fn, 'r').read()
+        except Exception:
+            print('--update: error reading %s' % fn)
+            s = None
+        return s
+    print('--update: not found: %s' % fn)
+    return None
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.178"&gt;def parse_stub_file(self, s, root_name):
+    '''
+    Parse s, the contents of a stub file, into a tree of Stubs.
+    
+    Parse by hand, so that --update can be run with Python 2.
+    '''
+    assert '\t' not in s
+    d = {}
+    root = Stub(kind='root', name=root_name)
+    indent_stack = [-1]  # To prevent the root from being popped.
+    stub_stack = [root]
+    lines = []
+    pat = re.compile(r'^([ ]*)(def|class)\s+([a-zA-Z_]+)(.*)')
+    for line in g.splitLines(s):
+        m = pat.match(line)
+        if m:
+            indent, kind, name = (len(m.group(1)), m.group(2), m.group(3))
+            old_indent = indent_stack[-1]
+            # Terminate any previous lines.
+            old_stub = stub_stack[-1]
+            old_stub.out_list.extend(lines)
+            lines = [line]
+            # Adjust the stacks.
+            if indent == old_indent:
+                stub_stack.pop()
+            elif indent &amp;gt; old_indent:
+                indent_stack.append(indent)
+            else:  # indent &amp;lt; old_indent
+                # The indent_stack can't underflow because
+                # indent &amp;gt;= 0 and indent_stack[0] &amp;lt; 0
+                assert indent &amp;gt;= 0
+                while indent &amp;lt;= indent_stack[-1]:
+                    indent_stack.pop()
+                    old_stub = stub_stack.pop()
+                    assert old_stub != root
+                indent_stack.append(indent)
+            # Create and push the new stub *after* adjusting the stacks.
+            assert stub_stack
+            parent = stub_stack[-1]
+            stack = [z.name for z in stub_stack[1:]]
+            parent = stub_stack[-1]
+            stub = Stub(kind, name, parent, stack)
+            self.add_stub(d, stub)
+            stub_stack.append(stub)
+        else:
+            parent = stub_stack[-1]
+            lines.append(line)
+    # Terminate the last stub.
+    old_stub = stub_stack[-1]
+    old_stub.out_list.extend(lines)
+    return d, root
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.179"&gt;def merge_stubs(self, new_stubs, old_root, new_root, trace=False):
+    '''
+    Merge the new_stubs *list* into the old_root *tree*.
+    - new_stubs is a list of Stubs from the .py file.
+    - old_root is the root of the stubs from the .pyi file.
+    - new_root is the root of the stubs from the .py file.
+    '''
+    # Part 1: Delete old stubs do *not* exist in the *new* tree.
+    aList = self.check_delete(new_stubs, old_root, new_root, trace)
+        # Checks that all ancestors of deleted nodes will be deleted.
+    aList = list(reversed(self.sort_stubs_by_hierarchy(aList)))
+        # Sort old stubs so that children are deleted before parents.
+    for stub in aList:
+        if trace: g.trace('deleting  %s' % stub)
+        parent = self.find_parent_stub(stub, old_root) or old_root
+        parent.children.remove(stub)
+        assert not self.find_stub(stub, old_root), stub
+    # Part 2: Insert new stubs that *not* exist in the *old* tree.
+    aList = [z for z in new_stubs if not self.find_stub(z, old_root)]
+    aList = self.sort_stubs_by_hierarchy(aList)
+        # Sort new stubs so that parents are created before children.
+    for stub in aList:
+        if trace: g.trace('inserting %s' % stub)
+        parent = self.find_parent_stub(stub, old_root) or old_root
+        parent.children.append(stub)
+        assert self.find_stub(stub, old_root), stub
 &lt;/t&gt;
 &lt;t tx="ekr.20160318141204.18"&gt;def visit(self, node):
     '''Return the formatted version of an Ast node, or list of Ast nodes.'''
@@ -2334,6 +2610,93 @@
     # assert type(s) == type('abc'), (node, type(s))
     assert g.isString(s), type(s)
     return s
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.180"&gt;def check_delete(self, new_stubs, old_root, new_root, trace):
+    '''Return a list of nodes that can be deleted.'''
+    old_stubs = self.flatten_stubs(old_root)
+    old_stubs.remove(old_root)
+    aList = [z for z in old_stubs if z not in new_stubs]
+    if trace:
+        dump_list('old_stubs', old_stubs)
+        dump_list('new_stubs', new_stubs)
+        dump_list('to-be-deleted stubs', aList)
+    delete_list = []
+    # Check that all parents of to-be-delete nodes will be deleted.
+    for z in aList:
+        z1 = z
+        for i in range(20):
+            z = z.parent
+            if not z:
+                g.trace('can not append: new root not found', z)
+                break
+            elif z == old_root:
+                delete_list.append(z1)
+                break
+            elif z not in aList:
+                g.trace("can not delete %s because of %s" % (z1, z))
+                break
+        else:
+            g.trace('can not happen: parent loop')
+    if trace:
+        dump_list('delete_list', delete_list)
+    return delete_list
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.181"&gt;def flatten_stubs(self, root):
+    '''Return a flattened list of all stubs in root's tree.'''
+    aList = [root]
+    for child in root.children:
+        self.flatten_stubs_helper(child, aList)
+    return aList
+
+def flatten_stubs_helper(self, root, aList):
+    '''Append all stubs in root's tree to aList.'''
+    aList.append(root)
+    for child in root.children:
+        self.flatten_stubs_helper(child, aList)
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.182"&gt;def find_parent_stub(self, stub, root):
+    '''Return stub's parent **in root's tree**.'''
+    return self.find_stub(stub.parent, root) if stub.parent else None
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.183"&gt;def find_stub(self, stub, root):
+    '''Return the stub **in root's tree** that matches stub.'''
+    if stub == root:  # Must use Stub.__eq__!
+        return root  # not stub!
+    for child in root.children:
+        stub2 = self.find_stub(stub, child)
+        if stub2: return stub2
+    return None
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.184"&gt;def sort_stubs_by_hierarchy(self, stubs1):
+    '''
+    Sort the list of Stubs so that parents appear before all their
+    descendants.
+    '''
+    stubs, result = stubs1[:], []
+    for i in range(50):
+        if stubs:
+            # Add all stubs with i parents to the results.
+            found = [z for z in stubs if z.level() == i]
+            result.extend(found)
+            for z in found:
+                stubs.remove(z)
+        else:
+            return result
+    g.trace('can not happen: unbounded stub levels.')
+    return []  # Abort the merge.
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.185"&gt;def trace_stubs(self, stub, aList=None, header=None, level=-1):
+    '''Return a trace of the given stub and all its descendants.'''
+    indent = ' ' * 4 * max(0, level)
+    if level == -1:
+        aList = ['===== %s...\n' % (header) if header else '']
+    for s in stub.out_list:
+        aList.append('%s%s' % (indent, s.rstrip()))
+    for child in stub.children:
+        self.trace_stubs(child, level=level + 1, aList=aList)
+    if level == -1:
+        return '\n'.join(aList) + '\n'
+    return ''
 &lt;/t&gt;
 &lt;t tx="ekr.20160318141204.186"&gt;# 2: ClassDef(identifier name, expr* bases,
 #             stmt* body, expr* decorator_list)
@@ -2386,6 +2749,34 @@
     self.level -= 1
     self.parent_stub = old_stub
 &lt;/t&gt;
+&lt;t tx="ekr.20160318141204.187"&gt;# 2: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list)
+# 3: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list,
+#                expr? returns)
+
+def visit_FunctionDef(self, node):
+
+    # Create the stub in the old context.
+    old_stub = self.parent_stub
+    self.parent_stub = Stub('def', node.name, old_stub, self.context_stack)
+    self.add_stub(self.stubs_dict, self.parent_stub)
+    # Enter the new context.
+    self.returns = []
+    self.level += 1
+    self.context_stack.append(node.name)
+    for z in node.body:
+        self.visit(z)
+    self.context_stack.pop()
+    self.level -= 1
+    # Format *after* traversing
+    # if self.trace_matches or self.trace_reduce:
+        # if not self.class_name_stack:
+            # print('def %s\n' % node.name)
+    self.out('def %s(%s) -&amp;gt; %s' % (
+        node.name,
+        self.format_arguments(node.args),
+        self.format_returns(node)))
+    self.parent_stub = old_stub
+&lt;/t&gt;
 &lt;t tx="ekr.20160318141204.188"&gt;# arguments = (expr* args, identifier? vararg, identifier? kwarg, expr* defaults)
 
 def format_arguments(self, node):
@@ -2438,6 +2829,94 @@
 &lt;t tx="ekr.20160318141204.19"&gt;
 # Contexts...
 &lt;/t&gt;
+&lt;t tx="ekr.20160318141204.190"&gt;def format_returns(self, node):
+    '''
+    Calculate the return type:
+    - Return None if there are no return statements.
+    - Patterns in [Def Name Patterns] override all other patterns.
+    - Otherwise, return a list of return values.
+    '''
+    name = self.get_def_name(node)
+    raw = [self.raw_format(z) for z in self.returns]
+    # Allow StubFormatter.do_Return to do the hack.
+    r = [self.format(z) for z in self.returns]
+    # Step 1: Return None if there are no return statements.
+    if not [z for z in self.returns if z.value is not None]:
+        empty = not any(isinstance(z, ast.FunctionDef) for z in node.body)
+        tail = ': ...' if empty else ':'
+        return 'None' + tail
+    # Step 2: [Def Name Patterns] override all other patterns.
+    for pattern in self.def_patterns:
+        found, s = pattern.match(name)
+        if found:
+            return s + ': ...'
+    # Step 3: remove recursive calls.
+    raw, r = self.remove_recursive_calls(name, raw, r)
+    # Step 4: Calculate return types.
+    return self.format_return_expressions(node, name, raw, r)
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.191"&gt;def format_return_expressions(self, node, name, raw_returns, reduced_returns):
+    '''
+    aList is a list of maximally reduced return expressions.
+    For each expression e in Alist:
+    - If e is a single known type, add e to the result.
+    - Otherwise, add Any # e to the result.
+    Return the properly indented result.
+    '''
+    assert len(raw_returns) == len(reduced_returns)
+    lws = '\n' + ' ' * 4
+    n = len(raw_returns)
+    known = all(is_known_type(e) for e in reduced_returns)
+    empty = not any(isinstance(z, ast.FunctionDef) for z in node.body)
+    tail = ': ...' if empty else ':'
+    if not known or self.verbose:
+        # First, generate the return lines.
+        aList = []
+        for i in range(n):
+            e, raw = reduced_returns[i], raw_returns[i]
+            known = ' ' if is_known_type(e) else '?'
+            aList.append('# %s %s: %s' % (' ', i, raw))
+            aList.append('# %s %s: return %s' % (known, i, e))
+        results = ''.join([lws + self.indent(z) for z in aList])
+        # Put the return lines in their proper places.
+        if known:
+            s = reduce_types(reduced_returns, name=name, trace=self.trace_reduce)
+            return s + tail + results
+        return 'Any' + tail + results
+    s = reduce_types(reduced_returns, name=name, trace=self.trace_reduce)
+    return s + tail
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.192"&gt;def get_def_name(self, node):
+    '''Return the representaion of a function or method name.'''
+    if self.class_name_stack:
+        name = '%s.%s' % (self.class_name_stack[-1], node.name)
+        # All ctors should return None
+        if node.name == '__init__':
+            name = 'None'
+    else:
+        name = node.name
+    return name
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.193"&gt;def remove_recursive_calls(self, name, raw, reduced):
+    '''Remove any recursive calls to name from both lists.'''
+    # At present, this works *only* if the return is nothing but the recursive call.
+    assert len(raw) == len(reduced)
+    pattern = Pattern('%s(*)' % name)
+    n = len(reduced)
+    raw_result, reduced_result = [], []
+    for i in range(n):
+        if pattern.match_entire_string(reduced[i]):
+            pass
+        else:
+            raw_result.append(raw[i])
+            reduced_result.append(reduced[i])
+    return raw_result, reduced_result
+&lt;/t&gt;
+&lt;t tx="ekr.20160318141204.194"&gt;def visit_Return(self, node):
+
+    self.returns.append(node)
+        # New: return the entire node, not node.value.
+&lt;/t&gt;
 &lt;t tx="ekr.20160318141204.195"&gt;
 
 class TestClass:
@@ -2479,34 +2958,6 @@
 &lt;t tx="ekr.20160318141204.199"&gt;
 def return_list(self, a):
     return [a]
-&lt;/t&gt;
-&lt;t tx="ekr.20160318141204.2"&gt;import argparse
-import ast
-from collections import OrderedDict
-    # Requires Python 2.7 or above. Without OrderedDict
-    # the configparser will give random order for patterns.
-try:
-    import ConfigParser as configparser  # Python 2
-except ImportError:
-    import configparser  # Python 3
-import glob
-import os
-import re
-import subprocess
-import sys
-import time
-import types
-import unittest
-try:
-    import StringIO as io  # Python 2
-except ImportError:
-    import io  # Python 3
-###
-    # # Third party imports.
-    # try:
-        # import pytest
-    # except Exception:
-        # pytest = None  # type:ignore
 &lt;/t&gt;
 &lt;t tx="ekr.20160318141204.20"&gt;# 2: ClassDef(identifier name, expr* bases,
 #             stmt* body, expr* decorator_list)
@@ -3345,17 +3796,22 @@
 &lt;/t&gt;
 &lt;t tx="ekr.20180901040718.1"&gt;def test_bug2_empty(self):
     # https://github.com/edreamleo/make-stub-files/issues/2
-    commands = [
-        # 'cls',
-        'python make_stub_files.py -o -s bug2.py',
-    ]
-    g.execute_shell_commands(commands, trace=True)
-    with open('bug2.pyi') as f:
-        s = f.read()
+    tag = 'test_bug2_empty'
+    s = 'class InvalidTag(Exception):\n    pass'
+    controller = Controller()
+    node = ast.parse(s, filename=tag, mode='exec')
+    st = StubTraverser(controller=controller)
+    # From StubTraverser.run.
+    st.parent_stub = Stub(kind='root', name='&amp;lt;new-stubs&amp;gt;')
+    st.visit(node)
+    # Allocate a StringIo file for output_stubs.
+    st.output_file = io.StringIO()
+    st.output_stubs(st.parent_stub)
+    s = st.output_file.getvalue()
     lines = g.splitLines(s)
-    expected = 'class InvalidTag(Exception): ...\n'
-    got = lines[1]
-    self.assertEqual(got, expected)
+    # Test.
+    expected = ['class InvalidTag(Exception): ...\n']
+    self.assertEqual(lines, expected)
 &lt;/t&gt;
 &lt;t tx="ekr.20180901044640.1"&gt;def test_bug2_non_empty(self):
     # https://github.com/edreamleo/make-stub-files/issues/2
@@ -3369,7 +3825,6 @@
     lines = g.splitLines(s)
     expected = 'class NonEmptyClass:\n'
     got = lines[1]
-    ### assert got == expected, 'expected: %r\ngot:    %r' % (expected, got)
     self.assertEqual(got, expected)
 &lt;/t&gt;
 &lt;t tx="ekr.20180901050914.1"&gt;&lt;/t&gt;
@@ -3409,11 +3864,9 @@
 
 https://github.com/edreamleo/make-stub-files/issues/13
 
-Create coverage tests:
-- For *Formatter classes.
-- For ReduceTypes class.
-- For Stub* classes.
-- Convert all old tests.
+*** Remove all bug*.pyi files.
+*** Fix failing unit test.
+*** Create coverage tests: Suppress coverage of tests themselves.
 
 Later:
 - Rewrite the readme.
@@ -3435,7 +3888,7 @@
 &lt;t tx="ekr.20210804025215.1"&gt;c.backup_helper(sub_dir='MakeStubFiles')
 &lt;/t&gt;
 &lt;t tx="ekr.20210804060105.1"&gt;g.cls()
-test = '' # Run all tests.
+test = '.TestMakeStubFiles.test_bug2_empty' # Run all tests.
 command = f"python -m unittest make_stub_files{test}"
 g.execute_shell_commands(command, trace=False)&lt;/t&gt;
 &lt;t tx="ekr.20210804070157.1"&gt;&lt;/t&gt;
@@ -3732,5 +4185,6 @@
     p.moveToThreadNext()
 c.redraw()
 &lt;/t&gt;
+&lt;t tx="ekr.20210804161223.1"&gt;# Found 3 marked nodes&lt;/t&gt;
 &lt;/tnodes&gt;
 &lt;/leo_file&gt;
@language python
</t>
<t tx="ekr.20210804170546.24"></t>
<t tx="ekr.20210804170546.25">@ignore
@nosearch
@language patch
--- HEAD
+++ uncommitted
@@ -19,9 +19,3 @@
     import StringIO as io  # Python 2
 except ImportError:
     import io  # Python 3
-###
-    # # Third party imports.
-    # try:
-        # import pytest
-    # except Exception:
-        # pytest = None  # type:ignore
@language python
</t>
<t tx="ekr.20210804170546.26">import argparse
import ast
from collections import OrderedDict
    # Requires Python 2.7 or above. Without OrderedDict
    # the configparser will give random order for patterns.
try:
    import ConfigParser as configparser  # Python 2
except ImportError:
    import configparser  # Python 3
import glob
import os
import re
import subprocess
import sys
import time
import types
import unittest
try:
    import StringIO as io  # Python 2
except ImportError:
    import io  # Python 3
###
    # # Third party imports.
    # try:
        # import pytest
    # except Exception:
        # pytest = None  # type:ignore
</t>
<t tx="ekr.20210804170546.27">@ignore
@nosearch
@language patch
--- HEAD
+++ uncommitted
@@ -1,13 +1,18 @@
 def test_bug2_empty(self):
     # https://github.com/edreamleo/make-stub-files/issues/2
-    commands = [
-        # 'cls',
-        'python make_stub_files.py -o -s bug2.py',
-    ]
-    g.execute_shell_commands(commands, trace=True)
-    with open('bug2.pyi') as f:
-        s = f.read()
+    tag = 'test_bug2_empty'
+    s = 'class InvalidTag(Exception):\n    pass'
+    controller = Controller()
+    node = ast.parse(s, filename=tag, mode='exec')
+    st = StubTraverser(controller=controller)
+    # From StubTraverser.run.
+    st.parent_stub = Stub(kind='root', name='&lt;new-stubs&gt;')
+    st.visit(node)
+    # Allocate a StringIo file for output_stubs.
+    st.output_file = io.StringIO()
+    st.output_stubs(st.parent_stub)
+    s = st.output_file.getvalue()
     lines = g.splitLines(s)
-    expected = 'class InvalidTag(Exception): ...\n'
-    got = lines[1]
-    self.assertEqual(got, expected)
+    # Test.
+    expected = ['class InvalidTag(Exception): ...\n']
+    self.assertEqual(lines, expected)
@language python
</t>
<t tx="ekr.20210804170546.28">def test_bug2_empty(self):
    # https://github.com/edreamleo/make-stub-files/issues/2
    commands = [
        # 'cls',
        'python make_stub_files.py -o -s bug2.py',
    ]
    g.execute_shell_commands(commands, trace=True)
    with open('bug2.pyi') as f:
        s = f.read()
    lines = g.splitLines(s)
    expected = 'class InvalidTag(Exception): ...\n'
    got = lines[1]
    self.assertEqual(got, expected)
</t>
<t tx="ekr.20210804170546.29">@ignore
@nosearch
@language patch
--- HEAD
+++ uncommitted
@@ -10,5 +10,4 @@
     lines = g.splitLines(s)
     expected = 'class NonEmptyClass:\n'
     got = lines[1]
-    ### assert got == expected, 'expected: %r\ngot:    %r' % (expected, got)
     self.assertEqual(got, expected)
@language python
</t>
<t tx="ekr.20210804170546.30">def test_bug2_non_empty(self):
    # https://github.com/edreamleo/make-stub-files/issues/2
    commands = [
        # 'cls',
        'python make_stub_files.py -o -s bug2a.py',
    ]
    g.execute_shell_commands(commands, trace=True)
    with open('bug2a.pyi') as f:
        s = f.read()
    lines = g.splitLines(s)
    expected = 'class NonEmptyClass:\n'
    got = lines[1]
    ### assert got == expected, 'expected: %r\ngot:    %r' % (expected, got)
    self.assertEqual(got, expected)
</t>
<t tx="ekr.20210804170546.7"></t>
<t tx="ekr.20210804170546.8"></t>
<t tx="ekr.20210804170546.9">import argparse
import ast
from collections import OrderedDict
    # Requires Python 2.7 or above. Without OrderedDict
    # the configparser will give random order for patterns.
try:
    import ConfigParser as configparser  # Python 2
except ImportError:
    import configparser  # Python 3
import glob
import os
import re
import subprocess
import sys
import time
import types
import unittest
try:
    import StringIO as io  # Python 2
except ImportError:
    import io  # Python 3
###
    # # Third party imports.
    # try:
        # import pytest
    # except Exception:
        # pytest = None  # type:ignore
</t>
</tnodes>
</leo_file>
