<?xml version="1.0" encoding="utf-8"?>
<!-- Created by Leo: http://leoeditor.com/leo_toc.html -->
<leo_file xmlns:leo="http://leoeditor.com/namespaces/leo-python-editor/1.1" >
<leo_header file_format="2"/>
<globals/>
<preferences/>
<find_panel_settings/>
<vnodes>
<v t="ekr.20160207181637.1"><vh>Startup</vh>
<v t="ekr.20160207181648.1"><vh>@settings</vh>
<v t="ekr.20180706073424.1"><vh>@bool run-pyflakes-on-write = False</vh></v>
<v t="ekr.20160207182535.1"><vh>@bool preload-find-pattern = False</vh></v>
</v>
<v t="ekr.20210805061637.1"><vh>buttons</vh>
<v t="ekr.20210804020706.1"><vh>@button coverage</vh></v>
<v t="ekr.20210804060105.1"><vh>@button unitttest</vh></v>
<v t="ekr.20210804021331.1"><vh>@button msf</vh></v>
</v>
</v>
<v t="ekr.20210805061856.1"><vh>Notes</vh>
<v t="ekr.20210805061902.1"><vh>No longer used</vh>
<v t="ekr.20160318141204.5"><vh>merge_types (not used)</vh></v>
<v t="ekr.20160207051429.1"><vh>test_merge_types</vh></v>
</v>
<v t="ekr.20210804153200.1"><vh>script convert-at-test</vh></v>
</v>
<v t="ekr.20160128104714.1"><vh>Files</vh>
<v t="ekr.20160128225533.1"><vh>@clean .gitignore</vh></v>
<v t="ekr.20160128102557.1"><vh>@clean example.cfg</vh></v>
<v t="ekr.20160126153220.1"><vh>@clean make_stub_files.cfg</vh></v>
<v t="ekr.20160330201030.1"><vh>@clean PKG-INFO.TXT</vh></v>
<v t="ekr.20160211110739.1"><vh>@clean README.md</vh>
<v t="ekr.20160211110807.1"><vh>Overview</vh></v>
<v t="ekr.20160211113019.1"><vh>Quick start</vh></v>
<v t="ekr.20160211110810.1"><vh>Command-line arguments</vh></v>
<v t="ekr.20160211110810.2"><vh>The configuration file</vh>
<v t="ekr.20160211111807.1"><vh>Patterns</vh></v>
<v t="ekr.20160211111823.1"><vh>[Global]</vh></v>
<v t="ekr.20160211111839.1"><vh>[Def Name Patterns]</vh></v>
<v t="ekr.20160211111901.1"><vh>[General Patterns]</vh></v>
</v>
<v t="ekr.20160211110810.3"><vh>Why this script is important</vh></v>
<v t="ekr.20160211110811.1"><vh>Summary</vh></v>
</v>
<v t="ekr.20160207101607.1"><vh>@clean theory.md</vh></v>
</v>
<v t="ekr.20160318141204.1" descendentVnodeUnknownAttributes="7d71005805000000302e352e3571017d71025808000000616e6e6f7461746571037d710473732e"><vh>@file make_stub_files.py</vh></v>
<v t="ekr.20210805053830.1"><vh>=== #18: full coverage</vh>
<v t="ekr.20210805090003.1"><vh>--- no longer used</vh>
<v t="ekr.20160318141204.12"><vh>function: pdb</vh></v>
<v t="ekr.20210806132036.1"><vh>&lt;&lt; define description &gt;&gt;</vh></v>
</v>
<v t="ekr.20210805061637.1"></v>
<v t="ekr.20210805102238.1"><vh>--- classes</vh>
<v t="ekr.20160318141204.14"><vh> class AstFormatter</vh>
<v t="ekr.20160318141204.15"><vh> f.Entries</vh>
<v t="ekr.20160318141204.17"><vh>f.format</vh></v>
<v t="ekr.20160318141204.18"><vh>f.visit</vh></v>
</v>
<v t="ekr.20160318141204.19"><vh>f.Contexts</vh>
<v t="ekr.20160318141204.20"><vh>f.ClassDef</vh></v>
<v t="ekr.20160318141204.21"><vh>f.FunctionDef</vh></v>
<v t="ekr.20160318141204.22"><vh>f.Interactive</vh></v>
<v t="ekr.20160318141204.23"><vh>f.Module</vh></v>
<v t="ekr.20160318141204.24"><vh>f.Lambda</vh></v>
</v>
<v t="ekr.20160318141204.25"><vh>f.Expressions</vh>
<v t="ekr.20160318141204.26"><vh>f.Expr</vh></v>
<v t="ekr.20160318141204.27"><vh>f.Expression</vh></v>
<v t="ekr.20160318141204.28"><vh>f.GeneratorExp</vh></v>
<v t="ekr.20160318141204.29"><vh>f.ctx nodes</vh></v>
</v>
<v t="ekr.20160318141204.30"><vh>f.Operands</vh>
<v t="ekr.20160318141204.31"><vh>f.arguments</vh></v>
<v t="ekr.20160318141204.32"><vh>f.arg (Python3 only) (make_stub_files)</vh></v>
<v t="ekr.20160318141204.33"><vh>f.Attribute</vh></v>
<v t="ekr.20160318141204.34"><vh>f.Bytes</vh></v>
<v t="ekr.20160318141204.35"><vh>f.Call &amp; f.keyword</vh>
<v t="ekr.20160318141204.36"><vh>f.keyword</vh></v>
</v>
<v t="ekr.20210804214511.1"><vh>f.Constant</vh></v>
<v t="ekr.20160318141204.37"><vh>f.comprehension</vh></v>
<v t="ekr.20160318141204.38"><vh>f.Dict</vh></v>
<v t="ekr.20160318141204.39"><vh>f.Ellipsis</vh></v>
<v t="ekr.20160318141204.40"><vh>f.ExtSlice</vh></v>
<v t="ekr.20160318141204.41"><vh>f.Index</vh></v>
<v t="ekr.20210806005225.1"><vh>f.FormattedValue &amp; JoinedStr</vh></v>
<v t="ekr.20160318141204.42"><vh>f.List</vh></v>
<v t="ekr.20160318141204.43"><vh>f.ListComp</vh></v>
<v t="ekr.20160318141204.44"><vh>f.Name &amp; NameConstant</vh></v>
<v t="ekr.20160318141204.45"><vh>f.Num</vh></v>
<v t="ekr.20160318141204.46"><vh>f.Repr</vh></v>
<v t="ekr.20160318141204.47"><vh>f.Slice</vh></v>
<v t="ekr.20160318141204.48"><vh>f.Str</vh></v>
<v t="ekr.20160318141204.49"><vh>f.Subscript</vh></v>
<v t="ekr.20160318141204.50"><vh>f.Tuple</vh></v>
</v>
<v t="ekr.20160318141204.51"><vh>f.Operators</vh>
<v t="ekr.20160318141204.52"><vh>f.BinOp</vh></v>
<v t="ekr.20160318141204.53"><vh>f.BoolOp</vh></v>
<v t="ekr.20160318141204.54"><vh>f.Compare</vh></v>
<v t="ekr.20160318141204.55"><vh>f.UnaryOp</vh></v>
<v t="ekr.20160318141204.56"><vh>f.ifExp (ternary operator)</vh></v>
</v>
<v t="ekr.20160318141204.57"><vh>f.Statements</vh>
<v t="ekr.20160318141204.58"><vh>f.Assert</vh></v>
<v t="ekr.20160318141204.59"><vh>f.Assign</vh></v>
<v t="ekr.20160318141204.60"><vh>f.AugAssign</vh></v>
<v t="ekr.20160318141204.61"><vh>f.Break</vh></v>
<v t="ekr.20160318141204.62"><vh>f.Continue</vh></v>
<v t="ekr.20160318141204.63"><vh>f.Delete</vh></v>
<v t="ekr.20160318141204.64"><vh>f.ExceptHandler</vh></v>
<v t="ekr.20160318141204.65"><vh>f.Exec</vh></v>
<v t="ekr.20160318141204.66"><vh>f.For</vh></v>
<v t="ekr.20160318141204.67"><vh>f.Global</vh></v>
<v t="ekr.20160318141204.68"><vh>f.If</vh></v>
<v t="ekr.20160318141204.69"><vh>f.Import &amp; helper</vh>
<v t="ekr.20160318141204.70"><vh>f.get_import_names</vh></v>
</v>
<v t="ekr.20160318141204.71"><vh>f.ImportFrom</vh></v>
<v t="ekr.20160318141204.72"><vh>f.Nonlocal (Python 3)</vh></v>
<v t="ekr.20160318141204.73"><vh>f.Pass</vh></v>
<v t="ekr.20160318141204.74"><vh>f.Print</vh></v>
<v t="ekr.20160318141204.75"><vh>f.Raise</vh></v>
<v t="ekr.20160318141204.76"><vh>f.Return</vh></v>
<v t="ekr.20160318141204.77"><vh>f.Starred (Python 3)</vh></v>
<v t="ekr.20160318141204.79"><vh>f.Try (Python 3)</vh></v>
<v t="ekr.20160318141204.80"><vh>f.TryExcept</vh></v>
<v t="ekr.20160318141204.81"><vh>f.TryFinally</vh></v>
<v t="ekr.20160318141204.82"><vh>f.While</vh></v>
<v t="ekr.20160318141204.83"><vh>f.With</vh></v>
<v t="ekr.20160318141204.84"><vh>f.Yield</vh></v>
<v t="ekr.20160318141204.85"><vh>f.YieldFrom (Python 3)</vh></v>
</v>
<v t="ekr.20160318141204.86"><vh>f.Utils</vh>
<v t="ekr.20160318141204.87"><vh>f.kind</vh></v>
<v t="ekr.20160318141204.88"><vh>f.indent</vh></v>
<v t="ekr.20160318141204.89"><vh>f.op_name</vh></v>
</v>
</v>
<v t="ekr.20160318141204.90"><vh>class AstArgFormatter (AstFormatter)</vh>
<v t="ekr.20160318141204.91"><vh>sf.Constants &amp; Name</vh></v>
</v>
<v t="ekr.20160318141204.125"><vh>class Controller</vh>
<v t="ekr.20160318141204.126"><vh>msf.ctor</vh></v>
<v t="ekr.20160318141204.128"><vh>msf.make_stub_file</vh></v>
<v t="ekr.20160318141204.131"><vh>msf.scan_command_line</vh></v>
<v t="ekr.20160318141204.132"><vh>msf.scan_options &amp; helpers</vh>
<v t="ekr.20160318141204.133"><vh>msf.make_op_name_dict</vh></v>
<v t="ekr.20160318141204.134"><vh>msf.create_parser</vh></v>
<v t="ekr.20160318141204.135"><vh>msf.find_pattern_ops</vh></v>
<v t="ekr.20160318141204.136"><vh>msf.get_config_string</vh></v>
<v t="ekr.20160318141204.137"><vh>msf.init_parser</vh></v>
<v t="ekr.20160318141204.138"><vh>msf.is_section_name</vh></v>
<v t="ekr.20160318141204.139"><vh>msf.make_patterns_dict</vh></v>
<v t="ekr.20160318141204.140"><vh>msf.scan_patterns</vh></v>
</v>
</v>
<v t="ekr.20160318141204.102"><vh>class Pattern</vh>
<v t="ekr.20160318141204.103"><vh>pattern.ctor</vh></v>
<v t="ekr.20160318141204.104"><vh>pattern.__eq__, __ne__, __hash__</vh></v>
<v t="ekr.20160318141204.105"><vh>pattern.str &amp; repr</vh></v>
<v t="ekr.20160318141204.106"><vh>pattern.is_balanced</vh></v>
<v t="ekr.20160318141204.107"><vh>pattern.is_regex</vh></v>
<v t="ekr.20160318141204.108"><vh>pattern.all_matches &amp; helpers</vh>
<v t="ekr.20160318141204.109"><vh>pattern.full_balanced_match</vh></v>
<v t="ekr.20160318141204.110"><vh>pattern.match_balanced</vh></v>
</v>
<v t="ekr.20160318141204.111"><vh>pattern.match (trace-matches)</vh></v>
<v t="ekr.20160318141204.112"><vh>pattern.match_entire_string</vh></v>
<v t="ekr.20160318141204.113"><vh>pattern.replace &amp; helpers</vh>
<v t="ekr.20160318141204.114"><vh>pattern.replace_balanced</vh></v>
<v t="ekr.20160318141204.115"><vh>pattern.replace_regex</vh></v>
</v>
</v>
<v t="ekr.20160318141204.116"><vh>class ReduceTypes</vh>
<v t="ekr.20160318141204.117"><vh>rt.ctor</vh></v>
<v t="ekr.20160318141204.118"><vh>rt.is_known_type</vh></v>
<v t="ekr.20160318141204.119"><vh>rt.reduce_collection</vh></v>
<v t="ekr.20160318141204.120"><vh>rt.reduce_numbers</vh></v>
<v t="ekr.20160318141204.121"><vh>rt.reduce_types</vh></v>
<v t="ekr.20160318141204.122"><vh>rt.reduce_unknowns</vh></v>
<v t="ekr.20160318141204.123"><vh>rt.show</vh></v>
<v t="ekr.20160318141204.124"><vh>rt.split_types</vh></v>
</v>
<v t="ekr.20160318141204.147"><vh>class StubFormatter (AstFormatter)</vh>
<v t="ekr.20160318141204.148"><vh>sf.ctor</vh></v>
<v t="ekr.20160318141204.149"><vh>sf.match_all</vh></v>
<v t="ekr.20160318141204.151"><vh>sf.trace_visitor</vh></v>
<v t="ekr.20160318141204.152"><vh>sf.Operands</vh>
<v t="ekr.20160318141204.153"><vh>sf.Attribute</vh></v>
<v t="ekr.20160318141204.154"><vh>sf.Constants: Constant, Bytes, Num, Str</vh></v>
<v t="ekr.20160318141204.155"><vh>sf.Dict</vh></v>
<v t="ekr.20160318141204.156"><vh>sf.List</vh></v>
<v t="ekr.20160318141204.157"><vh>sf.Name</vh></v>
<v t="ekr.20160318141204.158"><vh>sf.Tuple</vh></v>
</v>
<v t="ekr.20160318141204.159"><vh>sf.Operators</vh>
<v t="ekr.20160318141204.160"><vh>sf.BinOp</vh></v>
<v t="ekr.20160318141204.161"><vh>sf.BoolOp</vh></v>
<v t="ekr.20160318141204.162"><vh>sf.Call &amp; sf.keyword</vh>
<v t="ekr.20160318141204.163"><vh>sf.keyword</vh></v>
</v>
<v t="ekr.20160318141204.164"><vh>sf.Compare</vh></v>
<v t="ekr.20160318141204.165"><vh>sf.IfExp</vh></v>
<v t="ekr.20160318141204.166"><vh>sf.Subscript</vh></v>
<v t="ekr.20160318141204.167"><vh>sf.UnaryOp</vh></v>
</v>
<v t="ekr.20160318141204.168"><vh>sf.Return</vh></v>
</v>
<v t="ekr.20160318141204.169"><vh>class StubTraverser (ast.NodeVisitor)</vh>
<v t="ekr.20160318141204.170"><vh>st.ctor</vh></v>
<v t="ekr.20160318141204.171"><vh>st.add_stub</vh></v>
<v t="ekr.20160318141204.172"><vh>st.indent &amp; out</vh></v>
<v t="ekr.20160318141204.173"><vh>st.run (main line) &amp; helpers</vh>
<v t="ekr.20160318141204.174"><vh>st.output_stubs</vh></v>
<v t="ekr.20160318141204.175"><vh>st.output_time_stamp</vh></v>
<v t="ekr.20160318141204.176"><vh>st.update &amp; helpers</vh>
<v t="ekr.20160318141204.177"><vh>st.get_stub_file</vh></v>
<v t="ekr.20160318141204.178"><vh>st.parse_stub_file</vh></v>
<v t="ekr.20160318141204.179"><vh>st.merge_stubs &amp; helpers</vh>
<v t="ekr.20160318141204.180"><vh>st.check_delete</vh></v>
<v t="ekr.20160318141204.181"><vh>st.flatten_stubs</vh></v>
<v t="ekr.20160318141204.182"><vh>st.find_parent_stub</vh></v>
<v t="ekr.20160318141204.183"><vh>st.find_stub</vh></v>
<v t="ekr.20160318141204.184"><vh>st.sort_stubs_by_hierarchy</vh></v>
</v>
<v t="ekr.20160318141204.185"><vh>st.trace_stubs</vh></v>
</v>
</v>
<v t="ekr.20160318141204.186"><vh>st.visit_ClassDef</vh></v>
<v t="ekr.20160318141204.187"><vh>st.visit_FunctionDef &amp; helpers</vh>
<v t="ekr.20160318141204.188"><vh>st.format_arguments &amp; helper</vh>
<v t="ekr.20160318141204.189"><vh>st.munge_arg</vh></v>
</v>
<v t="ekr.20160318141204.190"><vh>st.format_returns &amp; helpers</vh>
<v t="ekr.20160318141204.191"><vh>st.format_return_expressions</vh></v>
<v t="ekr.20160318141204.192"><vh>st.get_def_name</vh></v>
<v t="ekr.20160318141204.193"><vh>st.remove_recursive_calls</vh></v>
</v>
</v>
<v t="ekr.20160318141204.194"><vh>st.visit_Return</vh></v>
</v>
</v>
<v t="ekr.20210806161202.1"><vh>test: class syntax</vh></v>
<v t="ekr.20210806134651.1"><vh>--- recent</vh>
<v t="ekr.20160318141204.131"></v>
</v>
<v t="ekr.20210806081329.1"><vh>--- missing tests</vh>
<v t="ekr.20160318141204.31"></v>
<v t="ekr.20160318141204.64"></v>
<v t="ekr.20160318141204.71"></v>
<v t="ekr.20160318141204.72"></v>
<v t="ekr.20160318141204.75"></v>
<v t="ekr.20160318141204.135"></v>
<v t="ekr.20160318141204.138"></v>
<v t="ekr.20160318141204.139"></v>
<v t="ekr.20160318141204.140"></v>
<v t="ekr.20160318141204.111"></v>
<v t="ekr.20160318141204.113"></v>
<v t="ekr.20160318141204.118"></v>
<v t="ekr.20160318141204.153"></v>
<v t="ekr.20160318141204.160"></v>
<v t="ekr.20160318141204.162"></v>
<v t="ekr.20160318141204.164"></v>
<v t="ekr.20160318141204.155"></v>
<v t="ekr.20160318141204.156"></v>
<v t="ekr.20160318141204.149"></v>
<v t="ekr.20160318141204.166"></v>
<v t="ekr.20160318141204.158"></v>
<v t="ekr.20160318141204.167"></v>
<v t="ekr.20160318141204.188"></v>
<v t="ekr.20160318141204.190"></v>
<v t="ekr.20160318141204.189"></v>
<v t="ekr.20160318141204.175"></v>
<v t="ekr.20160318141204.176"></v>
<v t="ekr.20160318141204.186"></v>
<v t="ekr.20160318141204.194"></v>
</v>
<v t="ekr.20210803055042.1"><vh>class TestMakeStubFiles(unittest.TestCase)</vh>
<v t="ekr.20210805090544.1"><vh>test issues...</vh>
<v t="ekr.20180901040718.1"><vh>test_bug2_empty</vh></v>
<v t="ekr.20180901044640.1"><vh>test_bug2_non_empty</vh></v>
<v t="ekr.20180901051603.1"><vh>test_bug3</vh></v>
</v>
<v t="ekr.20210805090943.1"><vh>test_ast_formatter_class</vh>
<v t="ekr.20210805144859.1"><vh>&lt;&lt; define tests &gt;&gt; (test_ast_formatter_class)</vh></v>
</v>
<v t="ekr.20210806011736.1"><vh>test_ast_formatter_class_on_file</vh></v>
<v t="ekr.20210805091045.1"><vh>test class ReduceTypes (mostly complete)</vh>
<v t="ekr.20210804105256.1"><vh>test_reduce_numbers</vh></v>
<v t="ekr.20210804111613.1"><vh>test_reduce_types</vh></v>
<v t="ekr.20210804111803.1"><vh>test_split_types</vh></v>
</v>
<v t="ekr.20210804103146.1"><vh>test class Pattern (mostly complete)</vh></v>
<v t="ekr.20210804112556.1"><vh>test class Stub (complete)</vh></v>
<v t="ekr.20210805092921.1"><vh>test class StubTraverser</vh>
<v t="ekr.20210804111915.1"><vh>test_st_find</vh></v>
<v t="ekr.20210804112211.1"><vh>test_st_flatten_stubs</vh></v>
<v t="ekr.20210804112405.1"><vh>test_st_merge_stubs</vh>
<v t="ekr.20210804112405.3"><vh>&lt;&lt; old_stubs &gt;&gt;</vh></v>
<v t="ekr.20210804112405.4"><vh>&lt;&lt; new_stubs &gt;&gt;</vh></v>
</v>
</v>
<v t="ekr.20210805093615.1"><vh>test file: make_stub_files.py</vh></v>
<v t="ekr.20210805093004.1"><vh>test top-level functions</vh>
<v t="ekr.20210806153836.1"><vh>test_finalize</vh></v>
<v t="ekr.20210806154007.1"><vh>test_is_known_type</vh></v>
<v t="ekr.20160207115947.1"><vh>test_truncate</vh></v>
</v>
</v>
</v>
<v t="ekr.20210806162349.1"><vh>--- changed visitors</vh>
<v t="ekr.20160318141204.31"></v>
<v t="ekr.20160318141204.35"></v>
<v t="ekr.20160318141204.20"></v>
<v t="ekr.20210804214511.1"></v>
<v t="ekr.20160318141204.18"></v>
<v t="ekr.20160318141204.91"></v>
<v t="ekr.20160318141204.75"></v>
<v t="ekr.20160318141204.83"></v>
<v t="ekr.20160318141204.18"></v>
</v>
<v t="ekr.20210804060105.1"></v>
<v t="ekr.20210805090943.1"></v>
<v t="ekr.20210805144859.1"></v>
<v t="ekr.20210807105513.1"><vh>--- To do: ###</vh>
<v t="ekr.20210807105645.1"><vh>--- msf</vh>
<v t="ekr.20160318141204.135"></v>
<v t="ekr.20160318141204.138"></v>
<v t="ekr.20160318141204.139"></v>
<v t="ekr.20160318141204.140"></v>
</v>
<v t="ekr.20210807105658.1"><vh>--- Pattern</vh>
<v t="ekr.20160318141204.111"></v>
<v t="ekr.20160318141204.113"></v>
</v>
<v t="ekr.20160318141204.118"></v>
<v t="ekr.20210807105711.1"><vh>--- StubFormatter</vh>
<v t="ekr.20160318141204.160"></v>
<v t="ekr.20160318141204.162"></v>
<v t="ekr.20160318141204.164"></v>
<v t="ekr.20160318141204.91"></v>
<v t="ekr.20160318141204.154"></v>
<v t="ekr.20160318141204.155"></v>
<v t="ekr.20160318141204.165"></v>
<v t="ekr.20160318141204.156"></v>
<v t="ekr.20160318141204.149"></v>
<v t="ekr.20160318141204.166"></v>
<v t="ekr.20160318141204.158"></v>
<v t="ekr.20160318141204.167"></v>
</v>
<v t="ekr.20210807105731.1"><vh>--- StubTraverser</vh>
<v t="ekr.20160318141204.188"></v>
<v t="ekr.20160318141204.190"></v>
<v t="ekr.20160318141204.175"></v>
<v t="ekr.20160318141204.176"></v>
<v t="ekr.20160318141204.186"></v>
<v t="ekr.20160318141204.194"></v>
</v>
</v>
<v t="ekr.20160318141204.26"></v>
<v t="ekr.20160318141204.84"></v>
<v t="ekr.20160318141204.85"></v>
</vnodes>
<tnodes>
<t tx="ekr.20160126153220.1">@language config

# A configuration file to make stubs for make_stub_files.py itself.

[Global]

files: make_stub_files.py
    
output_directory: .
    
prefix_lines:
    from typing import Any, Dict, Optional, Sequence, Tuple, Union
        # At present, I don't understand how to tell mypy about ast.Node
        # import ast
        # Node = ast.Node
    Node = Any

[Def Name Patterns]

# The returns are inherent in the design of make_stub_files.py:
AstFormatter.do_*: str
StubFormatter.do_*: str
StubTraverser.do_*: str

# Test of regex pattern.
.*__hash__$: int

# Pattern.all_matches: Sequence
# Pattern.full_balanced_match: Optional[int]
# Pattern.match_balanced: int
# Pattern.match_entire_string: bool
# StandAloneMakeStubFile.scan_types: Dict[str, str]

# StubTraverser.format_returns: str
# StubTraverser.match_return_patterns: Tuple[bool,str]
# StubTraverser.match_return_pattern: Optional[str]
# StubTraverser.match_balanced: int

[General Patterns]

# Declarations of names...
NotImplemented: bool
a: str
aList: List[Any]
comments: str
controller: StandAloneMakeStubFile
find_s: str
fn: str
found: str
general_patterns: List[Pattern]
group: str
i1: int
i2: int
i: int
j1: int
j2: int
j: int
n1: int
n2: int
n: int
name: str
ndots: int
node: Node
parser: optparse.OptionParser
patterns: List
repl_s: str
s: str
s1: str
s2: str
# s[1-2]?$: str
strict: bool
trace: bool
# New known functions
endswith(*): bool 

# Known functions...
os.path.basename(*): str
os.sep.join(*): str
sep.join(*): str
self.__eq__(*): bool
self.__ne__(*): bool
self.__gt__(*): bool
self.__lt__(*): bool
all(*): bool
any(*): bool

int(*): int
hash(*): int
len(*): int
repr(*): str
sorted(*): str
str%(*): str
str.join(*): str
r[*]: str
# Put this in the code.
str[*]: str
###.*\.__name__$: str
###.*\.hash()$: int
</t>
<t tx="ekr.20160128102557.1"># An example configuration file for make_stub_files.py.
# By default, make_stub_files.py uses ~/stubs/make_stub_files.cfg.
# Can be changed using the --config=path command-line option.

[Global]

files:
    
    # Files to be used *only* if no files are given on the command line.
    # glob.glob wildcards are supported.
    
output_directory: ~/stubs
    
prefix_lines:
    # Lines to be inserted at the start of each stub file.

    from typing import TypeVar
    T = TypeVar('T', int, float, complex)
    
# Notes about patterns used below:
#
#  **Balanced patterns** contain either (*), [*], or {*}.
#  Unlike regular expressions, balanced patterns match only balanced brackets.
#
#  Both regex and balanced patterns may appear in each section.
#  However, balanced patterns will never match argument names.
#
#  Patterns are matched in the order they appear in each section,
#  but the .* pattern (if present) will match last, regardless of its
#  position in the section.
    
[Def Name Patterns]

# These regex patterns give the return types of functions or methods.
#
# Patterns for methods should match class_name.method_name.
#
# Patterns in this section *override* all other patterns,
# so you should use these patterns only if:
#
# - No other pattern properly handles the function or method, or
#
# - The pattern specifies functions that should all return the same value.
#   For example, all ast tree traversers should have the same signatures.
#
# It may be unwise to use .* in this section, but the choice is yours.

[Argument Patterns]

# The regex patterns in this section apply only when assigning types
# to *arguments* to functions or methods. Patterns match argument names.
# Typically, most patterns can be put [General Patterns] section instead.

[General Patterns]

# The patterns in this section may be either regex or balanced patterns.
# Patterns in this section are applied both to arguments and return expressions.
# These patterns are applied *once* to argument names and *repeatedly* to
# return types until no further matches can be made.

aList[1-3]?: Sequence
i: int
j: int
k: int
node: ast.Ast
s[1-3]?: str

[Return Patterns]

# The patterns in this section may be either regex or balanced patterns.
# Patterns in this section are applied only to return expressions.
# These patterns are applied *repeatedly* to return expressions
# until no further matches can be made.

# Balanced patterns...

repr(*): str
str.join(*): str
str.replace(*): str
str%(*): str
str%str: str

# Regex patterns...

.*__name__: str
</t>
<t tx="ekr.20160128104714.1"></t>
<t tx="ekr.20160128225533.1">*.pyc
*.pyi
test/*.pyc
__pycache__/
.mypy_cache/
.cache/
.coverage
htmlcov/
</t>
<t tx="ekr.20160207051429.1">def test_merge_types(self):

    a, c, f, i, l, n = ('Any', 'complex', 'float', 'int', 'long', 'number')
    none = 'None'
    La, Lc = ['Any'], ['complex']
    Lac, Lai, Lan = ['Any', 'complex'], ['Any', 'int'], ['Any', 'None']
    Laci = ['Any', 'complex', 'int']
    Lnone = ['None']
    table = (
        (none, Lnone,   Lnone),
        (none, none,    Lnone),
        (a, none,       Lan),
        (a, a,          La),
        (La, a,         La),
        (Lac, a,        Lac),
        (Lac, i,        Laci),
        (Lac, Lai,      Laci),
    )
    for a1, a2, expected in table:
        got = merge_types(a1, a2)
        self.assertEqual(expected, got)
</t>
<t tx="ekr.20160207101607.1">@language rest
@wrap

This is the theory-of-operation document for the `make_stub_files` script. It is intentionally brief. Please [ask questions](#summary) if anything is unclear.

### Prerequisites

Maintainers should be familiar with the following:

- The [Python 3 ast class](https://docs.python.org/3/library/ast.html).
  You should know what a tree traversal is.
- [Pep 484](https://www.python.org/dev/peps/pep-0484/) and
  [Python's typing module](https://docs.python.org/3/library/typing.html).
  Having a clear **target language** greatly simplifies this project.
  
You don't need to know anything about type inference.

### High level description

This script is a modified code formatter. This script traverses the incoming ast tree *once* from the top down, generating results from the bottom up. There is only a *single* traversal, composed of four traversal classes. (See [below](#traversers) for details). This traversal produces a stub for every class and def line. To do this, it **replaces expressions with type hints**. In other words, the goal is to **reduce** expressions to **known types**, as defined by Pep 484.

The StubFormatter visitors do most of the work of type reduction. They delegate type reduction to the following helpers:

1. **`ReduceTypes.reduce_types(aList)`** reduces a *list* of 0 or more types to a *string* representing a type hint. It returns 'Any' for unknown types. At the top of the traversal, StubTraverser.do_FunctionDef also calls reduce_types (via helpers) on the list of all return expressions.

2. **`StubFormatter.match_all(node, s)`** applies all user-patterns to s and returns the result.

3. **`ReduceTypes.is_known_type(s)`** embodies the known types as defined in Pep 484 and the typing module.

In short, visitors are hardly more complex than the corresponding AstFormatter methods.

**Notes**:

- The `sf.do_Attribute` and `sf.do_Name` visitors look up names in `sf.names_dict`. This is much faster than matching patterns.

- `sf.match_all` is very fast because it only applies patterns that *could possibly* match at the node being visited. Those patterns are:

        self.patterns_dict.get(node.__class__.__name__, []) + self.regex_patterns
        
  That is, all regex patterns are applied "everywhere" in return expressions.

- The startup code create `names_dict`, `patterns_dict` and `regex_patterns` data structures. That's all you have to know about the startup code.

- The Pattern class handles almost all details of pattern matching. This shields the rest of the code from knowledge of patterns. In particular, `sf.match_all` knows nothing about patterns.

### Examples

A few examples may make this script's operation clearer. The --trace-matches and --trace-reduce switches turn on detailed traces that show exactly when and where reductions happen, and what the resulting type hints are. These traces are the truth.  Believe them, not words here.

Given the file truncate.py:

    def truncate(s, n):
        """Return s truncated to n characters."""
        return s if len(s) &lt;= n else s[:n-3] + '...'
        
The script produces this output with the --verbose option in effect:

    def truncate(s: str, n: int) -&gt; str: ...
        #   0: return s if len(s)&lt;=n else s[:n-3]+'...'
        #   0: return str
        
Here is the output with --trace-reduce --trace-matches in effect:

    make_stub_files.py -c make_stub_files.cfg truncate.py -v -o --trace-reduce --trace-matches
    
    callers                     pattern                types ==&gt; hint    
    =======                     =======         ========================
    reduce_types: do_BinOp                      [int, number] ==&gt; number
    match_all:    do_Subscript  str[*]: str      str[:number] ==&gt; str
    reduce_types: do_IfExp                               str] ==&gt; str

Finally, here is *part* of the result of tracing make_stub_files.py itself::

          context                   pattern                                                          types ==&gt; hint    
    =============================== ================ =========================================================================
    reduce_types: do_IfExp                                                    [bool, is_known_type(inner)] ==&gt; ? Any
    reduce_types: do_IfExp                                                    [bool, is_known_type(inner)] ==&gt; ? Any
    match_all:    do_Call           all(*): bool                  all(is_known_type(z.strip()) for z in... ==&gt; bool
    reduce_types: is_known_type                                                                [Any, bool] ==&gt; Union[Any, bool]
    match_all:    do_Call           sorted(*): str                                      sorted(Set[r1+r2]) ==&gt; str
    reduce_types: show                                  [show_helper(List[Any][:], known, str, str, bool)] ==&gt; ? Any
    match_all:    do_Subscript      r[*]: str                                                    r[number] ==&gt; str
    match_all:    do_Call           str.join(*): str                                         str.join(str) ==&gt; str
    reduce_types: reduce_types                       [show(str), show(str, known=bool), show_helper(Li...] ==&gt; ? Any
    reduce_types: do_BinOp                                                                   [int, number] ==&gt; number
    match_all:    do_Subscript      str[*]: str                                               str[:number] ==&gt; str
    reduce_types: do_IfExp                                                                           [str] ==&gt; str
    
    class AstFormatter
    
    reduce_types: do_BoolOp                                                              [val, val.strip()] ==&gt; ? Any
    reduce_types: do_BoolOp                                                                      [Any, str] ==&gt; Union[Any, str]
    reduce_types: visit                                                                               [str] ==&gt; str
    reduce_types: do_IfExp                                                                            [str] ==&gt; str
    match_all:    do_Call           repr(*): str                                               repr(Node.n) ==&gt; str
    reduce_types: get_import_names                                                                 [result] ==&gt; ? Any
    reduce_types: kind                                                            [Node.__class__.__name__] ==&gt; ? Any
    
This trace contains all essential data concerning pattern matching and type reduction.

Enable tracing in various visitors if you need more data.

&lt;a name="traversers"/&gt;
### Traversers

As stated above, this script traverses the parse tree *once*, using four different traversal classes. Each traverser produces the results needed at a particular point of the traversal. Imo, using separate traversal classes is good style, even though it would be straightforward to use a single class. Indeed, each class has a distinct purpose...

#### AstFormatter

This is the base formatter class. It defines the default formatting for each kind of node. More importantly, it emphasizes that subclasses must return strings, *never* lists. The `AstFormatter.visit` method checks that this is so. This assertion guarantees that subclasses must call `st.reduce_types` to convert a list of possible types into a single string representing their union.

#### StubTraverser

This class drives the traversal. It is a subclass of ast.NodeVisitor. No custom visit method is needed. Visitors are *not* formatters--they *use* formatters to produce stubs. This class overrides only the visitors for ClassDef, FunctionDef and Return ast nodes. The FunctionDef visitor invokes the StubFormatter class to format all the functions return statements. The FunctionDef visitor invokes the AstArgFormatter to format names in argument lists.

#### StubFormatter

This class formats return statements. The overridden visitors of this class replace constants and operators with their corresponding type hints. The do_BinOp method contains hard-coded patterns for creating type hints. More could be added. The script is truly simple because the visitor methods of this class are hardly more complex than the corresponding methods of the AstFormatter class.

### AstArgFormatter

This class works just like the StubFormatter class except that does *not* apply patterns to Name nodes. As the name implies, it is used to format arguments in function definitions. It could easily be merged into the StubFormatter class, but imo having a separate class is cleaner and even a bit safer.

### Unit testing

August, 2021: make_stub_files.py now contains traditional unit tests.  See the TestMakeStubFiles class.

Run these unit tests with:

    cd make_stub_files
    python -m unittest make_stub_files
    
Run coverage tests with:

    cd make_stub_files
    python -m pytest --cov-report html --cov-report term-missing --cov make_stub_files make_stub_files.py

&lt;a name="summary"/&gt;
### Summary

make_stub_files.py is a straightforward tree traversal. Or so it seems to me.
Please feel free to ask questions.

Edward K. Ream  
edreamleo@gmail.com</t>
<t tx="ekr.20160207115947.1">def test_truncate(self):
    table = (
        ('abc',     'abc'),
        ('abcd',    'abcd'),
        ('abcde',   'abcde'),
        ('abcdef',  'ab...'),
        ('abcdefg', 'ab...'),
    )
    for s1, s2 in table:
        got = truncate(s1, 5)
        self.assertEqual(s2, got, msg=f"s1: {s1!r}")
</t>
<t tx="ekr.20160207181637.1"></t>
<t tx="ekr.20160207181648.1"></t>
<t tx="ekr.20160207182535.1"></t>
<t tx="ekr.20160211110739.1">@language rest
@wrap

This is the readme file for `make_stub_files.py`. This file explains what the script does, how it works and why it is important. After a brief overview, a step-by-step section will get you started. Full source code for make_stub_files.py is in its [github repository](https://github.com/edreamleo/make-stub-files). Everything is in the public domain.

Before reading further, please be aware of two other tools that create mypy stubs:

- [MonkeyType](https://monkeytype.readthedocs.io/en/latest/index.html) (Python 3),
- [PyAnnotate](https://github.com/dropbox/pyannotate),
- [stubgen](https://mypy.readthedocs.io/en/stable/stubgen.html).

stubgen produces only minimal stubs, but MonkeyType and PyAnnotate are worth serious consideration.

@others</t>
<t tx="ekr.20160211110807.1">
### Overview

This script makes a stub (.pyi) file in the **output directory** for each **source file** listed on the command line (wildcard file names are supported). This script never creates directories automatically, nor does it overwrite stub files unless the --overwrite command-line option is in effect.

GvR says, "We actually do have a [stub generator](https://github.com/JukkaL/mypy/blob/master/mypy/stubgen.py) as part of mypy now (it has a few options) but yours has the advantage of providing a way to tune the generated signatures...This allows for a nice iterative way of developing stubs."

The script does no type inference. Instead, the user supplies **patterns** in a configuration file. The script matches these patterns to:

1. The names of arguments in functions and methods and

2. The text of **return expressions**. Return expressions are the actual text of whatever follows the "return" keyword. The script removes all comments in return expressions and converts all strings to "str". This **preprocessing** greatly simplifies pattern matching.

As a first example, given the method:

    def foo(self, i, s):
        if i:
            return "abc" # a comment
        else:
            return s
        
and the patterns:

    i: int
    s: str
    
the script produces the stub:

    def foo(i: int, s: str) --&gt; str: ...

`make_stub_files` eliminates much of the drudgery of creating [python stub (.pyi) files](https://www.python.org/dev/peps/pep-0484/#stub-files) from python source files. Stub files can be used by people who use Python 2.x code bases.

</t>
<t tx="ekr.20160211110810.1">
### Command-line arguments

    usage: make_stub_files.py [options] file1, file2, ...

    make_stub_file: Create stub (.pyi) files from python files
    
    positional arguments:
      FILE                  input files
    
    optional arguments:
      -h, --help            show this help message and exit
      -c FILE, --config FILE
                            full path to configuration file
      -d DIR, --dir DIR     full path to the output directory
      -f, --force-pyx       force the parsing of .pyx files
      -o, --overwrite       overwrite existing stub (.pyi) files
      -s, --silent          run without messages
      --trace-matches       trace Pattern.matches
      --trace-patterns      trace pattern creation
      --trace-reduce        trace st.reduce_types
      --trace-visitors      trace visitor methods
      -u, --update          update stubs in existing stub file
      -v, --verbose         verbose output in .pyi file
      -w, --warn            warn about unannotated args

*Note*: glob.glob wildcards can be used in file1, file2, ...
</t>
<t tx="ekr.20160211110810.2">
### The configuration file

The --config command-line option specifies the full path to the optional configuration file. The configuration file uses the .ini format. It has several configuration sections, all optional.

</t>
<t tx="ekr.20160211110810.3">
### Why this script is important

The script eliminates most of the drudgery from creating stub files. The script produces syntactically and semantically correct stub files without any patterns at all. Patterns make it easy to make stubs more specific.

Once we create stub files, mypy will check them by doing real type inference. This will find errors both in the stub files and in the program under test. There is now an easy way to use mypy!

Stubs express design intentions and intuitions as well as types. Until now, there has been no practical way of expressing and *testing* these assumptions. Now there is.

Using mypy, we can be as specific as we like about types. We can simply annotate that d is a dict, or we can say that d is a dict whose keys are strings and whose values are executables with a union of possible signatures. Stubs are the easy way to play with type inference.

Finally, stubs can simplify the general type inference problem. Without type hints or annotations, the type of everything depends on the type of everything else. Stubs could allow robust, maybe even complete, type inference to be done locally. Stubs help mypy to work faster.
</t>
<t tx="ekr.20160211110811.1">
### Summary

The make-stub-files script does for type/design analysis what Leo's c2py command did for converting C sources to python. It eliminates much of the drudgery associated with creating stub files, leaving the programmer to make non-trivial inferences.

Stub files allow us to explore type checking using mypy as a guide and helper. Stub files are both a design document and an executable, checkable, type specification. Stub files allow those with a Python 2 code base to use mypy.

One could imagine a similar insert_annotations script that would inject function annotations into source files using stub files as data. The "reverse" script should be more straightforward than this script.

Edward K. Ream  
January 25 to February 15, 2016
Revised, August 5, 2021.
</t>
<t tx="ekr.20160211111807.1">
#### Patterns

The [Def Name Patterns] and [General Patterns] configuration sections
specify patterns. All patterns have the form:

    find-string: replacement-string
    
Colons are not allowed in the find-string. This is a limitation of .ini files.

There are three kinds of patterns: balanced, regex and plain.

**Balanced patterns** are patterns whose find string that:

A: contain either `(*)`, `[*]`, or `{*}` or

B: ends with `*`.

Unlike regular expressions, `(*)`, `[*]`, or `{*}` match only
balanced brackets. A trailing `*` matches the rest of the string.

Examples:

    str(*): str
    StubTraverser.do_*
    
Balanced patterns such as:

    [*]: List[*]

work as expected. The script replaces the `*` in replacement-strings with
whatever matched `*` in the find-string.

**Regex patterns** (regular expression patterns) are denoted by a
find-string that ends with `$`. The trailing `$` does not become part of
the find-string. For example:

    ab(.*)de$: de\1\1ab

A pattern is a **plain pattern** if it is neither a balanced nor a regex
pattern.

The script matches patterns to *all parts* of return expressions.

*Important*: The script applies patterns *separately* to each return
expression. Comments never appear in return expressions, and all strings in
return values appear as str. As a result, there is no context to worry
about context in which patterns are matched. Very short patterns suffice.

</t>
<t tx="ekr.20160211111823.1">
#### [Global]

This configuration section specifies the files list, prefix lines and
output directory. For example:

    [Global]

    files:
        # Files to be used *only* if no files are given on the command line.
        # glob.glob wildcards are supported.
        ~/leo-editor/leo/core/*.py
        
    output_directory:
        # The output directory to be used if no --dir option is given.
        ~/stubs
        
    prefix:
        # Lines to be inserted at the start of each stub file.
        from typing import TypeVar, Iterable, Tuple
        T = TypeVar('T', int, float, complex)
</t>
<t tx="ekr.20160211111839.1">
#### [Def Name Patterns]

The script matches the find-strings in this section against names of
functions and methods. For methods, the script matches find-strings against
names of the form:

    class_name.method_name

When a find-string matches, the replacement-string becomes the return type
in the stub, without any further pattern matching. That is, this section
*overrides* [General Patterns].

Example 1:

    [Def Name Patterns]
    myFunction: List[str]
    
Any function named myFunction returns List[str].

Example 2:

    [Def Name Patterns]
    MyClass.myMethod: str
    
The myMethod method of the MyClass class returns str.

Example 3:

    [Def Name Patterns]
    MyClass.do_*: str
    
All methods of the MyClass class whose names start with "do_" return str.
</t>
<t tx="ekr.20160211111901.1">
#### [General Patterns]

For each function or method, the script matches the patterns in this
section against **all parts** of all return expressions in each function or method.

The intent of the patterns in this section should be to **reduce** return
expressions to **known types**. A known type is a either a name of a type
class, such as int, str, long, etc. or a **type hint**, as per
[Pep 484](https://www.python.org/dev/peps/pep-0484/).

The script *always* produces a syntactically correct stub, even if the
patterns do not reduce the return expression to a known type. For unknown
types, the script does the following:

1. Uses Any as the type of the function or method.

2. Follows the stub with a list of comments giving all the return
   expressions in the function or method.
   
For example, suppose that the patterns are not sufficient to resolve the
return type of:

    def foo(a):
        if a:
            return a+frungify(a)
        else:
            return defrungify(a)
         
The script will create this stub:

    def foo(a) --&gt; Any: ...
        # return a+frungify(a)
        # return defrungify(a)
        
The comments preserve maximal information about return types, which should
help the user to supply a more specific return type. The user can do this
in two ways by altering the stub files by hand or by adding new patterns to
the config file.
</t>
<t tx="ekr.20160211113019.1">
### Quick Start

1. Put `make_stub_files.py` on your path.

2. Enter a directory containing .py files:

        cd myDirectory
    
3. Generate stubs for foo.py in foo.pyi:

        make_stub_files foo.py

4. Look at foo.pyi to see the generated stubs.

5. Regenerate foo.pyi with more verbose output:

        make_stub_files foo.py -o -v

   The -o (--overwrite) option allows the script to overwrite foo.pyi.  
   The -v (--verbose) options generates return comments for all stubs in foo.pyi.
   
6. Update foo.pyi:

        make_stub_files -o -u
        
   The -u (--update) options updates foo.pyi as follows:
   
   - adds stubs to foo.pyi for classes and defs that are new in foo.py.
   - deletes stubs in foo.pyi for classes and defs that no longer exist in foo.py.
   - leaves all other stubs in foo.pyi unchanged.
   
7. Specify a configuration file containing patterns:

        make_stub_files -c myConfigFile.cfg -o
</t>
<t tx="ekr.20160318141204.102">class Pattern:
    """
    A class representing regex or balanced patterns.
    
    Sample matching code, for either kind of pattern:
        
        for m in reversed(pattern.all_matches(s)):
            s = pattern.replace(m, s)
    """
    @others
</t>
<t tx="ekr.20160318141204.103">def __init__(self, find_s, repl_s=''):
    """Ctor for the Pattern class."""
    self.find_s = find_s
    self.repl_s = repl_s
    if self.is_regex():
        self.regex = re.compile(find_s)
    elif self.is_balanced():
        self.regex = None
    else:
        # Escape all dangerous characters.
        result = []
        for ch in find_s:
            if ch == '_' or ch.isalnum():
                result.append(ch)
            else:
                result.append('\\' + ch)  # pragma: no cover
        self.regex = re.compile(''.join(result))
</t>
<t tx="ekr.20160318141204.104">def __eq__(self, obj):
    """Return True if two Patterns are equivalent."""
    if isinstance(obj, Pattern):
        return self.find_s == obj.find_s and self.repl_s == obj.repl_s
    return NotImplemented  # pragma: no cover

def __ne__(self, obj):
    """Return True if two Patterns are not equivalent."""
    return not self.__eq__(obj)

def __hash__(self):
    """Pattern.__hash__"""
    return len(self.find_s) + len(self.repl_s)
</t>
<t tx="ekr.20160318141204.105">def __repr__(self):  # pragma: no cover
    """Pattern.__repr__"""
    return '%s: %s' % (self.find_s, self.repl_s)

__str__ = __repr__
</t>
<t tx="ekr.20160318141204.106">def is_balanced(self):
    """Return True if self.find_s is a balanced pattern."""
    s = self.find_s
    if s.endswith('*'):
        return True
    for pattern in ('(*)', '[*]', '{*}'):
        if s.find(pattern) &gt; -1:
            return True
    return False
</t>
<t tx="ekr.20160318141204.107">def is_regex(self):
    """
    Return True if self.find_s is a regular pattern.
    For now a kludgy convention suffices.
    """
    return self.find_s.endswith('$')
        # A dollar sign is not valid in any Python expression.
</t>
<t tx="ekr.20160318141204.108">def all_matches(self, s):
    """
    Return a list of match objects for all matches in s.
    These are regex match objects or (start, end) for balanced searches.
    """
    if self.is_balanced():
        aList, i = [], 0
        while i &lt; len(s):
            progress = i
            j = self.full_balanced_match(s, i)
            if j is None:
                i += 1#   pragma: no cover
            else:
                aList.append((i, j),)
                i = j
            assert progress &lt; i
        return aList
    return list(self.regex.finditer(s))
</t>
<t tx="ekr.20160318141204.109">def full_balanced_match(self, s, i):
    """Return the index of the end of the match found at s[i:] or None."""
    pattern = self.find_s
    j = 0  # index into pattern
    while i &lt; len(s) and j &lt; len(pattern) and pattern[j] in ('*', s[i]):
        progress = i
        if pattern[j : j + 3] in ('(*)', '[*]', '{*}'):
            delim = pattern[j]
            i = self.match_balanced(delim, s, i)
            j += 3
        elif j == len(pattern) - 1 and pattern[j] == '*':
            # A trailing * matches the rest of the string.
            j += 1
            i = len(s)
            break
        else:
            i += 1
            j += 1
        assert progress &lt; i
    found = i &lt;= len(s) and j == len(pattern)
    return i if found else None
</t>
<t tx="ekr.20160318141204.110">def match_balanced(self, delim, s, i):
    """
    delim == s[i] and delim is in '([{'
    Return the index of the end of the balanced parenthesized string, or len(s)+1.
    """
    global g_input_file_name
    assert s[i] == delim, s[i]
    assert delim in '([{'
    delim2 = ')]}'['([{'.index(delim)]
    assert delim2 in ')]}'
    level = 0
    while i &lt; len(s):
        progress = i
        ch = s[i]
        i += 1
        if ch == delim:
            level += 1
        elif ch == delim2:
            level -= 1
            if level == 0:
                return i
        assert progress &lt; i
    # Unmatched: a syntax error.
    print('%20s: unmatched %s in %s' % (g_input_file_name, delim, s))  # pragma: no cover
    return len(s) + 1  # pragma: no cover
</t>
<t tx="ekr.20160318141204.111">def match(self, s, trace=False):  ###
    """
    Perform the match on the entire string if possible.
    Return (found, new s)
    """
    if self.is_balanced():
        j = self.full_balanced_match(s, 0)
        if j is None:
            return False, s
        start, end = 0, len(s)
        s = self.replace_balanced(s, start, end)
        return True, s
    m = self.regex.match(s)
    if m and m.group(0) == s:
        s = self.replace_regex(m, s)
        return True, s
    return False, s
</t>
<t tx="ekr.20160318141204.112">def match_entire_string(self, s):
    """Return True if s matches self.find_s"""
    if self.is_balanced():
        j = self.full_balanced_match(s, 0)
        return j == len(s)
    m = self.regex.match(s)
    return m and m.group(0) == s
</t>
<t tx="ekr.20160318141204.113">def replace(self, m, s):  ###
    """Perform any kind of replacement."""
    if self.is_balanced():
        start, end = m
        return self.replace_balanced(s, start, end)
    return self.replace_regex(m, s)
</t>
<t tx="ekr.20160318141204.114">def replace_balanced(self, s1, start, end):
    """
    Use m (returned by all_matches) to replace s by the string implied by repr_s.
    Within repr_s, * star matches corresponding * in find_s
    """
    s = s1[start:end]
    f, r = self.find_s, self.repl_s
    i1 = f.find('(*)')
    i2 = f.find('[*]')
    i3 = f.find('{*}')
    if -1 == i1 == i2 == i3:
        return s1[:start] + r + s1[end:]
    j = r.find('*')
    if j == -1:
        return s1[:start] + r + s1[end:]
    i = min([z for z in [i1, i2, i3] if z &gt; -1])
    assert i &gt; -1  # i is an index into f AND s
    delim = f[i]
    assert s[:i] == f[:i], (s[:i], f[:i])
    k = self.match_balanced(delim, s, i)
    s_star = s[i + 1 : k - 1]
    repl = r[:j] + s_star + r[j + 1 :]
    return s1[:start] + repl + s1[end:]
</t>
<t tx="ekr.20160318141204.115">def replace_regex(self, m, s):
    """Do the replacement in s specified by m."""
    s = self.repl_s
    for i in range(9):
        group = '\\%s' % i
        if s.find(group) &gt; -1:
            s = s.replace(group, m.group(i))
    return s
</t>
<t tx="ekr.20160318141204.116">class ReduceTypes:
    """
    A helper class for the top-level reduce_types function.
    
    This class reduces a list of type hints to a string containing the
    reduction of all types in the list.
    """
    @others
</t>
<t tx="ekr.20160318141204.117">def __init__(self, aList=None, name=None, trace=False):
    """Ctor for ReduceTypes class."""
    self.aList = aList
    self.name = name
    self.optional = False
    self.trace = trace
</t>
<t tx="ekr.20160318141204.118">def is_known_type(self, s):
    """
    Return True if s is nothing but a single known type.

    It suits the other methods of this class *not* to test inside inner
    brackets. This prevents unwanted Any types.
    """
    s = s.strip()
    table = (
        '', 'None',  # Tricky.
        'complex', 'float', 'int', 'long', 'number',
        'dict', 'list', 'tuple',
        'bool', 'bytes', 'str', 'unicode',
    )
    for s2 in table:
        if s2 == s:
            return True
        if Pattern(s2 + '(*)', s).match_entire_string(s):
            return True  ###
    if s.startswith('[') and s.endswith(']'):  ###
        inner = s[1:-1]
        return self.is_known_type(inner) if inner else True
    if s.startswith('(') and s.endswith(')'):  ###
        inner = s[1:-1]
        return self.is_known_type(inner) if inner else True
    if s.startswith('{') and s.endswith('}'):  ###
        return True
    table = (
        # Pep 484: https://www.python.org/dev/peps/pep-0484/
        # typing module: https://docs.python.org/3/library/typing.html
        # Test the most common types first.
        'Any', 'Dict', 'List', 'Optional', 'Tuple', 'Union',
        # Not generated by this program, but could arise from patterns.
        'AbstractSet', 'AnyMeta', 'AnyStr',
        'BinaryIO', 'ByteString',
        'Callable', 'CallableMeta', 'Container',
        'Final', 'Generic', 'GenericMeta', 'Hashable',
        'IO', 'ItemsView', 'Iterable', 'Iterator',
        'KT', 'KeysView',
        'Mapping', 'MappingView', 'Match',
        'MutableMapping', 'MutableSequence', 'MutableSet',
        'NamedTuple', 'OptionalMeta',
        # 'POSIX', 'PY2', 'PY3',
        'Pattern', 'Reversible',
        'Sequence', 'Set', 'Sized',
        'SupportsAbs', 'SupportsFloat', 'SupportsInt', 'SupportsRound',
        'T', 'TextIO', 'TupleMeta', 'TypeVar', 'TypingMeta',
        'Undefined', 'UnionMeta',
        'VT', 'ValuesView', 'VarBinding',
    )
    for s2 in table:
        if s2 == s:
            return True
        # Don't look inside bracketss.
        pattern = Pattern(s2 + '[*]', s)
        if pattern.match_entire_string(s):
            return True
    return False
</t>
<t tx="ekr.20160318141204.119">def reduce_collection(self, aList, kind):
    """
    Reduce the inner parts of a collection for the given kind.
    Return a list with only collections of the given kind reduced.
    """
    assert isinstance(aList, list)
    assert None not in aList, aList
    pattern = Pattern('%s[*]' % kind)
    others, r1, r2 = [], [], []
    for s in sorted(set(aList)):
        if pattern.match_entire_string(s):
            r1.append(s)
        else:
            others.append(s)
    for s in sorted(set(r1)):
        parts = []
        s2 = s[len(kind) + 1 : -1]
        for s3 in s2.split(','):
            s3 = s3.strip()
            parts.append(s3 if self.is_known_type(s3) else 'Any')
        r2.append('%s[%s]' % (kind, ', '.join(parts)))
    result = others
    result.extend(r2)
    return sorted(set(result))
</t>
<t tx="ekr.20160318141204.12">def pdb(self):  # pragma: no cover
    """Invoke a debugger during unit testing."""
    try:
        import leo.core.leoGlobals as leo_g
        assert leo_g
        # leo_g.pdb()
    except ImportError:
        import pdb
        pdb.set_trace()
</t>
<t tx="ekr.20160318141204.120">def reduce_numbers(self, aList):
    """
    Return aList with all number types in aList replaced by the most
    general numeric type in aList.
    """
    found = None
    numbers = ('number', 'complex', 'float', 'long', 'int')
    for kind in numbers:
        for z in aList:
            if z == kind:
                found = kind
                break
        if found:
            break
    if found:
        assert found in numbers, found
        aList = [z for z in aList if z not in numbers]
        aList.append(found)
    return aList
</t>
<t tx="ekr.20160318141204.121">def reduce_types(self):
    """
    self.aList consists of arbitrarily many types because this method is
    called from format_return_expressions.
    
    Return a *string* containing the reduction of all types in this list.
    Returning a string means that all traversers always return strings,
    never lists.
    """
    r = [('None' if z in ('', None) else z) for z in self.aList]
    assert None not in r
    self.optional = 'None' in r
        # self.show adds Optional if this flag is set.
    r = [z for z in r if z != 'None']
    if not r:
        self.optional = False
        return self.show('None')
    r = sorted(set(r))
    assert r
    assert None not in r
    r = self.reduce_numbers(r)
    for kind in ('Dict', 'List', 'Tuple',):
        r = self.reduce_collection(r, kind)
    r = self.reduce_unknowns(r)
    r = sorted(set(r))
    assert r
    assert 'None' not in r
    if len(r) == 1:
        return self.show(r[0])
    return self.show('Union[%s]' % (', '.join(sorted(r))))
</t>
<t tx="ekr.20160318141204.122">def reduce_unknowns(self, aList):
    """Replace all unknown types in aList with Any."""
    return [z if self.is_known_type(z) else 'Any' for z in aList]
</t>
<t tx="ekr.20160318141204.123">def show(self, s, known=True):  # pragma: no cover.
    """Show the result of reduce_types."""
    aList, name = self.aList, self.name
    trace = self.trace
    s = s.strip()
    if self.optional:
        s = 'Optional[%s]' % s
    if trace and (not known or len(aList) &gt; 1):
        if name:
            if name.find('.') &gt; -1:
                context = ''.join(name.split('.')[1:])
            else:
                context = name
        else:
            context = g.callers(3).split(',')[0].strip()
        context = truncate(context, 26)
        known = '' if known else '? '
        pattern = sorted(set([z.replace('\n', ' ') for z in aList]))
        pattern = '[%s]' % truncate(', '.join(pattern), 53 - 2)
        print('reduce_types: %-26s %53s ==&gt; %s%s' % (context, pattern, known, s))
            # widths above match the corresponding indents in match_all and match.
    return s
</t>
<t tx="ekr.20160318141204.124">def split_types(self, s):
    """Split types on *outer level* commas."""
    aList, i1, level = [], 0, 0
    for i, ch in enumerate(s):
        if ch == '[':
            level += 1
        elif ch == ']':
            level -= 1
        elif ch == ',' and level == 0:
            aList.append(s[i1:i])
            i1 = i + 1
    aList.append(s[i1:].strip())
    return aList
</t>
<t tx="ekr.20160318141204.125">class Controller:
    """
    Make Python stub (.pyi) files in the ~/stubs directory for every file
    in the [Source Files] section of the configuration file.
    """
    @others
</t>
<t tx="ekr.20160318141204.126">def __init__(self):
    """Ctor for Controller class."""
    self.options = {}
    # Ivars set on the command line...
    self.config_fn = None
    self.enable_coverage_tests = False
    self.enable_unit_tests = False
    self.files = []
    # Ivars set in the config file...
    self.output_fn = None
    self.output_directory = None
    self.overwrite = False
    self.prefix_lines = []
    self.silent = False
    self.trace_matches = False
    self.trace_patterns = False
    self.trace_reduce = False
    self.trace_visitors = False
    self.update_flag = False
    self.verbose = False  # Trace config arguments.
    self.warn = False
    # Pattern lists, set by config sections...
    self.section_names = ('Global', 'Def Name Patterns', 'General Patterns')
    self.def_patterns = []  # [Def Name Patterns]
    self.general_patterns = []  # [General Patterns]
    self.names_dict = {}
    self.op_name_dict = self.make_op_name_dict()
    self.patterns_dict = {}
    self.regex_patterns = []
</t>
<t tx="ekr.20160318141204.128">directory_warning_given = False

def make_stub_file(self, fn):  # pragma: no cover
    """
    Make a stub file in ~/stubs for all source files mentioned in the
    [Source Files] section of the configuration file.
    """
    global g_input_file_name
    extension = fn[fn.rfind('.'):]
    if not extension == '.py' and not (self.force_pyx and extension == '.pyx'):  
        print('not a python file', fn)
        return
    #
    # Read the input file.
    if not os.path.exists(fn):
        print('not found', fn)
        return
    # Set g_input_file_name for error messages.
    g_input_file_name = g.shortFileName(fn)
    try:
        with open(fn, 'r') as f:
            s = f.read()
    except UnicodeDecodeError:
        # Python 3 only, try utf-8 encoding.
        with open(fn, 'r', encoding='utf-8') as f:
            s = f.read()
    #
    # Compute the output file name.
    if self.output_directory:
        if not os.path.exists(self.output_directory):
            if not self.directory_warning_given:
                self.directory_warning_given = True
                print('output directory not found:', repr(self.output_directory))
            return
        base_fn = os.path.basename(fn)
        out_fn = os.path.join(self.output_directory, base_fn)
        out_fn = out_fn[:-len(extension)] + '.pyi'
    else:
        out_fn = fn[:-len(extension)] + '.pyi'
    self.output_fn = os.path.normpath(out_fn)
    #
    # Process s.
    node = ast.parse(s, filename=fn, mode='exec')
    StubTraverser(controller=self).run(node)
</t>
<t tx="ekr.20160318141204.131">def scan_command_line(self):  # pragma: no cover
    """Set ivars from command-line arguments."""
    # The parser implements the --help option.
    description = 'Create stub (.pyi) files using patterns, not type inference.'
    usage = 'make_stub_files.py [options] file1, file2, ...'
    parser = argparse.ArgumentParser(description=description, usage=usage)
    add = parser.add_argument
    add('files', metavar='FILE', type=str, nargs='+',
        help='input files')
    add('-c', '--config', dest='fn', metavar='FILE',
        help='full path to configuration file')
    add('-d', '--dir', dest='dir',
        help='full path to the output directory')
    add('-f', '--force-pyx', action='store_true', default=False,
        help='force the parsing of .pyx files')
    add('-o', '--overwrite', action='store_true', default=False,
        help='overwrite existing stub (.pyi) files')
    add('-s', '--silent', action='store_true', default=False,
        help='run without messages')
    add('--trace-matches', action='store_true', default=False,
        help='trace Pattern.matches')
    add('--trace-patterns', action='store_true', default=False,
        help='trace pattern creation')
    add('--trace-reduce', action='store_true', default=False,
        help='trace st.reduce_types')
    add('--trace-visitors', action='store_true', default=False,
        help='trace visitor methods')
    add('-u', '--update', action='store_true', default=False,
        help='update stubs in existing stub file')
    add('-v', '--verbose', action='store_true', default=False,
        help='verbose output in .pyi file')
    add('-w', '--warn', action='store_true', default=False,
        help='warn about unannotated args')
    # Parse.
    args = parser.parse_args()
    # Handle the args...
    self.overwrite = args.overwrite
    self.silent = args.silent
    self.trace_matches = args.trace_matches
    self.trace_patterns = args.trace_patterns
    self.trace_reduce = args.trace_reduce
    self.trace_visitors = args.trace_visitors
    self.update_flag = args.update
    self.verbose = args.verbose
    self.warn = args.warn
    self.force_pyx = args.force_pyx
    if args.fn:
        self.config_fn = args.fn
    if args.dir:
        dir_ = args.dir and args.dir.strip()
        dir_ = finalize(dir_)
        g.trace('dir', dir_)
        if os.path.exists(dir_):
            self.output_directory = dir_
        else:
            print('--dir: directory does not exist: %s' % dir_)
            print('exiting')
            sys.exit(1)
    if args.force_pyx:
        print('--force-pyx: .pyx files will be parsed as regular python, cython syntax is not supported')
    self.files = args.files
</t>
<t tx="ekr.20160318141204.132">def scan_options(self):  # pragma: no cover
    """Set all configuration-related ivars."""
    if self.verbose:
        print('')
        print(f"configuration file: {self.config_fn}")
    if not self.config_fn:
        return
    self.parser = parser = self.create_parser()
    s = self.get_config_string()
    self.init_parser(s)
    if self.files:
        files_source = 'command-line'
        files = self.files
        if isinstance(files, str):
            files = [files]
    elif parser.has_section('Global'):
        files_source = 'config file'
        files = parser.get('Global', 'files')
        files = [z.strip() for z in files.split('\n') if z.strip()]
    else:
        return
    if self.verbose:
        print(f"Files (from {files_source})...")
    files2 = []
    not_found = []
    for z in files:
        # Warn if z does not exist.
        files3 = glob.glob(finalize(z))
        if files3:
            if self.verbose:
                for z in files3:
                    print(f"  {z}")
            files2.extend(files3)
        else:
            not_found.append(z)
    if not_found:
        print('Not found...')
        for z in not_found:
            print(f"  {z}")
    self.files = files2
    if 'output_directory' in parser.options('Global'):
        s = parser.get('Global', 'output_directory').strip()
        output_dir = finalize(s)
        if os.path.exists(output_dir):
            self.output_directory = output_dir
            if self.verbose:
                print(f"output directory: {output_dir}")
        else:
            print(f"output directory not found: {output_dir}")
            self.output_directory = None  # inhibit run().
    if 'prefix_lines' in parser.options('Global'):
        prefix = parser.get('Global', 'prefix_lines')
        prefix_lines = prefix.split('\n')
            # The parser does not preserve leading whitespace.
        self.prefix_lines = [z for z in prefix_lines if z.strip()]
        # Annoying
            # if self.verbose:
                # print('Prefix lines...\n')
                # for z in self.prefix_lines:
                    # print('  %s' % z)
                # print('')
    if self.verbose:
        print('')
    self.def_patterns = self.scan_patterns('Def Name Patterns')
    self.general_patterns = self.scan_patterns('General Patterns')
    self.make_patterns_dict()
</t>
<t tx="ekr.20160318141204.133">def make_op_name_dict(self):
    """
    Make a dict whose keys are operators ('+', '+=', etc),
    and whose values are lists of values of ast.Node.__class__.__name__.
    """
    d = {
        '.': ['Attr',],
        '(*)': ['Call', 'Tuple',],
        '[*]': ['List', 'Subscript',],
        '{*}': ['???',],
        # 'and': 'BoolOp',
        # 'or':  'BoolOp',
    }
    for op in (
        '+', '-', '*', '/', '%', '**', '&lt;&lt;',
        '&gt;&gt;', '|', '^', '&amp;', '//',
    ):
        d[op] = ['BinOp',]
    for op in (
        '==', '!=', '&lt;', '&lt;=', '&gt;', '&gt;=',
        'is', 'is not', 'in', 'not in',
    ):
        d[op] = ['Compare',]
    return d
</t>
<t tx="ekr.20160318141204.134">def create_parser(self):  # pragma: no cover
    """Create a RawConfigParser and return it."""
    parser = configparser.RawConfigParser(dict_type=OrderedDict)
        # Requires Python 2.7
    parser.optionxform = str
    return parser
</t>
<t tx="ekr.20160318141204.135">def find_pattern_ops(self, pattern):  ###
    """Return a list of operators in pattern.find_s."""
    trace = False or self.trace_patterns
    if pattern.is_regex():  ###
        # Add the pattern to the regex patterns list.
        g.trace(pattern)
        self.regex_patterns.append(pattern)
        return []
    d = self.op_name_dict
    keys1, keys2, keys3, keys9 = [], [], [], []
    for op in d:
        aList = d.get(op)
        if op.replace(' ', '').isalnum():
            # an alpha op, like 'not, 'not in', etc.
            keys9.append(op)
        elif len(op) == 3:
            keys3.append(op)
        elif len(op) == 2:
            keys2.append(op)
        elif len(op) == 1:
            keys1.append(op)
        else:
            g.trace('bad op', op)  # pragma: no cover
    ops = []
    s = s1 = pattern.find_s
    for aList in (keys3, keys2, keys1):
        for op in aList:
            # Must match word here!
            if s.find(op) &gt; -1:
                s = s.replace(op, '')
                ops.append(op)
    # Handle the keys9 list very carefully.
    for op in keys9:
        target = ' %s ' % op
        ### if s.find(target) &gt; -1:
        if target in s:
            ops.append(op)  ###
            break  # Only one match allowed.
    if trace and ops: g.trace(s1, ops)
    return ops
</t>
<t tx="ekr.20160318141204.136">def get_config_string(self):  # pragma: no cover
    """Read the configuration file."""
    fn = finalize(self.config_fn)
    if os.path.exists(fn):
        with open(fn, 'r') as f:
            return f.read()
    print(f"\nconfiguration file not found: {fn}")
    return ''

</t>
<t tx="ekr.20160318141204.137">def init_parser(self, s):  # pragma: no cover
    """Add double back-slashes to all patterns starting with '['."""
    if not s:
        return
    aList = []
    for s in s.split('\n'):
        if self.is_section_name(s):
            aList.append(s)
        elif s.strip().startswith('['):
            aList.append(r'\\' + s[1:])
        else:
            aList.append(s)
    s = '\n'.join(aList) + '\n'
    file_object = io.StringIO(s)
    self.parser.read_file(file_object)
</t>
<t tx="ekr.20160318141204.138">def is_section_name(self, s):  ###

    def munge(s):
        return s.strip().lower().replace(' ', '')

    s = s.strip()
    if s.startswith('[') and s.endswith(']'):
        s = munge(s[1:-1])
        for s2 in self.section_names:
            if s == munge(s2):
                return True
    return False
</t>
<t tx="ekr.20160318141204.139">def make_patterns_dict(self):  ###
    """Assign all patterns to the appropriate ast.Node."""
    for pattern in self.general_patterns:
        ops = self.find_pattern_ops(pattern)
        if ops:
            for op in ops:
                # Add the pattern to op's list.
                op_names = self.op_name_dict.get(op)
                for op_name in op_names:
                    aList = self.patterns_dict.get(op_name, [])
                    aList.append(pattern)
                    self.patterns_dict[op_name] = aList
        else:
            # Enter the name in self.names_dict.
            name = pattern.find_s
            # Special case for 'number'
            if name == 'number':  ###
                aList = self.patterns_dict.get('Num', [])
                aList.append(pattern)
                self.patterns_dict['Num'] = aList
            elif name in self.names_dict:
                g.trace('duplicate pattern', pattern)  # pragma: no cover (user error)
            else:
                self.names_dict[name] = pattern.repl_s
    if 0:
        g.trace('names_dict...')
        for z in sorted(self.names_dict):
            print('  %s: %s' % (z, self.names_dict.get(z)))
    if 0:
        g.trace('patterns_dict...')
        for z in sorted(self.patterns_dict):
            aList = self.patterns_dict.get(z)
            print(z)
            for pattern in sorted(aList):
                print('  ' + repr(pattern))
    # Note: retain self.general_patterns for use in argument lists.
</t>
<t tx="ekr.20160318141204.14">class AstFormatter:
    """
    A class to recreate source code from an AST.
    
    This does not have to be perfect, but it should be close.
    """
    # pylint: disable=consider-using-enumerate

    @others
</t>
<t tx="ekr.20160318141204.140">def scan_patterns(self, section_name):  ###
    """Parse the config section into a list of patterns, preserving order."""
    trace = False or self.trace_patterns
    parser = self.parser
    aList = []
    if parser.has_section(section_name):
        seen = set()
        for key in parser.options(section_name):
            value = parser.get(section_name, key)
            # A kludge: strip leading \\ from patterns.
            if key.startswith(r'\\'):
                key = '[' + key[2:]  ###
            if key in seen:
                g.trace('duplicate key', key)  # pragma: no cover (user error)
            else:
                seen.add(key)
                aList.append(Pattern(key, value))
        if trace:  # pragma: no cover
            g.trace('%s...\n' % section_name)
            for z in aList:
                print(z)
            print('')
    return aList
</t>
<t tx="ekr.20160318141204.147">class StubFormatter(AstFormatter):
    """
    Formats an ast.Node and its descendants,
    making pattern substitutions in Name and operator nodes.
    """
    @others
</t>
<t tx="ekr.20160318141204.148">def __init__(self, controller, traverser):
    """Ctor for StubFormatter class."""
    self.controller = x = controller
    self.traverser = traverser
        # 2016/02/07: to give the formatter access to the class_stack.
    self.def_patterns = x.def_patterns
    self.general_patterns = x.general_patterns
    self.names_dict = x.names_dict
    self.patterns_dict = x.patterns_dict
    self.raw_format = AstFormatter().format
    self.regex_patterns = x.regex_patterns
    self.trace_matches = x.trace_matches
    self.trace_patterns = x.trace_patterns
    self.trace_reduce = x.trace_reduce
    self.trace_visitors = x.trace_visitors
    self.verbose = x.verbose
    # mypy workarounds
    self.seen_names = []
</t>
<t tx="ekr.20160318141204.149">matched_d = {}

def match_all(self, node, s, trace=False):  ###
    """Match all the patterns for the given node."""
    trace = trace or self.trace_matches
    # verbose = True
    d = self.matched_d
    name = node.__class__.__name__
    s1 = truncate(s, 40)
    caller = g.callers(2).split(',')[1].strip()
        # The direct caller of match_all.
    patterns = self.patterns_dict.get(name, []) + self.regex_patterns
    for pattern in patterns:
        found, s = pattern.match(s, trace=False)
        if found:
            if trace:  # pragma: no cover
                aList = d.get(name, [])
                if pattern not in aList:
                    aList.append(pattern)
                    d[name] = aList
                    print('match_all:    %-12s %26s %40s ==&gt; %s' % (caller, pattern, s1, s))
            break
    return s
</t>
<t tx="ekr.20160318141204.15">
# Entries...
</t>
<t tx="ekr.20160318141204.151">def trace_visitor(self, node, op, s):  # pragma: no cover
    """Trace node's visitor."""
    if self.trace_visitors:
        caller = g.callers(2).split(',')[1]
        s1 = AstFormatter().format(node).strip()
        print('%12s op %-6s: %s ==&gt; %s' % (caller, op.strip(), s1, s))
</t>
<t tx="ekr.20160318141204.152"># StubFormatter visitors for operands...
</t>
<t tx="ekr.20160318141204.153"># Attribute(expr value, identifier attr, expr_context ctx)

# attrs_seen = []

def do_Attribute(self, node):
    """StubFormatter.do_Attribute."""
    s = '%s.%s' % (
        self.visit(node.value),
        node.attr)  # Don't visit node.attr: it is always a string.
    s2 = self.names_dict.get(s)
    # if s2 and s2 not in self.attrs_seen:
        # self.attrs_seen.append(s2)
        # g.trace(s, '==&gt;', s2)
    return s2 or s
</t>
<t tx="ekr.20160318141204.154"># Return generic markers to allow better pattern matches.

def do_Contant(self, node):
    ### Experimental.
    name = node.value.__class__.__name__
    if name == 'ellipsis':
        return '...'
    return name

def do_Bytes(self, node):  # pragma: no cover (obsolete)
    return 'bytes'

def do_Num(self, node):  # pragma: no cover (obsolete)
    return 'number'

def do_Str(self, node):  # pragma: no cover (obsolete)
    """This represents a string constant."""
    return 'str'
</t>
<t tx="ekr.20160318141204.155">def do_Dict(self, node):  ###
    result = []
    keys = [self.visit(z) for z in node.keys]
    values = [self.visit(z) for z in node.values]
    if len(keys) == len(values):
        result.append('{')
        items = []
        # pylint: disable=consider-using-enumerate
        for i in range(len(keys)):
            items.append('%s:%s' % (keys[i], values[i]))
        result.append(', '.join(items))
        result.append('}')
    else:  # pragma: no cover (defensive)
        print('Error: f.Dict: len(keys) != len(values)\nkeys: %s\nvals: %s' % (
            repr(keys), repr(values)))
    return 'Dict[%s]' % ''.join(result) if result else 'Dict'
</t>
<t tx="ekr.20160318141204.156">def do_List(self, node):  ###
    """StubFormatter.List."""
    elts = [self.visit(z) for z in node.elts]
    elts = [z for z in elts if z]  # Defensive.
    return 'List[%s]' % ', '.join(elts) if elts else 'List'
</t>
<t tx="ekr.20160318141204.157"># seen_names = [] # t--ype: List[str]

def do_Name(self, node):
    """StubFormatter ast.Name visitor."""
    d = self.names_dict
    name = d.get(node.id, node.id)
    s = 'bool' if name in ('True', 'False') else name
    if False and node.id not in self.seen_names:  # pragma: no cover 
        self.seen_names.append(node.id)
        if d.get(node.id):
            g.trace(node.id, '==&gt;', d.get(node.id))
        elif node.id == 'aList':
            g.trace('**not found**', node.id)
    return s
</t>
<t tx="ekr.20160318141204.158">def do_Tuple(self, node):   ###
    """StubFormatter.Tuple."""
    elts = [self.visit(z) for z in node.elts]
    return 'Tuple[%s]' % ', '.join(elts)
</t>
<t tx="ekr.20160318141204.159"># StubFormatter visitors for operators...
</t>
<t tx="ekr.20160318141204.160"># BinOp(expr left, operator op, expr right)

def do_BinOp(self, node):  ###
    """StubFormatter.BinOp visitor."""
    trace = self.trace_reduce
    numbers = ['number', 'complex', 'float', 'long', 'int',]
    op = self.op_name(node.op)
    lhs = self.visit(node.left)
    rhs = self.visit(node.right)
    if op.strip() in ('is', 'is not', 'in', 'not in'):
        s = 'bool'
    elif lhs == rhs:
        s = lhs
            # Perhaps not always right,
            # but it is correct for Tuple, List, Dict.
    elif lhs in numbers and rhs in numbers:
        s = reduce_types([lhs, rhs], trace=trace)
            # reduce_numbers would be wrong: it returns a list.
    elif lhs == 'str' and op in '%+*':
        # str + any implies any is a string.
        s = 'str'
    else:
        # Fall back to the base-class behavior.
        s = '%s%s%s' % (
            self.visit(node.left),
            op,
            self.visit(node.right))
    s = self.match_all(node, s)
    self.trace_visitor(node, op, s)
    return s
</t>
<t tx="ekr.20160318141204.161"># BoolOp(boolop op, expr* values)

def do_BoolOp(self, node):  # pragma: no cover (Python 2.x only)
    """StubFormatter.BoolOp visitor for 'and' and 'or'."""
    trace = self.trace_reduce
    op = self.op_name(node.op)
    values = [self.visit(z).strip() for z in node.values]
    s = reduce_types(values, trace=trace)
    s = self.match_all(node, s)
    self.trace_visitor(node, op, s)
    return s
</t>
<t tx="ekr.20160318141204.162"># Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)

def do_Call(self, node):  ###
    """StubFormatter.Call visitor."""
    func = self.visit(node.func)
    args = [self.visit(z) for z in node.args]
    for z in node.keywords:
        # Calls f.do_keyword.
        args.append(self.visit(z))
    if getattr(node, 'starargs', None):
        args.append('*%s' % (self.visit(node.starargs)))
    if getattr(node, 'kwargs', None):
        args.append('**%s' % (self.visit(node.kwargs)))
    args = [z for z in args if z]  # Kludge: Defensive coding.
    # Explicit pattern:
    if func in ('dict', 'list', 'set', 'tuple',):
        if args:
            s = '%s[%s]' % (func.capitalize(), ', '.join(args))
        else:
            s = '%s' % func.capitalize()
    else:
        s = '%s(%s)' % (func, ', '.join(args))
    s = self.match_all(node, s, trace=False)
    self.trace_visitor(node, 'call', s)
    return s
</t>
<t tx="ekr.20160318141204.163"># keyword = (identifier arg, expr value)

def do_keyword(self, node):  ###
    # node.arg is a string.
    value = self.visit(node.value)
    # This is a keyword *arg*, not a Python keyword!
    return '%s=%s' % (node.arg, value)
</t>
<t tx="ekr.20160318141204.164"># Compare(expr left, cmpop* ops, expr* comparators)

def do_Compare(self, node):  ###
    """
    StubFormatter ast.Compare visitor for these ops:
    '==', '!=', '&lt;', '&lt;=', '&gt;', '&gt;=', 'is', 'is not', 'in', 'not in',
    """
    s = 'bool'  # Correct regardless of arguments.
    ops = ','.join([self.op_name(z) for z in node.ops])
    self.trace_visitor(node, ops, s)
    return s
</t>
<t tx="ekr.20160318141204.165"># If(expr test, stmt* body, stmt* orelse)

def do_IfExp(self, node):  ###
    """StubFormatterIfExp (ternary operator)."""
    trace = self.trace_reduce
    aList = [
        self.match_all(node, self.visit(node.body)),
        self.match_all(node, self.visit(node.orelse)),
    ]
    s = reduce_types(aList, trace=trace)
    s = self.match_all(node, s)
    self.trace_visitor(node, 'if', s)
    return s
</t>
<t tx="ekr.20160318141204.166"># Subscript(expr value, slice slice, expr_context ctx)

def do_Subscript(self, node):  ###
    """StubFormatter.Subscript."""
    s = '%s[%s]' % (
        self.visit(node.value),
        self.visit(node.slice))
    s = self.match_all(node, s)
    self.trace_visitor(node, '[]', s)
    return s
</t>
<t tx="ekr.20160318141204.167"># UnaryOp(unaryop op, expr operand)

def do_UnaryOp(self, node):  ###
    """StubFormatter.UnaryOp for unary +, -, ~ and 'not' operators."""
    op = self.op_name(node.op)
    if op.strip() == 'not':
        return 'bool'
    s = self.visit(node.operand)
    s = self.match_all(node, s)
    self.trace_visitor(node, op, s)
    return s
</t>
<t tx="ekr.20160318141204.168">def do_Return(self, node):
    """
    StubFormatter ast.Return vsitor.
    Return only the return expression itself.
    """
    s = AstFormatter.do_Return(self, node)
    assert s.startswith('return'), repr(s)
    return s[len('return') :].strip()
</t>
<t tx="ekr.20160318141204.169">class StubTraverser(ast.NodeVisitor):
    """
    An ast.Node traverser class that outputs a stub for each class or def.
    Names of visitors must start with visit_. The order of traversal does
    not matter, because so few visitors do anything.
    """
    @others
</t>
<t tx="ekr.20160318141204.17">def format(self, node):
    """Format the node (or list of nodes) and its descendants."""
    self.level = 0
    val = self.visit(node)
    return val  # val is a string.
</t>
<t tx="ekr.20160318141204.170">def __init__(self, controller):
    """Ctor for StubTraverser class."""
    self.controller = x = controller  # A Controller instance.
    # Internal state ivars...
    self.class_name_stack = []
    self.class_defs_count = 0
        # The number of defs seen for this class.
    self.context_stack = []
    sf = StubFormatter(controller=controller, traverser=self)
    self.format = sf.format
    self.arg_format = AstArgFormatter().format
    self.level = 0
    self.output_file = None
    self.parent_stub = None
    self.raw_format = AstFormatter().format
    self.returns = []
    self.stubs_dict = {}
        # Keys are stub.full_name's.  Values are stubs.
    self.warn_list = []
    # Copies of controller ivars...
    self.output_fn = x.output_fn
    self.overwrite = x.overwrite
    self.prefix_lines = x.prefix_lines
    self.silent = x.silent
    self.regex_patterns = x.regex_patterns
    self.update_flag = x.update_flag
    self.trace_matches = x.trace_matches
    self.trace_patterns = x.trace_patterns
    self.trace_reduce = x.trace_reduce
    self.trace_visitors = x.trace_visitors
    self.verbose = x.verbose
    self.warn = x.warn
    # Copies of controller patterns...
    self.def_patterns = x.def_patterns
    self.names_dict = x.names_dict
    self.general_patterns = x.general_patterns
    self.patterns_dict = x.patterns_dict
</t>
<t tx="ekr.20160318141204.171">def add_stub(self, d, stub):
    """Add the stub to d, checking that it does not exist."""
    global g_input_file_name
    key = stub.full_name
    assert key
    if key in d:
        print('%20s: ignoring duplicate entry for %s' % (g_input_file_name, key))  # pragma: no cover
    else:
        d[key] = stub
</t>
<t tx="ekr.20160318141204.172">def indent(self, s):
    """Return s, properly indented."""
    # This version of indent *is* used.
    return '%s%s' % (' ' * 4 * self.level, s)

def out(self, s):  # pragma: no cover
    """Output the string to the console or the file."""
    s = self.indent(s)
    if self.parent_stub:
        self.parent_stub.out_list.append(s)
    elif self.output_file:
        self.output_file.write(s + '\n')
    else:
        print(s)
</t>
<t tx="ekr.20160318141204.173">def run(self, node):  # pragma: no cover
    """StubTraverser.run: write the stubs in node's tree to self.output_fn."""
    fn = self.output_fn
    dir_ = os.path.dirname(fn)
    if os.path.exists(fn) and not self.overwrite:
        print('file exists: %s' % fn)
        return
    if dir_ and not os.path.exists(dir_):
        print('output directory not not found: %s' % dir_)
        return
    # Create parent_stub.out_list.
    self.parent_stub = Stub(kind='root', name='&lt;new-stubs&gt;')
    for z in self.prefix_lines or []:
        self.parent_stub.out_list.append(z)
    self.visit(node)
    if self.update_flag:
        self.parent_stub = self.update(fn, new_root=self.parent_stub)
    # Output the stubs.
    self.output_file = open(fn, 'w')
    self.output_time_stamp()
    self.output_stubs(self.parent_stub)
    self.output_file.close()
    self.output_file = None
    self.parent_stub = None
    if self.verbose:
        print('wrote: %s' % fn)
</t>
<t tx="ekr.20160318141204.174">def output_stubs(self, stub):
    """Output this stub and all its descendants."""
    for s in stub.out_list or []:
        # Indentation must be present when an item is added to stub.out_list.
        if self.output_file:
            self.output_file.write(s.rstrip() + '\n')
        else:
            print(s)  # pragma: no cover
    # Recursively print all children.
    for child in stub.children:
        self.output_stubs(child)
</t>
<t tx="ekr.20160318141204.175">def output_time_stamp(self):  ###
    """Put a time-stamp in the output file."""
    if self.output_file:
        self.output_file.write('# make_stub_files: %s\n' %
            time.strftime("%a %d %b %Y at %H:%M:%S"))
</t>
<t tx="ekr.20160318141204.176">def update(self, fn, new_root):  ###
    """
    Merge the new_root tree with the old_root tree in fn (a .pyi file).

    new_root is the root of the stub tree from the .py file.
    old_root (read below) is the root of stub tree from the .pyi file.
    
    Return old_root, or new_root if there are any errors.
    """
    s = self.get_stub_file(fn)
    if not s or not s.strip():
        return new_root
    if '\t' in s:
        # Tabs in stub files make it impossible to parse them reliably.
        g.trace('Can not update stub files containing tabs.')
        return new_root
    # Read old_root from the .pyi file.
    old_d, old_root = self.parse_stub_file(s, root_name='&lt;old-stubs&gt;')
    if old_root:
        # Merge new stubs into the old tree.
        if 0:
            print(self.trace_stubs(old_root, header='old_root'))
            print(self.trace_stubs(new_root, header='new_root'))
        print('***** updating stubs from %s *****' % fn)
        self.merge_stubs(self.stubs_dict.values(), old_root, new_root)
        # print(self.trace_stubs(old_root, header='updated_root'))
        return old_root
    return new_root
</t>
<t tx="ekr.20160318141204.177">def get_stub_file(self, fn):  # pragma: no cover
    """Read the stub file into s."""
    if os.path.exists(fn):
        try:
            s = open(fn, 'r').read()
        except Exception:
            print('--update: error reading %s' % fn)
            s = None
        return s
    print('--update: not found: %s' % fn)
    return None
</t>
<t tx="ekr.20160318141204.178">def parse_stub_file(self, s, root_name):
    """
    Parse s, the contents of a stub file, into a tree of Stubs.
    
    Parse by hand, so that --update can be run with Python 2.
    """
    assert '\t' not in s
    d = {}
    root = Stub(kind='root', name=root_name)
    indent_stack = [-1]  # To prevent the root from being popped.
    stub_stack = [root]
    lines = []
    pat = re.compile(r'^([ ]*)(def|class)\s+([a-zA-Z_]+)(.*)')
    for line in g.splitLines(s):
        m = pat.match(line)
        if m:
            indent, kind, name = (len(m.group(1)), m.group(2), m.group(3))
            old_indent = indent_stack[-1]
            # Terminate any previous lines.
            old_stub = stub_stack[-1]
            old_stub.out_list.extend(lines)
            lines = [line]
            # Adjust the stacks.
            if indent == old_indent:
                stub_stack.pop()
            elif indent &gt; old_indent:
                indent_stack.append(indent)
            else:  # indent &lt; old_indent
                # The indent_stack can't underflow because
                # indent &gt;= 0 and indent_stack[0] &lt; 0
                assert indent &gt;= 0
                while indent &lt;= indent_stack[-1]:
                    indent_stack.pop()
                    old_stub = stub_stack.pop()
                    assert old_stub != root
                indent_stack.append(indent)
            # Create and push the new stub *after* adjusting the stacks.
            assert stub_stack
            parent = stub_stack[-1]
            stack = [z.name for z in stub_stack[1:]]
            parent = stub_stack[-1]
            stub = Stub(kind, name, parent, stack)
            self.add_stub(d, stub)
            stub_stack.append(stub)
        else:
            parent = stub_stack[-1]
            lines.append(line)
    # Terminate the last stub.
    old_stub = stub_stack[-1]
    old_stub.out_list.extend(lines)
    return d, root
</t>
<t tx="ekr.20160318141204.179">def merge_stubs(self, new_stubs, old_root, new_root, trace=False):
    """
    Merge the new_stubs *list* into the old_root *tree*.
    - new_stubs is a list of Stubs from the .py file.
    - old_root is the root of the stubs from the .pyi file.
    - new_root is the root of the stubs from the .py file.
    """
    # Part 1: Delete old stubs do *not* exist in the *new* tree.
    aList = self.check_delete(new_stubs, old_root, new_root, trace)
        # Checks that all ancestors of deleted nodes will be deleted.
    aList = list(reversed(self.sort_stubs_by_hierarchy(aList)))
        # Sort old stubs so that children are deleted before parents.
    for stub in aList:
        if trace: g.trace('deleting  %s' % stub)
        parent = self.find_parent_stub(stub, old_root) or old_root
        parent.children.remove(stub)
        assert not self.find_stub(stub, old_root), stub
    # Part 2: Insert new stubs that *not* exist in the *old* tree.
    aList = [z for z in new_stubs if not self.find_stub(z, old_root)]
    aList = self.sort_stubs_by_hierarchy(aList)
        # Sort new stubs so that parents are created before children.
    for stub in aList:
        if trace: g.trace('inserting %s' % stub)
        parent = self.find_parent_stub(stub, old_root) or old_root
        parent.children.append(stub)
        assert self.find_stub(stub, old_root), stub
</t>
<t tx="ekr.20160318141204.18">def visit(self, node):
    """Return the formatted version of an Ast node, or list of Ast nodes."""
    tag = 'AstFormatter.visit'
    name = node.__class__.__name__
    ### g.trace(name) ###
    if isinstance(node, (list, tuple)):
        return ','.join([self.visit(z) for z in node])  # pragma: no cover (defensive)
    if node is None:
        return 'None'  # pragma: no cover
    if not isinstance(node, ast.AST):
        # #13: Insert an error comment directly into the output.
        return f"\n#{tag}: not an AST node: {name}\n"  # pragma: no cover (defensive)
        # assert False, f"\n#{tag}: not an AST node: {name}\n"
    method_name = 'do_' + node.__class__.__name__
    # #13: *Never* ignore missing visitors!
    method = getattr(self, method_name, None)
    if method:
        s = method(node)
        assert g.isString(s), s.__class__.__name__
        # g.trace(name,  '==&gt;', s) ###
        return s
    # #13: Insert an error comment directly into the output.
    return f"\n#{tag}: no visitor: do_{name}\n"  # pragma: no cover (defensive)
    # assert False, f"\n#{tag}: no visitor: do_{name}\n"
</t>
<t tx="ekr.20160318141204.180">def check_delete(self, new_stubs, old_root, new_root, trace):
    """Return a list of nodes that can be deleted."""
    old_stubs = self.flatten_stubs(old_root)
    old_stubs.remove(old_root)
    aList = [z for z in old_stubs if z not in new_stubs]
    if trace:  # pragma: no cover
        dump_list('old_stubs', old_stubs)
        dump_list('new_stubs', new_stubs)
        dump_list('to-be-deleted stubs', aList)
    delete_list = []
    # Check that all parents of to-be-delete nodes will be deleted.
    for z in aList:
        z1 = z
        for i in range(20):
            z = z.parent
            if not z:  # pragma: no cover
                g.trace('can not append: new root not found', z)
                break
            elif z == old_root:
                delete_list.append(z1)
                break
            elif z not in aList:  # pragma: no cover
                g.trace("can not delete %s because of %s" % (z1, z))
                break
        else:  # pragma: no cover
            g.trace('can not happen: parent loop')
    if trace:  # pragma: no cover
        dump_list('delete_list', delete_list)
    return delete_list
</t>
<t tx="ekr.20160318141204.181">def flatten_stubs(self, root):
    """Return a flattened list of all stubs in root's tree."""
    aList = [root]
    for child in root.children:
        self.flatten_stubs_helper(child, aList)
    return aList

def flatten_stubs_helper(self, root, aList):
    """Append all stubs in root's tree to aList."""
    aList.append(root)
    for child in root.children:
        self.flatten_stubs_helper(child, aList)
</t>
<t tx="ekr.20160318141204.182">def find_parent_stub(self, stub, root):
    """Return stub's parent **in root's tree**."""
    return self.find_stub(stub.parent, root) if stub.parent else None
</t>
<t tx="ekr.20160318141204.183">def find_stub(self, stub, root):
    """Return the stub **in root's tree** that matches stub."""
    if stub == root:  # Must use Stub.__eq__!
        return root  # not stub!
    for child in root.children:
        stub2 = self.find_stub(stub, child)
        if stub2: return stub2
    return None
</t>
<t tx="ekr.20160318141204.184">def sort_stubs_by_hierarchy(self, stubs1):
    """
    Sort the list of Stubs so that parents appear before all their
    descendants.
    """
    stubs, result = stubs1[:], []
    for i in range(50):
        if stubs:
            # Add all stubs with i parents to the results.
            found = [z for z in stubs if z.level() == i]
            result.extend(found)
            for z in found:
                stubs.remove(z)
        else:
            return result
    # Abort the merge.
    g.trace('can not happen: unbounded stub levels.')  # pragma: no cover
    return []  # pragma: no cover
</t>
<t tx="ekr.20160318141204.185">def trace_stubs(self, stub, aList=None, header=None, level=-1):  # pragma: no cover
    """Return a trace of the given stub and all its descendants."""
    indent = ' ' * 4 * max(0, level)
    if level == -1:
        aList = ['===== %s...\n' % (header) if header else '']
    for s in stub.out_list:
        aList.append('%s%s' % (indent, s.rstrip()))
    for child in stub.children:
        self.trace_stubs(child, level=level + 1, aList=aList)
    if level == -1:
        return '\n'.join(aList) + '\n'
    return ''
</t>
<t tx="ekr.20160318141204.186"># 2: ClassDef(identifier name, expr* bases,
#             stmt* body, expr* decorator_list)
# 3: ClassDef(identifier name, expr* bases,
#             keyword* keywords, expr? starargs, expr? kwargs
#             stmt* body, expr* decorator_list)
#
# keyword arguments supplied to call (NULL identifier for **kwargs)
# keyword = (identifier? arg, expr value)

def visit_ClassDef(self, node):  ###

    # Create the stub in the old context.
    old_stub = self.parent_stub
    self.class_defs_count = 0
    self.parent_stub = Stub('class', node.name, old_stub, self.context_stack)
    self.add_stub(self.stubs_dict, self.parent_stub)
    # Enter the new context.
    self.class_name_stack.append(node.name)
    self.context_stack.append(node.name)
    if self.trace_matches or self.trace_reduce:  # pragma: no cover
        print('\nclass %s\n' % node.name)
    #
    # Fix issue #2: look ahead to see if there are any functions in this class.
    empty = not any(isinstance(z, ast.FunctionDef) for z in node.body)
    tail = ' ...' if empty else ''
    #
    # Format...
    bases = [self.visit(z) for z in node.bases] if node.bases else []
    if getattr(node, 'keywords', None):  # Python 3
        for keyword in node.keywords:
            bases.append('%s=%s' % (keyword.arg, self.visit(keyword.value)))
    if getattr(node, 'starargs', None):  # Python 3
        bases.append('*%s', self.visit(node.starargs))
    if getattr(node, 'kwargs', None):  # Python 3
        bases.append('*%s', self.visit(node.kwargs))
    if not node.name.startswith('_'):
        if node.bases:
            s = '(%s)' % ', '.join([self.format(z) for z in node.bases])
        else:
            s = ''
        self.out('class %s%s:%s' % (node.name, s, tail))
    # Visit...
    self.level += 1
    for z in node.body:
        self.visit(z)
    # Restore the context
    self.context_stack.pop()
    self.class_name_stack.pop()
    self.level -= 1
    self.parent_stub = old_stub
</t>
<t tx="ekr.20160318141204.187"># 2: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list)
# 3: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list,
#                expr? returns)

def visit_FunctionDef(self, node):

    # Create the stub in the old context.
    old_stub = self.parent_stub
    self.parent_stub = Stub('def', node.name, old_stub, self.context_stack)
    self.add_stub(self.stubs_dict, self.parent_stub)
    # Enter the new context.
    self.returns = []
    self.level += 1
    self.context_stack.append(node.name)
    for z in node.body:
        self.visit(z)
    self.context_stack.pop()
    self.level -= 1
    # Format *after* traversing
    # if self.trace_matches or self.trace_reduce:
        # if not self.class_name_stack:
            # print('def %s\n' % node.name)
    self.out('def %s(%s) -&gt; %s' % (
        node.name,
        self.format_arguments(node.args),
        self.format_returns(node)))
    self.parent_stub = old_stub
</t>
<t tx="ekr.20160318141204.188"># arguments = (expr* args, identifier? vararg, identifier? kwarg, expr* defaults)

def format_arguments(self, node):  ###
    """
    Format the arguments node.
    Similar to AstFormat.do_arguments, but it is not a visitor!
    """
    assert isinstance(node, ast.arguments), node
    args = [self.raw_format(z) for z in node.args]
    defaults = [self.raw_format(z) for z in node.defaults]
    # Assign default values to the last args.
    result = []
    n_plain = len(args) - len(defaults)
    for i, arg in enumerate(args):
        s = self.munge_arg(arg)
        if i &lt; n_plain:
            result.append(s)
        else:
            result.append('%s=%s' % (s, defaults[i - n_plain]))
    # Now add the vararg and kwarg args.
    name = getattr(node, 'vararg', None)
    if name:
        if hasattr(ast, 'arg'):  # python 3:
            name = self.raw_format(name)
        result.append('*' + name)
    name = getattr(node, 'kwarg', None)
    if name:
        if hasattr(ast, 'arg'):  # python 3:
            name = self.raw_format(name)
        result.append('**' + name)
    return ', '.join(result)
</t>
<t tx="ekr.20160318141204.189">type_pattern = re.compile(r'.*:.*')

def munge_arg(self, s):
    """Add an annotation for s if possible."""
    if s == 'self':
        return s
    for pattern in self.general_patterns:
        if pattern.match_entire_string(s):  ###
            return '%s: %s' % (s, pattern.repl_s)
    if self.warn and s not in self.warn_list:  # pragma: no cover
        self.warn_list.append(s)
        print('no annotation for %s' % s)
    # Fix issue #3.
    if self.type_pattern.match(s):
        return s
    return s + ': Any'
</t>
<t tx="ekr.20160318141204.19">
# Contexts...
</t>
<t tx="ekr.20160318141204.190">def format_returns(self, node):  ###
    """
    Calculate the return type:
    - Return None if there are no return statements.
    - Patterns in [Def Name Patterns] override all other patterns.
    - Otherwise, return a list of return values.
    """
    name = self.get_def_name(node)
    raw = [self.raw_format(z) for z in self.returns]
    # Allow StubFormatter.do_Return to do the hack.
    r = [self.format(z) for z in self.returns]
    ### g.trace('1', raw, r)
    # Step 1: Return None if there are no return statements.
    if not [z for z in self.returns if z.value is not None]:
        empty = not any(isinstance(z, ast.FunctionDef) for z in node.body)
        tail = ': ...' if empty else ':'
        return 'None' + tail
    # Step 2: [Def Name Patterns] override all other patterns.
    for pattern in self.def_patterns:
        found, s = pattern.match(name)
        ### g.trace('2', found, name, pattern, s)
        if found:
            return s + ': ...'
    # Step 3: remove recursive calls.
    raw, r = self.remove_recursive_calls(name, raw, r)
    ### g.trace('3', raw, r)
    # Step 4: Calculate return types.
    return self.format_return_expressions(node, name, raw, r)
</t>
<t tx="ekr.20160318141204.191">def format_return_expressions(self, node, name, raw_returns, reduced_returns):  ###
    """
    aList is a list of maximally reduced return expressions.
    For each expression e in Alist:
    - If e is a single known type, add e to the result.
    - Otherwise, add Any # e to the result.
    Return the properly indented result.
    """
    assert len(raw_returns) == len(reduced_returns)
    lws = '\n' + ' ' * 4
    n = len(raw_returns)
    known = all(is_known_type(e) for e in reduced_returns)
    empty = not any(isinstance(z, ast.FunctionDef) for z in node.body)
    tail = ': ...' if empty else ':'
    if not known or self.verbose:
        # First, generate the return lines.
        aList = []
        for i in range(n):
            e, raw = reduced_returns[i], raw_returns[i]
            known = ' ' if is_known_type(e) else '?'
            aList.append('# %s %s: %s' % (' ', i, raw))
            aList.append('# %s %s: return %s' % (known, i, e))
        results = ''.join([lws + self.indent(z) for z in aList])
        # Put the return lines in their proper places.
        if known:
            s = reduce_types(reduced_returns, name=name, trace=self.trace_reduce)
            return s + tail + results
        return 'Any' + tail + results
    # Coverage tests use verbose option.
    s = reduce_types(reduced_returns, name=name, trace=self.trace_reduce)  # pragma: no cover
    return s + tail  # pragma: no cover
</t>
<t tx="ekr.20160318141204.192">def get_def_name(self, node):
    """Return the representaion of a function or method name."""
    if self.class_name_stack:
        name = '%s.%s' % (self.class_name_stack[-1], node.name)
        # All ctors should return None
        if node.name == '__init__':
            name = 'None'
    else:
        name = node.name  ###
    return name
</t>
<t tx="ekr.20160318141204.193">def remove_recursive_calls(self, name, raw, reduced):  ###
    """Remove any recursive calls to name from both lists."""
    # At present, this works *only* if the return is nothing but the recursive call.
    assert len(raw) == len(reduced)
    pattern = Pattern('%s(*)' % name)
    n = len(reduced)
    raw_result, reduced_result = [], []
    for i in range(n):
        if pattern.match_entire_string(reduced[i]):
            pass
        else:
            raw_result.append(raw[i])
            reduced_result.append(reduced[i])
    return raw_result, reduced_result
</t>
<t tx="ekr.20160318141204.194">def visit_Return(self, node):  ###
    self.returns.append(node)
        # New: return the entire node, not node.value.
</t>
<t tx="ekr.20160318141204.20"># 2: ClassDef(identifier name, expr* bases, stmt* body, expr* decorator_list)
# 3: ClassDef(identifier name, expr* bases, keyword* keywords, stmt* body, expr* decorator_list)

def do_ClassDef(self, node):
    result = []
    name = node.name  # Only a plain string is valid.
    bases = [self.visit(z) for z in node.bases] if node.bases else []
    if getattr(node, 'decorator_list', None):  # Python 3
        for decorator in node.decorator_list:
            result.append(f"@{self.visit(decorator)}\n")  # Bug fix: 2021/08/06.
    if getattr(node, 'keywords', None):  # Python 3
        for keyword in node.keywords:
            bases.append('%s=%s' % (keyword.arg, self.visit(keyword.value)))
    # Fix issue #2: look ahead to see if there are any functions in this class.
    empty = not any(isinstance(z, ast.FunctionDef) for z in node.body)
    tail = ' ...' if empty else ''
    if bases:
        result.append(
            self.indent('class %s(%s):%s\n' % (name, ', '.join(bases), tail)))
    else:
        result.append(self.indent('class %s:%s\n' % (name, tail)))  # Fix #2
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.21"># 2: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list)
# 3: FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list, expr? returns)

def do_FunctionDef(self, node):
    """Format a FunctionDef node."""
    result = []
    if node.decorator_list:
        for z in node.decorator_list:
            result.append('@%s\n' % self.visit(z))
    name = node.name  # Only a plain string is valid.
    args = self.visit(node.args) if node.args else ''
    if getattr(node, 'returns', None):  # Python 3.
        returns = self.visit(node.returns)
        # Bug found by unit test.
        result.append(self.indent('def %s(%s) -&gt; %s:\n' % (name, args, returns)))
    else:
        result.append(self.indent('def %s(%s):\n' % (name, args)))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.22">def do_Interactive(self, node):  # pragma: no cover (will never be used)
    for z in node.body:
        self.visit(z)

</t>
<t tx="ekr.20160318141204.23">def do_Module(self, node):
    assert 'body' in node._fields
    result = ''.join([self.visit(z) for z in node.body])
    return result  # 'module:\n%s' % (result)

</t>
<t tx="ekr.20160318141204.24">def do_Lambda(self, node):
    return self.indent('lambda %s: %s' % (
        self.visit(node.args),
        self.visit(node.body)))
</t>
<t tx="ekr.20160318141204.25">
# Expressions...

</t>
<t tx="ekr.20160318141204.26">def do_Expr(self, node):
    """An outer expression: must be indented."""
    return self.indent('%s\n' % self.visit(node.value))</t>
<t tx="ekr.20160318141204.27">def do_Expression(self, node):  # pragma: no cover (never used)
    """An expression context"""
    return '%s\n' % self.visit(node.body)

</t>
<t tx="ekr.20160318141204.28">def do_GeneratorExp(self, node):
    elt = self.visit(node.elt) or ''
    gens = [self.visit(z) for z in node.generators]
    gens = [z if z else '&lt;**None**&gt;' for z in gens]  # Kludge: probable bug.
    return '&lt;gen %s for %s&gt;' % (elt, ','.join(gens))

</t>
<t tx="ekr.20160318141204.29">def do_AugLoad(self, node):  # pragma: no cover (defensive)
    return 'AugLoad'

def do_Del(self, node):  # pragma: no cover (defensive)
    return 'Del'

def do_Load(self, node):  # pragma: no cover (defensive)
    return 'Load'

def do_Param(self, node):  # pragma: no cover (defensive)
    return 'Param'

def do_Store(self, node):  # pragma: no cover (defensive)
    return 'Store'
</t>
<t tx="ekr.20160318141204.30">
# Operands...

</t>
<t tx="ekr.20160318141204.31"># 2: arguments = (expr* args, identifier? vararg, identifier? kwarg, expr* defaults)

# 3: arguments = (
#       arg* posonlyargs, arg* args, arg? vararg, arg* kwonlyargs,
#       expr* kw_defaults, arg? kwarg, expr* defaults
# )

def do_arguments(self, node):
    """Format the arguments node."""
    kind = self.kind(node)
    assert kind == 'arguments', kind
    args = [self.visit(z) for z in node.args]
    defaults = [self.visit(z) for z in node.defaults]
    # Assign default values to the last args.
    args2 = []
    # PEP 570: Position-only args.
    posonlyargs = getattr(node, 'posonlyargs', [])
    if posonlyargs:
        for z in posonlyargs:
            args2.append(self.visit(z))
        args2.append('/')
    n_plain = len(args) - len(defaults)
    for i in range(len(args)):
        if i &lt; n_plain:
            args2.append(args[i])
        else:
            args2.append('%s=%s' % (args[i], defaults[i - n_plain]))
    if not isPython3:  # pragma: no cover
        # Add the vararg and kwarg names.
        name = getattr(node, 'vararg', None)
        if name:
            args2.append('*' + name)
        name = getattr(node, 'kwarg', None)
        if name:
            args2.append('**' + name)
        return ', '.join(args2)
    # PEP 3102: keyword-only args.
    if node.kwonlyargs:
        assert len(node.kwonlyargs) == len(node.kw_defaults)
        args2.append('*')
        for n, z in enumerate(node.kwonlyargs):
            if node.kw_defaults[n] is None:
                args2.append(self.visit(z))
            else:
                args2.append('%s=%s' % (self.visit(z), self.visit(node.kw_defaults[n])))
    # Add the vararg and kwarg expressions.
    vararg = getattr(node, 'vararg', None)
    if vararg:
        args2.append('*' + self.visit(vararg))
    kwarg = getattr(node, 'kwarg', None)
    if kwarg:
        args2.append('**' + self.visit(kwarg))
    return ', '.join(args2)
</t>
<t tx="ekr.20160318141204.32"># 3: arg = (identifier arg, expr? annotation)

def do_arg(self, node):
    if getattr(node, 'annotation', None):
        return '%s: %s' % (node.arg, self.visit(node.annotation))
    return node.arg
</t>
<t tx="ekr.20160318141204.33"># Attribute(expr value, identifier attr, expr_context ctx)

def do_Attribute(self, node):
    return '%s.%s' % (
        self.visit(node.value),
        node.attr)  # Don't visit node.attr: it is always a string.

</t>
<t tx="ekr.20160318141204.34">def do_Bytes(self, node):  # pragma: no cover (obsolete)
    return str(node.s)

</t>
<t tx="ekr.20160318141204.35"># 2: Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)
# 3: Call(expr func, expr* args, keyword* keywords)

def do_Call(self, node):
    func = self.visit(node.func)
    args = [self.visit(z) for z in node.args]
    for z in node.keywords:
        # Calls f.do_keyword.
        args.append(self.visit(z))
    if not isPython3: # pragma: no cover (python 2)
        if getattr(node, 'starargs', None):
            args.append('*%s' % (self.visit(node.starargs)))  
        if getattr(node, 'kwargs', None):
            args.append('**%s' % (self.visit(node.kwargs))) # pragma: no cover (python 2)
        args = [z for z in args if z]  # Kludge: Defensive coding.
    return '%s(%s)' % (func, ', '.join(args))

</t>
<t tx="ekr.20160318141204.36"># keyword = (identifier arg, expr value)

def do_keyword(self, node):
    """Handle keyword *arg*, not a Python keyword!"""
    # node.arg is a string.
    value = self.visit(node.value)
    return '%s=%s' % (node.arg, value) if node.arg else '**%s' % value

</t>
<t tx="ekr.20160318141204.37">def do_comprehension(self, node):
    result = []
    name = self.visit(node.target)  # A name.
    it = self.visit(node.iter)  # An attribute.
    result.append('%s in %s' % (name, it))
    ifs = [self.visit(z) for z in node.ifs]
    if ifs:
        result.append(' if %s' % (''.join(ifs)))
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.38">def do_Dict(self, node):
    result = []
    keys = [self.visit(z) for z in node.keys]
    values = [self.visit(z) for z in node.values]
    if len(keys) == len(values):
        result.append('{')
        items = []
        for i in range(len(keys)):
            items.append('%s:%s' % (keys[i], values[i]))
        result.append(', '.join(items))
        result.append('}')
    else:  # pragma: no cover (defensive)
        print('Error: f.Dict: len(keys) != len(values)\nkeys: %s\nvals: %s' % (
            repr(keys), repr(values)))
    return ''.join(result)
</t>
<t tx="ekr.20160318141204.39">def do_Ellipsis(self, node):  # pragma: no cover (obsolete)
    return '...'
</t>
<t tx="ekr.20160318141204.40">def do_ExtSlice(self, node):  # pragma: no cover (deprecated)
    return ':'.join([self.visit(z) for z in node.dims])

</t>
<t tx="ekr.20160318141204.41">def do_Index(self, node):  # pragma: no cover (python 2)
    return self.visit(node.value)

</t>
<t tx="ekr.20160318141204.42">def do_List(self, node):
    # Not used: list context.
    # self.visit(node.ctx)
    elts = [self.visit(z) for z in node.elts]
    elts = [z for z in elts if z]  # Defensive.
    return '[%s]' % ','.join(elts)

</t>
<t tx="ekr.20160318141204.43">def do_ListComp(self, node):
    elt = self.visit(node.elt)
    gens = [self.visit(z) for z in node.generators]
    gens = [z if z else '&lt;**None**&gt;' for z in gens]  # Kludge: probable bug.
    return '%s for %s' % (elt, ''.join(gens))

</t>
<t tx="ekr.20160318141204.44">def do_Name(self, node):
    return node.id

def do_NameConstant(self, node):  # pragma: no cover (obsolete)
    s = repr(node.value)
    return 'bool' if s in ('True', 'False') else s

</t>
<t tx="ekr.20160318141204.45">def do_Num(self, node):  # pragma: no cover (obsolete)
    return repr(node.n)

</t>
<t tx="ekr.20160318141204.46">def do_Repr(self, node):  # pragma: no cover (Python 2.x only)
    return 'repr(%s)' % self.visit(node.value)

</t>
<t tx="ekr.20160318141204.47">def do_Slice(self, node):
    lower, upper, step = '', '', ''
    if getattr(node, 'lower', None) is not None:
        lower = self.visit(node.lower)
    if getattr(node, 'upper', None) is not None:
        upper = self.visit(node.upper)
    if getattr(node, 'step', None) is not None:
        step = self.visit(node.step)
        return '%s:%s:%s' % (lower, upper, step)
    return '%s:%s' % (lower, upper)

</t>
<t tx="ekr.20160318141204.48">def do_Str(self, node):  # pragma: no cover (obsolete)
    """This represents a string constant."""
    return repr(node.s)

</t>
<t tx="ekr.20160318141204.49"># Subscript(expr value, slice slice, expr_context ctx)

in_subscript = False

def do_Subscript(self, node):
    
    # A hack, for do_Tuple.
    old_in_subscript = self.in_subscript
    try:
        self.in_subscript = True
        value = self.visit(node.value)
        the_slice = self.visit(node.slice)
    finally:
        self.in_subscript = old_in_subscript
    return '%s[%s]' % (value, the_slice)

</t>
<t tx="ekr.20160318141204.5">def merge_types(a1, a2):
    '''
    a1 and a2 may be strings or lists.
    return a list containing both of them, flattened, without duplicates.
    '''
    # Only useful if visitors could return either lists or strings.
    assert a1 is not None
    assert a2 is not None
    r1 = a1 if isinstance(a1, (list, tuple)) else [a1]
    r2 = a2 if isinstance(a2, (list, tuple)) else [a2]
    return sorted(set(r1 + r2))

</t>
<t tx="ekr.20160318141204.50">def do_Tuple(self, node):
    elts_s = ', '.join(self.visit(z) for z in node.elts)
    return elts_s if self.in_subscript else '(%s)' % elts_s
</t>
<t tx="ekr.20160318141204.51">
# Operators...

</t>
<t tx="ekr.20160318141204.52">def do_BinOp(self, node):
    return '%s%s%s' % (
        self.visit(node.left),
        self.op_name(node.op),
        self.visit(node.right))

</t>
<t tx="ekr.20160318141204.53">def do_BoolOp(self, node):
    op_name = self.op_name(node.op)
    values = [self.visit(z) for z in node.values]
    return op_name.join(values)

</t>
<t tx="ekr.20160318141204.54">def do_Compare(self, node):
    result = []
    lt = self.visit(node.left)
    ops = [self.op_name(z) for z in node.ops]
    comps = [self.visit(z) for z in node.comparators]
    result.append(lt)
    if len(ops) == len(comps):
        for i in range(len(ops)):
            result.append('%s%s' % (ops[i], comps[i]))
    else:  # pragma: no cover (defensive)
        print('can not happen: ops', repr(ops), 'comparators', repr(comps))
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.55">def do_UnaryOp(self, node):
    return '%s%s' % (
        self.op_name(node.op),
        self.visit(node.operand))

</t>
<t tx="ekr.20160318141204.56">def do_IfExp(self, node):
    return '%s if %s else %s ' % (
        self.visit(node.body),
        self.visit(node.test),
        self.visit(node.orelse))
</t>
<t tx="ekr.20160318141204.57">
# Statements...

</t>
<t tx="ekr.20160318141204.58">def do_Assert(self, node):
    test = self.visit(node.test)
    if getattr(node, 'msg', None):
        message = self.visit(node.msg)
        return self.indent('assert %s, %s' % (test, message))
    return self.indent('assert %s' % test)

</t>
<t tx="ekr.20160318141204.59">def do_Assign(self, node):
    return self.indent('%s = %s\n' % (
        '='.join([self.visit(z) for z in node.targets]),
        self.visit(node.value)))

</t>
<t tx="ekr.20160318141204.60">def do_AugAssign(self, node):
    return self.indent('%s%s=%s\n' % (
        self.visit(node.target),
        self.op_name(node.op),  # Bug fix: 2013/03/08.
        self.visit(node.value)))

</t>
<t tx="ekr.20160318141204.61">def do_Break(self, node):
    return self.indent('break\n')

</t>
<t tx="ekr.20160318141204.62">def do_Continue(self, node):
    return self.indent('continue\n')

</t>
<t tx="ekr.20160318141204.63">def do_Delete(self, node):
    targets = [self.visit(z) for z in node.targets]
    return self.indent('del %s\n' % ','.join(targets))

</t>
<t tx="ekr.20160318141204.64">def do_ExceptHandler(self, node):
    result = []
    result.append(self.indent('except'))
    if getattr(node, 'type', None):
        result.append(' %s' % self.visit(node.type))
    if getattr(node, 'name', None):
        if isinstance(node.name, ast.AST):  
            result.append(' as %s' % self.visit(node.name))  # pragma: no cover (python 2)
        else:
            result.append(' as %s' % node.name)  # Python 3.x.
    result.append(':\n')
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.65">def do_Exec(self, node):  # pragma: no cover (Python 2.x only)
    body = self.visit(node.body)
    args = []  # Globals before locals.
    if getattr(node, 'globals', None):
        args.append(self.visit(node.globals))
    if getattr(node, 'locals', None):
        args.append(self.visit(node.locals))
    if args:
        return self.indent('exec %s in %s\n' % (
            body, ','.join(args)))
    return self.indent('exec %s\n' % (body))

</t>
<t tx="ekr.20160318141204.66">def do_For(self, node):
    result = []
    result.append(self.indent('for %s in %s:\n' % (
        self.visit(node.target),
        self.visit(node.iter))))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        result.append(self.indent('else:\n'))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.67">def do_Global(self, node):
    return self.indent('global %s\n' % (
        ','.join(node.names)))

</t>
<t tx="ekr.20160318141204.68">def do_If(self, node):
    result = []
    result.append(self.indent('if %s:\n' % (
        self.visit(node.test))))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        result.append(self.indent('else:\n'))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.69">def do_Import(self, node):
    names = []
    for fn, asname in self.get_import_names(node):
        if asname:
            names.append('%s as %s' % (fn, asname))
        else:
            names.append(fn)
    return self.indent('import %s\n' % (','.join(names)))

</t>
<t tx="ekr.20160318141204.70">def get_import_names(self, node):
    """Return a list of the the full file names in the import statement."""
    result = []
    for ast2 in node.names:
        if self.kind(ast2) == 'alias':
            data = ast2.name, ast2.asname
            result.append(data)
        else:  # pragma: no cover (defensive)
            print('unsupported kind in Import.names list', self.kind(ast2))
    return result

</t>
<t tx="ekr.20160318141204.71">def do_ImportFrom(self, node):
    names = []
    for fn, asname in self.get_import_names(node):
        if asname:
            names.append('%s as %s' % (fn, asname))
        else:
            names.append(fn)
    return self.indent('from %s import %s\n' % (
        node.module,
        ','.join(names)))
</t>
<t tx="ekr.20160318141204.72"># Nonlocal(identifier* names)

def do_Nonlocal(self, node):
    return self.indent('nonlocal %s\n' % ', '.join(node.names))
</t>
<t tx="ekr.20160318141204.73">def do_Pass(self, node):
    return self.indent('pass\n')

</t>
<t tx="ekr.20160318141204.74">def do_Print(self, node):  # pragma: no cover (Python 2.x only)
    vals = []
    for z in node.values:
        vals.append(self.visit(z))
    if getattr(node, 'dest', None):
        vals.append('dest=%s' % self.visit(node.dest))
    if getattr(node, 'nl', None):
        vals.append('nl=%s' % node.nl)
    return self.indent('print(%s)\n' % ','.join(vals))

</t>
<t tx="ekr.20160318141204.75">def do_Raise(self, node):
    args = []
    for attr in (
        'exc', 'cause',  # python 3
        'type', 'inst', 'tback'  # python 2
    ):
        if getattr(node, attr, None) is not None:
            args.append(self.visit(getattr(node, attr)))
    if args:
        return self.indent('raise %s\n' % ','.join(args))
    return self.indent('raise\n')

</t>
<t tx="ekr.20160318141204.76">def do_Return(self, node):
    if node.value:
        return self.indent('return %s\n' % (
            self.visit(node.value).strip()))
    return self.indent('return\n')

</t>
<t tx="ekr.20160318141204.77"># Starred(expr value, expr_context ctx)

def do_Starred(self, node):
    return '*' + self.visit(node.value)
</t>
<t tx="ekr.20160318141204.79"># Try(stmt* body, excepthandler* handlers, stmt* orelse, stmt* finalbody)

def do_Try(self, node):  # Python 3

    result = []
    result.append(self.indent('try:\n'))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.handlers:
        for z in node.handlers:
            result.append(self.visit(z))
    if node.orelse:
        result.append(self.indent('else:\n'))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    if node.finalbody:
        result.append(self.indent('finally:\n'))
        for z in node.finalbody:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160318141204.80">def do_TryExcept(self, node):  # pragma: no cover (python 2)
    result = []
    result.append(self.indent('try:\n'))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.handlers:
        for z in node.handlers:
            result.append(self.visit(z))
    if node.orelse:
        result.append('else:\n')
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.81">def do_TryFinally(self, node):  # pragma: no cover (python 2)
    result = []
    result.append(self.indent('try:\n'))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    result.append(self.indent('finally:\n'))
    for z in node.finalbody:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.82">def do_While(self, node):
    result = []
    result.append(self.indent('while %s:\n' % self.visit(node.test)))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        result.append('else:\n')
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)

</t>
<t tx="ekr.20160318141204.83"># 2:  With(expr context_expr, expr? optional_vars,
#          stmt* body)
# withitem = (expr context_expr, expr? optional_vars)

# 3:  With(withitem* items,
#          stmt* body)

def do_With(self, node):
    result = []
    result.append(self.indent('with '))
    vars_list = []
    if getattr(node, 'context_expression', None):  # pragma: no cover (python 2)
        result.append(self.visit(node.context_expresssion))
    if getattr(node, 'optional_vars', None):  # pragma: no cover (python 2)
        try:
            for z in node.optional_vars:
                vars_list.append(self.visit(z))
        except TypeError:  # Not iterable.
            vars_list.append(self.visit(node.optional_vars))
    if getattr(node, 'items', None):  # Python 3.
        for item in node.items:
            result.append(self.visit(item.context_expr))
            result.append(' as ')
            if getattr(item, 'optional_vars', None):
                try:
                    for z in item.optional_vars: # pragma: no cover (expect TypeError)
                        vars_list.append(self.visit(z))
                except TypeError:
                    vars_list.append(self.visit(item.optional_vars))
                
    result.append(','.join(vars_list))
    result.append(':\n')
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160318141204.84">def do_Yield(self, node):
    # do_Expr has already indented this *expression*.
    if getattr(node, 'value', None):
        return 'yield %s' % self.visit(node.value)
    return 'yield'
</t>
<t tx="ekr.20160318141204.85"># YieldFrom(expr value)

def do_YieldFrom(self, node):
    # do_Expr has already indented this *expression*.
    return 'yield from %s' % self.visit(node.value)
</t>
<t tx="ekr.20160318141204.86">
# Utils...

</t>
<t tx="ekr.20160318141204.87">def kind(self, node):
    """Return the name of node's class."""
    return node.__class__.__name__
</t>
<t tx="ekr.20160318141204.88">def indent(self, s):
    return '%s%s' % (' ' * 4 * self.level, s)
</t>
<t tx="ekr.20160318141204.89">@nobeautify

def op_name(self, node, strict=True):
    """Return the print name of an operator node."""
    d = {
        # Binary operators.
        'Add': '+',
        'BitAnd': '&amp;',
        'BitOr': '|',
        'BitXor': '^',
        'Div': '/',
        'FloorDiv': '//',
        'LShift': '&lt;&lt;',
        'Mod': '%',
        'Mult': '*',
        'Pow': '**',
        'RShift': '&gt;&gt;',
        'Sub': '-',
        # Boolean operators.
        'And': ' and ',
        'Or': ' or ',
        # Comparison operators
        'Eq': '==',
        'Gt': '&gt;',
        'GtE': '&gt;=',
        'In': ' in ',
        'Is': ' is ',
        'IsNot': ' is not ',
        'Lt': '&lt;',
        'LtE': '&lt;=',
        'NotEq': '!=',
        'NotIn': ' not in ',
        # Context operators.
        'AugLoad': '&lt;AugLoad&gt;',
        'AugStore': '&lt;AugStore&gt;',
        'Del': '&lt;Del&gt;',
        'Load': '&lt;Load&gt;',
        'Param': '&lt;Param&gt;',
        'Store': '&lt;Store&gt;',
        # Unary operators.
        'Invert': '~',
        'Not': ' not ',
        'UAdd': '+',
        'USub': '-',
    }
    name = d.get(self.kind(node), '&lt;%s&gt;' % node.__class__.__name__)
    if strict: assert name, self.kind(node)
    return name
</t>
<t tx="ekr.20160318141204.90">class AstArgFormatter(AstFormatter):
    """
    Just like the AstFormatter class, except it prints the class
    names of constants instead of actual values.
    """
    @others
</t>
<t tx="ekr.20160318141204.91"># Return generic markers to allow better pattern matches.

def do_Contant(self, node):
    ### Experimental.
    name = node.value.__class__.__name__
    if name == 'ellipsis':
        return '...'
    return name

def do_BoolOp(self, node):  # pragma: no cover (Python 2.x only)
    return 'bool'

def do_Bytes(self, node):  # pragma: no cover (obsolete)
    return 'bytes'

def do_Name(self, node):  # pragma: no cover (python 2)
    return 'bool' if node.id in ('True', 'False') else node.id

def do_Num(self, node):  # pragma: no cover (python 2)
    return 'number'

def do_Str(self, node):  # pragma: no cover (python 2)
    """This represents a string constant."""
    return 'str'
</t>
<t tx="ekr.20160330201030.1">Metadata-Version: 1.0
Name: make_stub_files
Version: 0.1
Summary: make stub files for mypy
Home-page: https://github.com/edreamleo/make-stub-files
Author: Edward K. Ream
Author-email: edreamleo@gmail.com
License: MIT
Description:
    Usage: make_stub_files.py [options] file1, file2, ...
    
    Options:
      -h, --help          show this help message and exit
      -c FN, --config=FN  full path to configuration file
      -d DIR, --dir=DIR   full path to the output directory
      -o, --overwrite     overwrite existing stub (.pyi) files
      -t, --test          run unit tests on startup
      --trace-matches     trace Pattern.matches
      --trace-patterns    trace pattern creation
      --trace-reduce      trace st.reduce_types
      --trace-visitors    trace visitor methods
      -u, --update        update stubs in existing stub file
      -v, --verbose       verbose output in .pyi file
      -w, --warn          warn about unannotated args

Download URL: https://github.com/edreamleo/make-stub-files
Keywords: mypy, type checking, stub, Python
Platform: Windows, Linux, MacOS
Categories:
    Development Status :: 4 - Beta
    License :: OSI Approved :: MIT License
    Operating System :: MacOS
    Operating System :: Microsoft :: Windows
    Operating System :: POSIX :: Linux
    Programming Language :: Python
    Topic :: Software Development
</t>
<t tx="ekr.20180706073424.1"># pyflakes complains about the TestClass class.</t>
<t tx="ekr.20180901040718.1">def test_bug2_empty(self):
    # https://github.com/edreamleo/make-stub-files/issues/2
    tag = 'test_bug2_empty'
    s = 'class InvalidTag(Exception):\n    pass'
    controller = Controller()
    node = ast.parse(s, filename=tag, mode='exec')
    st = StubTraverser(controller=controller)
    # From StubTraverser.run.
    st.parent_stub = Stub(kind='root', name='&lt;new-stubs&gt;')
    st.visit(node)
    # Allocate a StringIo file for output_stubs.
    st.output_file = io.StringIO()
    st.output_stubs(st.parent_stub)
    # Test.
    lines = g.splitLines(st.output_file.getvalue())
    expected = ['class InvalidTag(Exception): ...\n']
    self.assertEqual(lines, expected)
</t>
<t tx="ekr.20180901044640.1">def test_bug2_non_empty(self):
    # https://github.com/edreamleo/make-stub-files/issues/2
    tag = 'test_bug2_non_empty'
    s = (
        'class NonEmptyClass:\n'
        '\n'
        '    def spam():\n'
        '        pass\n'
    )
    expected = [
        'class NonEmptyClass:\n',
        '    def spam() -&gt; None: ...\n',
    ]
    controller = Controller()
    node = ast.parse(s, filename=tag, mode='exec')
    st = StubTraverser(controller=controller)
    # From StubTraverser.run.
    st.parent_stub = Stub(kind='root', name='&lt;new-stubs&gt;')
    st.visit(node)
    # Allocate a StringIo file for output_stubs.
    st.output_file = io.StringIO()
    st.output_stubs(st.parent_stub)
    # Test.
    lines = g.splitLines(st.output_file.getvalue())
    self.assertEqual(lines, expected)
</t>
<t tx="ekr.20180901051603.1">def test_bug3(self):
    # https://github.com/edreamleo/make-stub-files/issues/3
    tag = 'test_bug3'
    s = (
        'class UnsupportedAlgorithm(Exception):\n'
        '    def __init__(self, message: Any, reason: Optional[str]=None) -&gt; None:\n'
        '        pass\n'
    )
    expected = [
        'class UnsupportedAlgorithm(Exception):\n',
        '    def __init__(self, message: Any, reason: Optional[str]=None) -&gt; None: ...\n',
    ]
    controller = Controller()
    node = ast.parse(s, filename=tag, mode='exec')
    st = StubTraverser(controller=controller)
    # From StubTraverser.run.
    st.parent_stub = Stub(kind='root', name='&lt;new-stubs&gt;')
    st.visit(node)
    # Allocate a StringIo file for output_stubs.
    st.output_file = io.StringIO()
    st.output_stubs(st.parent_stub)
    # Test.
    lines = g.splitLines(st.output_file.getvalue())
    self.assertEqual(lines, expected)
</t>
<t tx="ekr.20210803055042.1">class TestMakeStubFiles(unittest.TestCase):  # pragma: no cover
    """Unit tests for make_stub_files.py"""
    @others
</t>
<t tx="ekr.20210804020706.1">g.cls()
command = r"python -m pytest --cov-report html --cov-report term-missing --cov make_stub_files make_stub_files.py"
g.execute_shell_commands(command, trace=False)
</t>
<t tx="ekr.20210804021331.1">g.cls()
"""Run make_stub_files with the given set of arguments."""
cfg = r'c:\users\Edward~1\make_stub_files.cfg'
msf = 'make_stub_files.py'
src = 'make_stub_files.py'
command = f"python {msf} -c {cfg} -o -v {src} -h"
g.execute_shell_commands(command, trace=False)</t>
<t tx="ekr.20210804060105.1">g.cls()
if 0:  # Run one test.
    # test = '.TestMakeStubFiles.test_file_msb'
    test = '.TestMakeStubFiles.test_ast_formatter_class'
else:  # Run all tests.
    test = ''
command = f"python -m unittest make_stub_files{test}"
g.execute_shell_commands(command, trace=False)</t>
<t tx="ekr.20210804103146.1">def test_pattern_class(self):
    g = LeoGlobals() # Use the g available to the script.
    table = (
        # s,  Pattern.find_s, Pattern.repl_s, expected
        ('aabbcc', '(a+)(b+)(c+)$', r'\3\2\1', 'ccbbaa'),
        ('[str]', r'\[str\]$', 'xxx', 'xxx'), # Guido bug.
        ('s3', r's[1-3]?\b$', 'str', 'str'), # lengthening bug.
        ('s', 's', 'str', 'str'),
        ('abc', 'abc', 'ABC', 'ABC'),
        ('str(str)', 'str(*)', 'str', 'str'),
        ('[whatever]', '[*]', 'List[*]', 'List[whatever]'), # * on the RHS.
        ('(int,str)', '(*)', 'Tuple[*]', 'Tuple[int,str]'), # Guido bug 2.
        ('abcxyz', 'abc*', 'xxx', 'xxx'), # New test for trailing *.
        ('list(self.regex.finditer(str))','list(*)','List[*]',
         'List[self.regex.finditer(str)]'),
    )
    for s, find, repl, expected in table:
        pattern = Pattern(find, repl)
        result = pattern.match_entire_string(s)
        self.assertTrue(result, msg=repr(s))
        aList = pattern.all_matches(s)
        self.assertTrue(len(aList) == 1, msg=repr(aList))
        found, s2 = pattern.match(s)
        self.assertTrue(found, msg=f"after pattern.match({s!r})")
        assert s2 == expected, (s, pattern, 'expected', expected, 'got', s2)
    p1 = Pattern('abc','xyz')
    p2 = Pattern('abc','xyz')
    p3 = Pattern('abc','pdq')
    self.assertEqual(p1, p2)
    self.assertNotEqual(p1, p3)
    self.assertNotEqual(p2, p3)
    aSet = set()
    aSet.add(p1)
    self.assertTrue(p1 in aSet)
    self.assertTrue(p2 in aSet)
    self.assertFalse(p3 in aSet)
    self.assertEqual(list(aSet), [p1])
    self.assertEqual(list(aSet), [p2])
    aSet.add(p3)
    self.assertTrue(p1.match_entire_string('abc'))
    self.assertFalse(p1.match_entire_string('abcx'))
</t>
<t tx="ekr.20210804105256.1">def test_reduce_numbers(self):
    a, c, f, i, l, n = ('Any', 'complex', 'float', 'int', 'long', 'number')
    table = (
        ([i,i],     [i]),
        ([i],       [i]),
        ([f, i],    [f]),
        ([c, i],    [c]),
        ([l, a],    [a, l]),
    )
    for aList, expected in table:
        got = ReduceTypes().reduce_numbers(aList)
        self.assertEqual(expected, got, msg=repr(aList))
</t>
<t tx="ekr.20210804111613.1">def test_reduce_types(self):

    a, c, f, i, l, n = ('Any', 'complex', 'float', 'int', 'long', 'number')
    none = 'None'
    x = 'xyzzy'
    y = 'pdq'
    table = (
        ([i,i],         i),
        ([i],           i),
        ([f, i],        f),
        ([c, i],        c),
        ([l, a],        'Union[Any, long]'),
        # Handle None
        ([None],        none),
        ([None, None],  none),
        ([None, a, c],  'Optional[Union[Any, complex]]'),
        # Handle unknown types, and special cases
        ([i, x],        'Union[Any, int]'),
        ([None, x],     'Optional[Any]'),
        ([none, x],     'Optional[Any]'),
        (['', x],       'Optional[Any]'),
        ([none, x, c],  'Optional[Union[Any, complex]]'),
        ([x, y],        'Any'),
        # Collection merging.  More could be done...
        (['Dict[int, str]', 'Dict[Any, str]'],          'Union[Dict[Any, str], Dict[int, str]]'),
        (['List[int, str]', 'List[Any, str]'],          'Union[List[Any, str], List[int, str]]'),
        (['Union[int, str]', 'Union[Any, str]'],        'Union[Union[Any, str], Union[int, str]]'),
        (['Union[int, str]', 'int', 'Union[Any, str]'], 'Union[Union[Any, str], Union[int, str], int]'),
        (['Tuple[xyz, pdq]'],                           'Tuple[Any, Any]'),
    )
    for aList, expected in table:
        got = reduce_types(aList)  # Call the global function for better coverage.
        self.assertEqual(expected, got, msg=repr(aList))
</t>
<t tx="ekr.20210804111803.1">def test_split_types(self):
    table = (
        ('list',                    ['list']),
        ('List[a,b]',               ['List[a,b]']),
        ('List[a,b], List[c,d]',    ['List[a,b]', 'List[c,d]']),
    )
    for s, expected in table:
        got = ReduceTypes().split_types(s)
        self.assertEqual(expected, got, msg=repr(s))
</t>
<t tx="ekr.20210804111915.1">def test_st_find(self):

    s = """\
def is_known_type(s: str) -&gt; Union[Any,bool]: ...
def main() -&gt; None: ...
def merge_types(a1: Any, a2: Any) -&gt; str: ...

class AstFormatter:
    def format(self, node: Node) -&gt; Union[Any,str]: ...
        def helper(self): -&gt; None
    def visit(self, node: Node) -&gt; str: ...
    def do_ClassDef(self, node: Node) -&gt; str: ...
    def do_FunctionDef(self, node: Node) -&gt; str: ...
"""
    g = LeoGlobals() # Use the g available to the script.
    st = StubTraverser(controller=g.NullObject())
    d, root = st.parse_stub_file(s, root_name='&lt;root&gt;')  # Root *is* used below.
    if 0:
        print(st.trace_stubs(root, header='root'))
    stub1 = Stub(kind='class', name='AstFormatter')
    stub2 = Stub(kind='def', name='format', parent=stub1, stack=['AstFormatter'])
    stub3 = Stub(kind='def', name='helper', parent = stub2, stack=['AstFormatter', 'format'])
    # stub4 = Stub(kind='def', name='main')
    for stub in (stub1, stub2, stub3,):  # (stub1, stub2, stub3):
        found = st.find_stub(stub, root)
        id_found = found and id(found) or None
        if 0:
            print('found  %s =&gt; %9s %35s ==&gt; %s' % (id(stub), id_found, stub, found))
        found = st.find_parent_stub(stub, root)
        id_found = found and id(found) or None
        if 0:
            print('parent %s =&gt; %9s %35s ==&gt; %s' % (id(stub), id_found, stub, found))
</t>
<t tx="ekr.20210804112211.1">def test_st_flatten_stubs(self):
    s = """\
    def is_known_type(s: str) -&gt; Union[Any,bool]: ...
    def main() -&gt; None: ...
    def merge_types(a1: Any, a2: Any) -&gt; str: ...
    
    class AstFormatter:
        def format(self, node: Node) -&gt; Union[Any,str]: ...
            def helper(self): -&gt; None
        def visit(self, node: Node) -&gt; str: ...
        def do_ClassDef(self, node: Node) -&gt; str: ...
        def do_FunctionDef(self, node: Node) -&gt; str: ...
    """
    g = LeoGlobals()  # Use the g available to the script.
    st = StubTraverser(controller=g.NullObject())
    d, root = st.parse_stub_file(s, root_name='&lt;root&gt;')
    if 0:
        print(st.trace_stubs(root, header='root'))
    aList = st.flatten_stubs(root)
    self.assertTrue(aList)
    if 0:
        for i, stub in enumerate(aList):
            print('%2s %s' % (i, stub))
    for stub in aList:
        found = st.find_stub(stub, root)
        self.assertTrue(found, msg=repr(stub))
</t>
<t tx="ekr.20210804112405.1">def test_st_merge_stubs(self):
    # To do:
    # - Test between-stub lines and leading lines.
    # - Round-trip tests!
    &lt;&lt; old_stubs &gt;&gt;
    &lt;&lt; new_stubs &gt;&gt;
    g = LeoGlobals() # Use the g available to the script.
    st = StubTraverser(controller=g.NullObject())
    # dump('old_s', old_s)
    # dump('new_s', new_s)
    old_d, old_root = st.parse_stub_file(old_s, root_name='&lt;old-root&gt;')
    new_d, new_root = st.parse_stub_file(new_s, root_name='&lt;new-root&gt;')
    if 0:
        dump_dict('old_d', old_d)
        dump_dict('new_d', new_d)
        print(st.trace_stubs(old_root, header='trace_stubs(old_root)'))
        print(st.trace_stubs(new_root, header='trace_stubs(new_root)'))
    if 0:  # separate unit test. Passed.
        aList = st.sort_stubs_by_hierarchy(new_root)
        dump_list(aList, 'after sort_stubs_by_hierarcy')
    new_stubs = new_d.values()
    st.merge_stubs(new_stubs, old_root, new_root, trace=False)
    if 0:
        print(st.trace_stubs(old_root, header='trace_stubs(old_root)'))
</t>
<t tx="ekr.20210804112405.3">old_s = """\
def main() -&gt; None: ...
def merge_types(a1: Any, a2: Any) -&gt; str: ...
def pdb(self) -&gt; None: ...
def reduce_types(aList: List[Any], name: str=None, trace: bool=False) -&gt; Any: ...
class Pattern(object):
    def __init__(self, find_s: str, repl_s: str='') -&gt; None: ...
    def __eq__(self, obj: Any) -&gt; bool: ...
    def __ne__(self, obj: Any) -&gt; bool: ...
    def __hash__(self) -&gt; int: ...
    def __repr__(self) -&gt; str: ...
    def is_balanced(self) -&gt; bool: ...
    def is_regex(self) -&gt; Any: ...
        #   0: return self.find_s.endswith('$')
        # ? 0: return self.find_s.endswith(str)
"""
</t>
<t tx="ekr.20210804112405.4">new_s = """\
def is_known_type(s: str) -&gt; Union[Any,bool]: ...
def main() -&gt; None: ...
def merge_types(a1: Any, a2: Any) -&gt; str: ...
def pdb(self) -&gt; None: ...
def reduce_numbers(aList: List[Any]) -&gt; List[Any]: ...
def reduce_types(aList: List[Any], name: str=None, trace: bool=False) -&gt; Any: ...

class AstFormatter:
    def format(self, node: Node) -&gt; Union[Any,str]: ...
    def visit(self, node: Node) -&gt; str: ...
    def do_ClassDef(self, node: Node) -&gt; str: ...
    def do_FunctionDef(self, node: Node) -&gt; str: ...
"""
</t>
<t tx="ekr.20210804112556.1">def test_stub_class(self):
    g = LeoGlobals()  # Use the g available to the script.
    # Test equality...
    stub1 = Stub(kind='def', name='foo')
    stub2 = Stub(kind='class', name='foo')
    stub3 = Stub(kind='def', name='bar')
    stub4 = Stub(kind='def', name='foo')
    stub4.out_list = ['xyzzy']  # Contents of out_list must not affect equality!
    aList = [stub1, stub3]
    self.assertNotEqual(stub1, stub2)
    self.assertNotEqual(stub1, stub3)
    self.assertEqual(stub1, stub4)
    self.assertTrue(stub1 in aList)
    self.assertFalse(stub2 in aList)
    self.assertTrue(stub3 in aList)
    # Test __hash__
    d = {stub1: 'stub1'}
    self.assertTrue(stub1 in d)
    self.assertFalse(stub2 in d)
    # Test parents and level.
    stub_1 = Stub(kind='def', name='stub_1')
    stub_2 = Stub(kind='def', name='stub_2', parent=stub_1, stack=['stub_1'])
    stub_3 = Stub(kind='def', name='stub_3', parent=stub_2, stack=['stub_1', 'stub_2'])
    self.assertEqual(stub_1.parents(), [], msg=repr(stub_1.parents()))
    self.assertEqual(stub_2.parents(), ['stub_1'], msg=repr(stub_2.parents()))
    self.assertEqual(stub_3.parents(), ['stub_1', 'stub_2'], msg=repr(stub_3.parents()))
    self.assertEqual(stub_1.level(), 0)
    self.assertEqual(stub_2.level(), 1)
    self.assertEqual(stub_3.level(), 2)
</t>
<t tx="ekr.20210804153200.1">"""Convert all following @test nodes."""
g.cls()

def body(p):
    def_s = f"def {headline(p)}(self):\n"
    lines = [' '*4 + z.rstrip()+'\n' for z in g.splitLines(p.b) if '@others' not in z]
    return def_s + ''.join(lines)

def headline(p):
    return p.h[1:].replace('-','_').replace(' ','_').replace('__', '_')

while p:
    if p.h.startswith('@test'):
        if 1:  # Change.
            print(p.h)
            p.b = body(p)  # body first, to use original headline.
            p.h = headline(p)
            p.setDirty()
        else:  # Report.
            h = headline(p)
            b = body(p)
            print(h.rstrip())
            print(b.rstrip())
            print('-'*40)
    p.moveToThreadNext()
c.redraw()
</t>
<t tx="ekr.20210804214511.1">def do_Constant(self, node):  # #13
    return repr(node.value)
</t>
<t tx="ekr.20210805053830.1">@language rest

https://github.com/edreamleo/make-stub-files/issues/18

@language python
@nosearch
</t>
<t tx="ekr.20210805061637.1"></t>
<t tx="ekr.20210805061856.1"></t>
<t tx="ekr.20210805061902.1"></t>
<t tx="ekr.20210805090003.1"></t>
<t tx="ekr.20210805090544.1"></t>
<t tx="ekr.20210805090943.1">def test_ast_formatter_class(self):
    formatter = AstFormatter()
    if 0:  # For debugging.
        tests = ["""\
            def yield_test():
                yield 1
            """
    ]
    else:
        tests = [
        &lt;&lt; define tests &gt;&gt;
        ]
    for i, source_data in enumerate(tests):
        filename = f"test {i+1}"
        if isinstance(source_data, str):
            source = textwrap.dedent(source_data)
            expected_s = textwrap.dedent(source)
        else:
            source, expected = source_data
            source = textwrap.dedent(source)
            expected_s = textwrap.dedent(expected)
        node = ast.parse(source, filename=filename, mode='exec')
        try:
            result_s = formatter.format(node)
        except Exception:
            self.fail(filename)
        lines = g.splitLines(result_s)
        expected = g.splitLines(expected_s)
        self.assertEqual(expected, lines, msg=filename)
</t>
<t tx="ekr.20210805091045.1"></t>
<t tx="ekr.20210805092921.1"></t>
<t tx="ekr.20210805093004.1"></t>
<t tx="ekr.20210805093615.1">def test_file_msb(self):
    """Run make_stub_files on itself."""
    if 1:
        # This test is was only briefly useful.
        # In general, this test masks proper testing.
        self.skipTest('Prevents proper coverage data')
    elif 1:
        # Actually creates stubs.
        # f"python {msf} -c {cfg} -o -v {src}"
        directory = os.path.dirname(__file__)
        config_fn = os.path.normpath(os.path.abspath(os.path.expanduser('make_stub_files.cfg')))
        sys.argv = ['python', '-c', config_fn, '-o', '-v', __file__]
        main()
    else: # Works: (Like main function)
        controller = Controller()
        # Set ivars instead of calling scan_command_line.
        fn = __file__
        directory = os.path.dirname(__file__)
        controller.config_fn = finalize(os.path.join(directory, 'make_stub_files.cfg'))
        assert os.path.exists(controller.config_fn), controller.config_fn
        controller.overwrite = True
        # Go!
        controller.scan_options()
        for fn in controller.files:
            controller.make_stub_file(fn)
</t>
<t tx="ekr.20210805102238.1"></t>
<t tx="ekr.20210805144859.1"># Tests are either a single string, or a tuple: (source, expected).

# Test 1. Class.
"""\
class AstFormatter:
    def format(self, node: Node) -&gt; Union[Any, str]:
        pass
""",
# Test 2: Constant.
"""\
a = 1
b = 2.5
c = False
d = None
""",
# Test 3: ClassDef
(
"""\
@class_decorator
class TestClass(str, base2=int):
    pass
""",
"""\
@class_decorator
class TestClass(str, base2=int): ...
    pass
""",
),
# Test 4: FunctionDef
"""\
@function_decorator
def f():
    pass
""",
# Test 5: Position-only arg.
"""\
def pos_only_arg(arg, /):
    pass
""",
# Test 6: Keyword-only arg.
"""\
def kwd_only_arg(*, arg, arg2=None):
    pass
""",
# Test 7: Position-only and keyword-only args.
"""\
def combined_example(pos_only, /, standard, *, kwd_only):
    pass
""",
# Test 8: Call.
"print(*args, **kwargs)\n",
# Test 9: Slices: Python 3.9 does not use ExtSlice.
"print(s[0:1:2])\n",
# Test 10: Continue.
"""\
while 1:
    continue
""",
# Test 11: Delete.
"del a\n",
# Test 12: ExceptHandler.
"""\
try:
    pass
except Exception as e:
    print('oops')
else:
    print('else')
finally:
    print('finally')
""",
# Test 13: ImportFrom.
"from a import b as c\n",
# Test 14: Nonlocal.
"""\
def nonlocal_test():
    nonlocal a
""",
# Test 15: Raise.
"""\
raise Exception('spam', 'eggs')
raise
""",
# Test 16: While.
"""\
while True:
    print(True)
else:
    print('else')
""",
# Test 17: With.
"""\
with open(f, 'r') as f:
    f.read()
""",
# Test 18: Yield and YieldFrom.
"""\
def yield_test():
    yield 1
    yield from z
    yield
""",
</t>
<t tx="ekr.20210806005225.1"># FormattedValue(expr value, int? conversion, expr? format_spec)

def do_FormattedValue(self, node):
    return self.visit(node.value)
    
def do_JoinedStr(self, node):
    return "%s" % ''.join(self.visit(z) for z in node.values or [])

</t>
<t tx="ekr.20210806011736.1">def test_ast_formatter_class_on_file(self):
    # Use the source of *this* file as a single test.
    filename = __file__
    formatter = AstFormatter()
    with open(filename, 'r') as f:
        source = f.read()
    node = ast.parse(source, filename=filename, mode='exec')
    result_s = formatter.format(node)
    assert result_s
</t>
<t tx="ekr.20210806081329.1"></t>
<t tx="ekr.20210806132036.1">@pagewidth 90

description = textwrap.dedent("""\

make_stub_files: Create stubs (.pyi files) using patterns, not type inference.

make_stub_files applies patterns to argument names and the text of return expressions and
creates annotations when the patterns match. (Return expressions are the text of whatever
follows the "return" keyword.)

Before applying patterns, make_stub_files removes comments from return expressions and
converts all strings to "str". This preprocessing simplifies pattern matching.

See README.md for examples.
"""
)</t>
<t tx="ekr.20210806134651.1"></t>
<t tx="ekr.20210806153836.1">def test_finalize(self):
    result = finalize(__file__)
    self.assertEqual(result, __file__)
</t>
<t tx="ekr.20210806154007.1">def test_is_known_type(self):
    self.assertTrue(is_known_type('str'))
</t>
<t tx="ekr.20210806161202.1">class T(base=None):
    pass
    
T(base=str)
print(T)</t>
<t tx="ekr.20210806162349.1"></t>
<t tx="ekr.20210807105513.1">@nosearch
</t>
<t tx="ekr.20210807105645.1"></t>
<t tx="ekr.20210807105658.1"></t>
<t tx="ekr.20210807105711.1"></t>
<t tx="ekr.20210807105731.1"></t>
</tnodes>
</leo_file>
