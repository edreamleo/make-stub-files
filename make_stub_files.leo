<?xml version="1.0" encoding="utf-8"?>
<!-- Created by Leo: http://leoeditor.com/leo_toc.html -->
<?xml-stylesheet ekr_test ?>
<leo_file xmlns:leo="http://leoeditor.com/namespaces/leo-python-editor/1.1" >
<leo_header file_format="2" tnodes="0" max_tnode_index="0" clone_windows="0"/>
<globals body_outline_ratio="0.5" body_secondary_ratio="0.5">
	<global_window_position top="50" left="50" height="500" width="700"/>
	<global_log_window_position top="0" left="0" height="0" width="0"/>
</globals>
<preferences/>
<find_panel_settings/>
<vnodes>
<v t="ekr.20160207181637.1"><vh>Startup</vh>
<v t="ekr.20160207181648.1"><vh>@settings</vh>
<v t="ekr.20160207181710.1"><vh>@data history-list</vh></v>
<v t="ekr.20160207181843.1"><vh>@button cfa-code</vh></v>
<v t="ekr.20160207182535.1"><vh>@bool preload-find-pattern = False</vh></v>
</v>
<v t="ekr.20160207105647.1"><vh>Scripts</vh>
<v t="ekr.20160206095102.1"><vh>@button write-unit-tests</vh>
<v t="ekr.20160206095102.2"><vh>&lt;&lt; docstring &gt;&gt; (write-unit-tests)</vh></v>
<v t="ekr.20160206101802.3"><vh>class TestWriter</vh>
<v t="ekr.20160206101802.4"><vh>&lt;&lt; define file_template &gt;&gt;</vh></v>
<v t="ekr.20160206101802.5"><vh>&lt;&lt; define test_template &gt;&gt;</vh></v>
<v t="ekr.20160206101802.6"><vh> ctor</vh></v>
<v t="ekr.20160206101802.7"><vh>clean</vh></v>
<v t="ekr.20160206101802.8"><vh>get_body</vh></v>
<v t="ekr.20160206101802.9"><vh>run</vh></v>
<v t="ekr.20160206103417.1"><vh>plural</vh></v>
<v t="ekr.20160206101802.10"><vh>test</vh></v>
<v t="ekr.20160206101802.11"><vh>write_file</vh></v>
</v>
</v>
<v t="ekr.20160207105710.1"><vh>@button check-leading-lines</vh></v>
</v>
<v t="ekr.20160126153016.3"><vh>Unused</vh>
<v t="ekr.20160203134203.1"><vh>pattern.__gt/lt/ge/le__</vh></v>
<v t="ekr.20160202061118.1"><vh>sf.visit (attempts all matches on all nodes)</vh></v>
<v t="ekr.20160202064553.1"><vh>sf.match</vh></v>
<v t="ekr.20160208162138.1"><vh>from st.Call (failed experiment)</vh></v>
<v t="ekr.20160209103842.1"><vh>Unused from Stub</vh>
<v t="ekr.20160203134611.1"><vh>stub.__gt/lt/ge/le__</vh></v>
<v t="ekr.20160203154154.1"><vh>from Stub.__gt__</vh></v>
</v>
<v t="ekr.20160210184122.1"><vh>reduce_types (OLD, splits lines)</vh>
<v t="ekr.20160210184122.2"><vh>&lt;&lt; define show &gt;&gt;</vh></v>
</v>
<v t="ekr.20160210190143.1"><vh>old merge_stubs (asserts fail)</vh></v>
</v>
</v>
<v t="ekr.20160128154704.1"><vh>Files</vh>
<v t="ekr.20160210112634.1"><vh>Test files</vh>
<v t="ekr.20160128154715.1"><vh>@clean test/test_msf.py</vh>
<v t="ekr.20160128190252.1"><vh>setUp</vh></v>
<v t="ekr.20160128190112.1"><vh>test_pattern_class</vh></v>
<v t="ekr.20160128190224.1"><vh>test_is_known_type</vh></v>
</v>
<v t="ekr.20160206104033.1"><vh>@@test run all msf unit tests</vh></v>
<v t="ekr.20160206165656.1"><vh>@clean test/test.py</vh></v>
</v>
<v t="ekr.20160128104714.1"><vh>Config files</vh>
<v t="ekr.20160128225533.1"><vh>@clean .gitignore</vh></v>
<v t="ekr.20160128102557.1"><vh>@clean example.cfg</vh></v>
<v t="ekr.20160128104639.1"><vh>@clean msf.cfg</vh></v>
<v t="ekr.20160126153220.1"><vh>@clean make_stub_files.cfg</vh></v>
<v t="ekr.20160206165507.1"><vh>@clean test.cfg</vh></v>
</v>
<v t="ekr.20160128105006.1"><vh>Doc files</vh>
<v t="ekr.20160126153921.1"><vh>@edit README.md</vh></v>
<v t="ekr.20160207101607.1"><vh>@edit theory.md</vh></v>
<v t="ekr.20160209063927.1"><vh>Must read Aha: the code is pre-determined!</vh></v>
</v>
</v>
<v t="ekr.20160206171945.1"><vh>Unit tests</vh>
<v t="ekr.20160210080720.1" a="M"><vh>@test --update</vh>
<v t="ekr.20160203075612.1"><vh> &lt;&lt; imports &gt;&gt; (make_stub_files.py)</vh></v>
<v t="ekr.20160210081628.1"><vh>&lt;&lt; old_stubs &gt;&gt;</vh></v>
<v t="ekr.20160210144515.1"><vh>&lt;&lt; new_stubs &gt;&gt;</vh></v>
<v t="ekr.20160206104634.1"><vh>  top-level functions</vh>
<v t="ekr.20160210083825.1"><vh>dump</vh></v>
<v t="ekr.20160210141342.1"><vh>dump_dict</vh></v>
<v t="ekr.20160210141651.1"><vh>dump_list</vh></v>
<v t="ekr.20160130034812.1"><vh>is_known_type (split_types)</vh></v>
<v t="ekr.20160126153212.100"><vh>main</vh></v>
<v t="ekr.20160207051316.1"><vh>merge_types (returns list, not used)</vh></v>
<v t="ekr.20160206120522.1"><vh>pdb</vh></v>
<v t="ekr.20160205101134.1"><vh>reduce_numbers (returns list)</vh></v>
<v t="ekr.20160205072101.1"><vh>reduce_types (--trace-reduce, returns string)</vh>
<v t="ekr.20160207133035.1"><vh>&lt;&lt; define show &gt;&gt;</vh></v>
</v>
<v t="ekr.20160206212123.1"><vh>split_types</vh></v>
<v t="ekr.20160207115604.1"><vh>truncate</vh></v>
</v>
<v t="ekr.20160210082857.1"><vh>base classes</vh>
<v t="ekr.20160126153212.3"><vh> class AstFormatter</vh>
<v t="ekr.20160126153212.4"><vh> f.Entries</vh>
<v t="ekr.20160126153212.5"><vh>f.format</vh></v>
<v t="ekr.20160126153212.6"><vh>f.visit</vh></v>
</v>
<v t="ekr.20160126153212.7"><vh>f.Contexts</vh>
<v t="ekr.20160126153212.8"><vh>f.ClassDef</vh></v>
<v t="ekr.20160126153212.9"><vh>f.FunctionDef</vh></v>
<v t="ekr.20160126153212.10"><vh>f.Interactive</vh></v>
<v t="ekr.20160126153212.11"><vh>f.Module</vh></v>
<v t="ekr.20160126153212.12"><vh>f.Lambda</vh></v>
</v>
<v t="ekr.20160126153212.13"><vh>f.Expressions</vh>
<v t="ekr.20160126153212.14"><vh>f.Expr</vh></v>
<v t="ekr.20160126153212.15"><vh>f.Expression</vh></v>
<v t="ekr.20160126153212.16"><vh>f.GeneratorExp</vh></v>
<v t="ekr.20160126153212.17"><vh>f.ctx nodes</vh></v>
</v>
<v t="ekr.20160126153212.18"><vh>f.Operands</vh>
<v t="ekr.20160126153212.19"><vh>f.arguments</vh></v>
<v t="ekr.20160126153212.20"><vh>f.arg (Python3 only)</vh></v>
<v t="ekr.20160126153212.21"><vh>f.Attribute</vh></v>
<v t="ekr.20160126153212.22"><vh>f.Bytes</vh></v>
<v t="ekr.20160126153212.23"><vh>f.Call &amp; f.keyword</vh>
<v t="ekr.20160126153212.24"><vh>f.keyword</vh></v>
</v>
<v t="ekr.20160126153212.25"><vh>f.comprehension</vh></v>
<v t="ekr.20160126153212.26"><vh>f.Dict</vh></v>
<v t="ekr.20160126153212.27"><vh>f.Ellipsis</vh></v>
<v t="ekr.20160126153212.28"><vh>f.ExtSlice</vh></v>
<v t="ekr.20160126153212.29"><vh>f.Index</vh></v>
<v t="ekr.20160126153212.30"><vh>f.List</vh></v>
<v t="ekr.20160126153212.31"><vh>f.ListComp</vh></v>
<v t="ekr.20160126153212.32"><vh>f.Name</vh></v>
<v t="ekr.20160126153212.33"><vh>f.Num</vh></v>
<v t="ekr.20160126153212.34"><vh>f.Repr</vh></v>
<v t="ekr.20160126153212.35"><vh>f.Slice</vh></v>
<v t="ekr.20160126153212.36"><vh>f.Str</vh></v>
<v t="ekr.20160126153212.37"><vh>f.Subscript</vh></v>
<v t="ekr.20160205143923.1"><vh>f.Tuple</vh></v>
</v>
<v t="ekr.20160126153212.39"><vh>f.Operators</vh>
<v t="ekr.20160126153212.40"><vh>f.BinOp</vh></v>
<v t="ekr.20160126153212.41"><vh>f.BoolOp</vh></v>
<v t="ekr.20160126153212.42"><vh>f.Compare</vh></v>
<v t="ekr.20160126153212.43"><vh>f.UnaryOp</vh></v>
<v t="ekr.20160126153212.44"><vh>f.ifExp (ternary operator)</vh></v>
</v>
<v t="ekr.20160126153212.45"><vh>f.Statements</vh>
<v t="ekr.20160126153212.46"><vh>f.Assert</vh></v>
<v t="ekr.20160126153212.47"><vh>f.Assign</vh></v>
<v t="ekr.20160126153212.48"><vh>f.AugAssign</vh></v>
<v t="ekr.20160126153212.49"><vh>f.Break</vh></v>
<v t="ekr.20160126153212.50"><vh>f.Continue</vh></v>
<v t="ekr.20160126153212.51"><vh>f.Delete</vh></v>
<v t="ekr.20160126153212.52"><vh>f.ExceptHandler</vh></v>
<v t="ekr.20160126153212.53"><vh>f.Exec</vh></v>
<v t="ekr.20160126153212.54"><vh>f.For</vh></v>
<v t="ekr.20160126153212.55"><vh>f.Global</vh></v>
<v t="ekr.20160126153212.56"><vh>f.If</vh></v>
<v t="ekr.20160126153212.57"><vh>f.Import &amp; helper</vh>
<v t="ekr.20160126153212.58"><vh>f.get_import_names</vh></v>
</v>
<v t="ekr.20160126153212.59"><vh>f.ImportFrom</vh></v>
<v t="ekr.20160126153212.60"><vh>f.Pass</vh></v>
<v t="ekr.20160126153212.61"><vh>f.Print</vh></v>
<v t="ekr.20160126153212.62"><vh>f.Raise</vh></v>
<v t="ekr.20160126153212.63"><vh>f.Return</vh></v>
<v t="ekr.20160126153212.64"><vh>f.TryExcept</vh></v>
<v t="ekr.20160126153212.65"><vh>f.TryFinally</vh></v>
<v t="ekr.20160126153212.66"><vh>f.While</vh></v>
<v t="ekr.20160126153212.67"><vh>f.With</vh></v>
<v t="ekr.20160126153212.68"><vh>f.Yield</vh></v>
</v>
<v t="ekr.20160126153212.69"><vh>f.Utils</vh>
<v t="ekr.20160126153212.70"><vh>f.kind</vh></v>
<v t="ekr.20160126153212.71"><vh>f.indent</vh></v>
<v t="ekr.20160126153212.72"><vh>f.op_name</vh></v>
</v>
</v>
<v t="ekr.20160202165117.1"><vh>class AstArgFormatter (AstFormatter)</vh>
<v t="ekr.20160202165143.1"><vh>sf.Constants &amp; Name</vh></v>
</v>
<v t="ekr.20160131180118.1"><vh>class LeoGlobals</vh>
<v t="ekr.20160210143802.1"><vh>class NullObject (Python Cookbook)</vh></v>
<v t="ekr.20160203095618.2"><vh>g._callerName</vh></v>
<v t="ekr.20160203095618.1"><vh>g.callers</vh></v>
<v t="ekr.20160202170529.1"><vh>g.cls</vh></v>
<v t="ekr.20160131180244.1"><vh>g.pdb</vh></v>
<v t="ekr.20160203183934.1"><vh>g.shortFileName</vh></v>
<v t="ekr.20160206101140.1"><vh>g.splitLines</vh></v>
<v t="ekr.20160131180306.1"><vh>g.trace</vh></v>
</v>
<v t="ekr.20160126153212.80"><vh>class StubFormatter (AstFormatter)</vh>
<v t="ekr.20160202061329.1"><vh>sf.ctor</vh></v>
<v t="ekr.20160205131910.1"><vh>sf.match_all (trace-matches)</vh></v>
<v t="ekr.20160206203133.1"><vh>sf.visit</vh></v>
<v t="ekr.20160208093906.1"><vh>sf.trace_visitor</vh></v>
<v t="ekr.20160205053705.1"><vh>sf.Operands</vh>
<v t="ekr.20160205103604.4"><vh>sf.Attribute (names_dict)</vh></v>
<v t="ekr.20160126153212.81"><vh>sf.Constants: Bytes, Num, Str</vh></v>
<v t="ekr.20160205103604.9"><vh>sf.Dict ** call match_all?</vh></v>
<v t="ekr.20160206204452.1"><vh>sf.List ** call_match_all?</vh></v>
<v t="ekr.20160204153904.1"><vh>sf.Name (names_dict)</vh></v>
<v t="ekr.20160126153212.38"><vh>sf.Tuple (match_all)</vh></v>
</v>
<v t="ekr.20160205053641.1"><vh>sf.Operators</vh>
<v t="ekr.20160205053641.2"><vh>sf.BinOp (reduce_types &amp; match_all)</vh></v>
<v t="ekr.20160205053641.3"><vh>sf.BoolOp (reduce_types)</vh></v>
<v t="ekr.20160205103604.6"><vh>sf.Call &amp; sf.keyword (match_all)</vh>
<v t="ekr.20160205103604.7"><vh>sf.keyword</vh></v>
</v>
<v t="ekr.20160205053641.4"><vh>sf.Compare</vh></v>
<v t="ekr.20160205053641.6"><vh>sf.IfExp (reduce_types, match_all)</vh></v>
<v t="ekr.20160205142626.1"><vh>sf.Subscript (match_all)</vh></v>
<v t="ekr.20160205053641.5"><vh>sf.UnaryOp (match_all)</vh></v>
</v>
<v t="ekr.20160201194801.1"><vh>sf.Return</vh></v>
</v>
</v>
<v t="ekr.20160203073604.1"><vh>class Stub(object)</vh>
<v t="ekr.20160210134702.1"><vh>stub.__ctor__</vh></v>
<v t="ekr.20160203130235.1"><vh>stub.__eq__ and __ne__</vh></v>
<v t="ekr.20160203140342.1"><vh>stub.__hash__</vh></v>
<v t="ekr.20160210111955.1"><vh>stub.__repr__and __str__</vh></v>
<v t="ekr.20160210132520.1"><vh>stub.parents and level</vh></v>
</v>
<v t="ekr.20160126153212.82"><vh>class StubTraverser (ast.NodeVisitor)</vh>
<v t="ekr.20160126153212.83"><vh>st.ctor</vh></v>
<v t="ekr.20160209194832.1"><vh>st.add_stub</vh></v>
<v t="ekr.20160126153212.84"><vh>st.indent &amp; out</vh></v>
<v t="ekr.20160126153212.85"><vh>st.run (main line) &amp; helpers</vh>
<v t="ekr.20160203183228.1"><vh>st.output_stubs</vh></v>
<v t="ekr.20160209105448.1"><vh>st.output_time_stamp</vh></v>
<v t="ekr.20160204224242.1"><vh>st.update &amp; helpers</vh>
<v t="ekr.20160205060709.1"><vh>st.get_stub_file</vh></v>
<v t="ekr.20160205060807.1"><vh>st.parse_stub_file</vh></v>
<v t="ekr.20160210041431.1"><vh>st.merge_stubs &amp; helpers</vh>
<v t="ekr.20160210043910.1"><vh>st.find_parent_stub</vh></v>
<v t="ekr.20160210043933.1"><vh>st.find_stub</vh></v>
<v t="ekr.20160210043957.1"><vh>st.sort_stubs_by_hierarchy</vh></v>
</v>
<v t="ekr.20160209104843.1"><vh>st.trace_stubs</vh></v>
</v>
</v>
<v t="ekr.20160126153212.87"><vh>st.visit_ClassDef</vh></v>
<v t="ekr.20160126153212.88"><vh>st.visit_FunctionDef &amp; helpers</vh>
<v t="ekr.20160126153212.89"><vh>st.format_arguments &amp; helper</vh>
<v t="ekr.20160126153212.91"><vh>st.munge_arg</vh></v>
</v>
<v t="ekr.20160126153212.90"><vh>st.format_returns &amp; helpers</vh>
<v t="ekr.20160130032546.1"><vh>st.format_return_expressions</vh></v>
<v t="ekr.20160128122410.1"><vh>st.get_def_name</vh></v>
<v t="ekr.20160207190840.1"><vh>st.remove_recursive_calls</vh></v>
</v>
</v>
<v t="ekr.20160126153212.99"><vh>st.visit_Return</vh></v>
</v>
</v>
<v t="ekr.20160207051429.1"><vh>@test merge_types (not used)</vh>
<v t="ekr.20160207051316.1"></v>
</v>
<v t="ekr.20160206110004.1"><vh>@test Pattern class</vh>
<v t="ekr.20160128041938.1"><vh>class Pattern(object)</vh>
<v t="ekr.20160128113859.1"><vh>pattern.ctor</vh></v>
<v t="ekr.20160203130717.1"><vh>pattern.__eq__, __ne__, __hash__</vh></v>
<v t="ekr.20160128113914.1"><vh>pattern.str &amp; repr</vh></v>
<v t="ekr.20160128042857.1"><vh>pattern.is_balanced</vh></v>
<v t="ekr.20160206174054.1"><vh>pattern.is_regex</vh></v>
<v t="ekr.20160128042705.1"><vh>pattern.all_matches &amp; helpers</vh>
<v t="ekr.20160128051025.1"><vh>pattern.full_balanced_match</vh></v>
<v t="ekr.20160128045845.1"><vh>pattern.match_balanced</vh></v>
</v>
<v t="ekr.20160202070025.1"><vh>pattern.match (trace-matches)</vh></v>
<v t="ekr.20160128114726.1"><vh>pattern.match_entire_string</vh></v>
<v t="ekr.20160206174740.1"><vh>pattern.replace &amp; helpers</vh>
<v t="ekr.20160131204607.1"><vh>pattern.replace_balanced</vh></v>
<v t="ekr.20160206174547.1"><vh>pattern.replace_regex</vh></v>
</v>
</v>
</v>
<v t="ekr.20160206170515.1"><vh>@test reduce_numbers</vh>
<v t="ekr.20160205101134.1"></v>
</v>
<v t="ekr.20160206173343.1"><vh>@test reduce_types</vh>
<v t="ekr.20160128041938.1"></v>
<v t="ekr.20160130034812.1"></v>
<v t="ekr.20160207051316.1"></v>
<v t="ekr.20160205101134.1"></v>
<v t="ekr.20160205072101.1"></v>
</v>
<v t="ekr.20160207162818.1"><vh>@test split_types</vh>
<v t="ekr.20160206212123.1"></v>
</v>
<v t="ekr.20160210145128.1"><vh>@test st.find_stub &amp; find_parent_stub</vh>
<v t="ekr.20160203075612.1"></v>
<v t="ekr.20160210164250.1"><vh>&lt;&lt; define s &gt;&gt; (@test st.find/parent_stub)</vh></v>
<v t="ekr.20160210082857.1"></v>
<v t="ekr.20160203073604.1"></v>
<v t="ekr.20160126153212.82"></v>
</v>
<v t="ekr.20160210112945.1"><vh>@test Stub class</vh>
<v t="ekr.20160203075612.1"></v>
<v t="ekr.20160131180118.1"></v>
<v t="ekr.20160203073604.1"></v>
</v>
<v t="ekr.20160207115947.1"><vh>@test truncate</vh>
<v t="ekr.20160207115604.1"></v>
</v>
</v>
<v t="ekr.20160205133120.1"><vh>Recent</vh>
<v t="ekr.20160207165240.1"><vh>re: Improve inferences</vh>
<v t="ekr.20160126153212.90"></v>
<v t="ekr.20160205072101.1"></v>
<v t="ekr.20160205103604.6"></v>
<v t="ekr.20160126153212.88"></v>
<v t="ekr.20160126153212.87"></v>
</v>
<v t="ekr.20160207165031.1"><vh>re: merge List &amp; Tuple types</vh>
<v t="ekr.20160205072101.1"></v>
</v>
<v t="ekr.20160208161113.1"><vh>main types routines...</vh>
<v t="ekr.20160205072101.1"></v>
<v t="ekr.20160206212123.1"></v>
<v t="ekr.20160208093906.1"></v>
<v t="ekr.20160205053641.1"></v>
</v>
<v t="ekr.20160208060210.1"><vh>Notes for theory.md</vh></v>
</v>
<v t="ekr.20160126153212.1"><vh>@clean make_stub_files.py</vh>
<v t="ekr.20160203075612.1"></v>
<v t="ekr.20160206104634.1"></v>
<v t="ekr.20160126153212.3"></v>
<v t="ekr.20160202165117.1"></v>
<v t="ekr.20160131180118.1"></v>
<v t="ekr.20160128041938.1"></v>
<v t="ekr.20160126153212.73"><vh>class StandAloneMakeStubFile</vh>
<v t="ekr.20160126153212.74"><vh>msf.ctor</vh></v>
<v t="ekr.20160126165907.1"><vh>msf.finalize</vh></v>
<v t="ekr.20160126153212.75"><vh>msf.make_stub_file</vh></v>
<v t="ekr.20160126153212.76"><vh>msf.run</vh></v>
<v t="ekr.20160128154243.1"><vh>msf.run_all_unit_tests</vh></v>
<v t="ekr.20160126153212.77"><vh>msf.scan_command_line</vh></v>
<v t="ekr.20160126153212.78"><vh>msf.scan_options &amp; helpers</vh>
<v t="ekr.20160204170921.1"><vh>msf.make_op_name_dict</vh></v>
<v t="ekr.20160203105356.1"><vh>msf.create_parser</vh></v>
<v t="ekr.20160204170443.1"><vh>msf.find_pattern_ops (--trace-patterns)</vh></v>
<v t="ekr.20160203105721.1"><vh>msf.get_config_string</vh></v>
<v t="ekr.20160203074843.1"><vh>msf.init_parser</vh></v>
<v t="ekr.20160203094439.1"><vh>msf.is_section_name</vh></v>
<v t="ekr.20160204113206.1"><vh>msf.make_patterns_dict (--trace-patterns)</vh></v>
<v t="ekr.20160126153212.79"><vh>msf.scan_patterns</vh></v>
</v>
</v>
<v t="ekr.20160203073604.1"></v>
<v t="ekr.20160126153212.80"></v>
<v t="ekr.20160126153212.82"></v>
<v t="ekr.20160131175042.1"><vh>class TestClass</vh>
<v t="ekr.20160201125349.1"><vh>parse_group (Guido)</vh></v>
<v t="ekr.20160131192406.1"><vh>return_all</vh></v>
<v t="ekr.20160131192735.1"><vh>return_array</vh></v>
<v t="ekr.20160131175118.1"><vh>return_list</vh></v>
<v t="ekr.20160205161341.1"><vh>return_two_lists (fails)</vh></v>
</v>
</v>
<v t="ekr.20160131174909.1"><vh>** to do</vh>
<v t="ekr.20160210112748.1"><vh>Posts &amp; docs</vh></v>
<v t="ekr.20160210112711.1"><vh>later</vh></v>
<v t="ekr.20160210112727.1"><vh>Leo stuff</vh></v>
</v>
<v t="ekr.20160210112945.1"></v>
<v t="ekr.20160210041431.1"></v>
<v t="ekr.20160204224242.1"></v>
<v t="ekr.20160210080720.1" a="M"></v>
<v t="ekr.20160210193834.1"><vh>checkin log</vh></v>
</vnodes>
<tnodes>
<t tx="ekr.20160126153016.3"></t>
<t tx="ekr.20160126153212.1">#!/usr/bin/env python
'''
This script makes a stub (.pyi) file in the output directory for each
source file listed on the command line (wildcard file names are supported).

For full details, see README.md.

This file is in the public domain.
'''
&lt;&lt; imports &gt;&gt;
@others
g = LeoGlobals() # For ekr.
if __name__ == "__main__":
    main()
</t>
<t tx="ekr.20160126153212.10">
def do_Interactive(self, node):
    for z in node.body:
        self.visit(z)
</t>
<t tx="ekr.20160126153212.100">
def main():
    '''
    The driver for the stand-alone version of make-stub-files.
    All options come from ~/stubs/make_stub_files.cfg.
    '''
    # g.cls()
    controller = StandAloneMakeStubFile()
    controller.scan_command_line()
    controller.scan_options()
    controller.run()
    print('done')
</t>
<t tx="ekr.20160126153212.11">
def do_Module(self, node):
    assert 'body' in node._fields
    result = ''.join([self.visit(z) for z in node.body])
    return result # 'module:\n%s' % (result)
</t>
<t tx="ekr.20160126153212.12">
def do_Lambda(self, node):
    return self.indent('lambda %s: %s' % (
        self.visit(node.args),
        self.visit(node.body)))
</t>
<t tx="ekr.20160126153212.13">
# Expressions...
</t>
<t tx="ekr.20160126153212.14">
def do_Expr(self, node):
    '''An outer expression: must be indented.'''
    return self.indent('%s\n' % self.visit(node.value))
</t>
<t tx="ekr.20160126153212.15">
def do_Expression(self, node):
    '''An inner expression: do not indent.'''
    return '%s\n' % self.visit(node.body)
</t>
<t tx="ekr.20160126153212.16">
def do_GeneratorExp(self, node):
    elt = self.visit(node.elt) or ''
    gens = [self.visit(z) for z in node.generators]
    gens = [z if z else '&lt;**None**&gt;' for z in gens] # Kludge: probable bug.
    return '&lt;gen %s for %s&gt;' % (elt, ','.join(gens))
</t>
<t tx="ekr.20160126153212.17">
def do_AugLoad(self, node):
    return 'AugLoad'

def do_Del(self, node):
    return 'Del'

def do_Load(self, node):
    return 'Load'

def do_Param(self, node):
    return 'Param'

def do_Store(self, node):
    return 'Store'
</t>
<t tx="ekr.20160126153212.18">
# Operands...
</t>
<t tx="ekr.20160126153212.19">
# arguments = (expr* args, identifier? vararg, identifier? kwarg, expr* defaults)

def do_arguments(self, node):
    '''Format the arguments node.'''
    kind = self.kind(node)
    assert kind == 'arguments', kind
    args = [self.visit(z) for z in node.args]
    defaults = [self.visit(z) for z in node.defaults]
    # Assign default values to the last args.
    args2 = []
    n_plain = len(args) - len(defaults)
    for i in range(len(args)):
        if i &lt; n_plain:
            args2.append(args[i])
        else:
            args2.append('%s=%s' % (args[i], defaults[i - n_plain]))
    # Now add the vararg and kwarg args.
    name = getattr(node, 'vararg', None)
    if name: args2.append('*' + name)
    name = getattr(node, 'kwarg', None)
    if name: args2.append('**' + name)
    return ','.join(args2)
</t>
<t tx="ekr.20160126153212.20">
# Python 3:
# arg = (identifier arg, expr? annotation)

def do_arg(self, node):
    if node.annotation:
        return self.visit(node.annotation)
    else:
        return ''
</t>
<t tx="ekr.20160126153212.21">
# Attribute(expr value, identifier attr, expr_context ctx)

def do_Attribute(self, node):
    return '%s.%s' % (
        self.visit(node.value),
        node.attr) # Don't visit node.attr: it is always a string.
</t>
<t tx="ekr.20160126153212.22">
def do_Bytes(self, node): # Python 3.x only.
    return str(node.s)
</t>
<t tx="ekr.20160126153212.23">
# Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)

def do_Call(self, node):
    func = self.visit(node.func)
    args = [self.visit(z) for z in node.args]
    for z in node.keywords:
        # Calls f.do_keyword.
        args.append(self.visit(z))
    if getattr(node, 'starargs', None):
        args.append('*%s' % (self.visit(node.starargs)))
    if getattr(node, 'kwargs', None):
        args.append('**%s' % (self.visit(node.kwargs)))
    args = [z for z in args if z] # Kludge: Defensive coding.
    return '%s(%s)' % (func, ','.join(args))
</t>
<t tx="ekr.20160126153212.24">
# keyword = (identifier arg, expr value)

def do_keyword(self, node):
    # node.arg is a string.
    value = self.visit(node.value)
    # This is a keyword *arg*, not a Python keyword!
    return '%s=%s' % (node.arg, value)
</t>
<t tx="ekr.20160126153212.25">
def do_comprehension(self, node):
    result = []
    name = self.visit(node.target) # A name.
    it = self.visit(node.iter) # An attribute.
    result.append('%s in %s' % (name, it))
    ifs = [self.visit(z) for z in node.ifs]
    if ifs:
        result.append(' if %s' % (''.join(ifs)))
    return ''.join(result)
</t>
<t tx="ekr.20160126153212.26">
def do_Dict(self, node):
    result = []
    keys = [self.visit(z) for z in node.keys]
    values = [self.visit(z) for z in node.values]
    if len(keys) == len(values):
        # result.append('{\n' if keys else '{')
        result.append('{')
        items = []
        for i in range(len(keys)):
            items.append('%s:%s' % (keys[i], values[i]))
        result.append(', '.join(items))
        result.append('}')
        # result.append(',\n'.join(items))
        # result.append('\n}' if keys else '}')
    else:
        print('Error: f.Dict: len(keys) != len(values)\nkeys: %s\nvals: %s' % (
            repr(keys), repr(values)))
    return ''.join(result)
</t>
<t tx="ekr.20160126153212.27">
def do_Ellipsis(self, node):
    return '...'
</t>
<t tx="ekr.20160126153212.28">
def do_ExtSlice(self, node):
    return ':'.join([self.visit(z) for z in node.dims])
</t>
<t tx="ekr.20160126153212.29">
def do_Index(self, node):
    return self.visit(node.value)
</t>
<t tx="ekr.20160126153212.3">

class AstFormatter:
    '''
    A class to recreate source code from an AST.
    
    This does not have to be perfect, but it should be close.
    '''
    # pylint: disable=consider-using-enumerate
    @others
</t>
<t tx="ekr.20160126153212.30">
def do_List(self, node):
    # Not used: list context.
    # self.visit(node.ctx)
    elts = [self.visit(z) for z in node.elts]
    elst = [z for z in elts if z] # Defensive.
    return '[%s]' % ','.join(elts)
</t>
<t tx="ekr.20160126153212.31">
def do_ListComp(self, node):
    elt = self.visit(node.elt)
    gens = [self.visit(z) for z in node.generators]
    gens = [z if z else '&lt;**None**&gt;' for z in gens] # Kludge: probable bug.
    return '%s for %s' % (elt, ''.join(gens))
</t>
<t tx="ekr.20160126153212.32">
def do_Name(self, node):
    return node.id
</t>
<t tx="ekr.20160126153212.33">
def do_Num(self, node):
    return repr(node.n)
</t>
<t tx="ekr.20160126153212.34">
# Python 2.x only

def do_Repr(self, node):
    return 'repr(%s)' % self.visit(node.value)
</t>
<t tx="ekr.20160126153212.35">
def do_Slice(self, node):
    lower, upper, step = '', '', ''
    if getattr(node, 'lower', None) is not None:
        lower = self.visit(node.lower)
    if getattr(node, 'upper', None) is not None:
        upper = self.visit(node.upper)
    if getattr(node, 'step', None) is not None:
        step = self.visit(node.step)
    if step:
        return '%s:%s:%s' % (lower, upper, step)
    else:
        return '%s:%s' % (lower, upper)
</t>
<t tx="ekr.20160126153212.36">
def do_Str(self, node):
    '''This represents a string constant.'''
    return repr(node.s)
</t>
<t tx="ekr.20160126153212.37">
# Subscript(expr value, slice slice, expr_context ctx)

def do_Subscript(self, node):
    value = self.visit(node.value)
    the_slice = self.visit(node.slice)
    return '%s[%s]' % (value, the_slice)
</t>
<t tx="ekr.20160126153212.38">
def do_Tuple(self, node):
    '''StubFormatter.Tuple.'''
    elts = [self.visit(z) for z in node.elts]
    if 1:
        return 'Tuple[%s]' % ', '.join(elts)
    else:
        s = '(%s)' % ', '.join(elts)
        return self.match_all(node, s)
    # return 'Tuple[%s]' % ', '.join(elts)
</t>
<t tx="ekr.20160126153212.39">
# Operators...
</t>
<t tx="ekr.20160126153212.4">
# Entries...
</t>
<t tx="ekr.20160126153212.40">
def do_BinOp(self, node):
    return '%s%s%s' % (
        self.visit(node.left),
        self.op_name(node.op),
        self.visit(node.right))
</t>
<t tx="ekr.20160126153212.41">
def do_BoolOp(self, node):
    op_name = self.op_name(node.op)
    values = [self.visit(z) for z in node.values]
    return op_name.join(values)
</t>
<t tx="ekr.20160126153212.42">
def do_Compare(self, node):
    result = []
    lt = self.visit(node.left)
    ops = [self.op_name(z) for z in node.ops]
    comps = [self.visit(z) for z in node.comparators]
    result.append(lt)
    if len(ops) == len(comps):
        for i in range(len(ops)):
            result.append('%s%s' % (ops[i], comps[i]))
    else:
        print('can not happen: ops', repr(ops), 'comparators', repr(comps))
    return ''.join(result)
</t>
<t tx="ekr.20160126153212.43">
def do_UnaryOp(self, node):
    return '%s%s' % (
        self.op_name(node.op),
        self.visit(node.operand))
</t>
<t tx="ekr.20160126153212.44">
def do_IfExp(self, node):
    return '%s if %s else %s ' % (
        self.visit(node.body),
        self.visit(node.test),
        self.visit(node.orelse))
</t>
<t tx="ekr.20160126153212.45">
# Statements...
</t>
<t tx="ekr.20160126153212.46">
def do_Assert(self, node):
    test = self.visit(node.test)
    if getattr(node, 'msg', None):
        message = self.visit(node.msg)
        return self.indent('assert %s, %s' % (test, message))
    else:
        return self.indent('assert %s' % test)
</t>
<t tx="ekr.20160126153212.47">
def do_Assign(self, node):
    return self.indent('%s=%s\n' % (
        '='.join([self.visit(z) for z in node.targets]),
        self.visit(node.value)))
</t>
<t tx="ekr.20160126153212.48">
def do_AugAssign(self, node):
    return self.indent('%s%s=%s\n' % (
        self.visit(node.target),
        self.op_name(node.op), # Bug fix: 2013/03/08.
        self.visit(node.value)))
</t>
<t tx="ekr.20160126153212.49">
def do_Break(self, node):
    return self.indent('break\n')
</t>
<t tx="ekr.20160126153212.5">
def format(self, node):
    '''Format the node (or list of nodes) and its descendants.'''
    self.level = 0
    val = self.visit(node)
    return val and val.strip() or ''
</t>
<t tx="ekr.20160126153212.50">
def do_Continue(self, node):
    return self.indent('continue\n')
</t>
<t tx="ekr.20160126153212.51">
def do_Delete(self, node):
    targets = [self.visit(z) for z in node.targets]
    return self.indent('del %s\n' % ','.join(targets))
</t>
<t tx="ekr.20160126153212.52">
def do_ExceptHandler(self, node):
    result = []
    result.append(self.indent('except'))
    if getattr(node, 'type', None):
        result.append(' %s' % self.visit(node.type))
    if getattr(node, 'name', None):
        if isinstance(node.name, ast.AST):
            result.append(' as %s' % self.visit(node.name))
        else:
            result.append(' as %s' % node.name) # Python 3.x.
    result.append(':\n')
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160126153212.53">
# Python 2.x only

def do_Exec(self, node):
    body = self.visit(node.body)
    args = [] # Globals before locals.
    if getattr(node, 'globals', None):
        args.append(self.visit(node.globals))
    if getattr(node, 'locals', None):
        args.append(self.visit(node.locals))
    if args:
        return self.indent('exec %s in %s\n' % (
            body, ','.join(args)))
    else:
        return self.indent('exec %s\n' % (body))
</t>
<t tx="ekr.20160126153212.54">
def do_For(self, node):
    result = []
    result.append(self.indent('for %s in %s:\n' % (
        self.visit(node.target),
        self.visit(node.iter))))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        result.append(self.indent('else:\n'))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160126153212.55">
def do_Global(self, node):
    return self.indent('global %s\n' % (
        ','.join(node.names)))
</t>
<t tx="ekr.20160126153212.56">
def do_If(self, node):
    result = []
    result.append(self.indent('if %s:\n' % (
        self.visit(node.test))))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        result.append(self.indent('else:\n'))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160126153212.57">
def do_Import(self, node):
    names = []
    for fn, asname in self.get_import_names(node):
        if asname:
            names.append('%s as %s' % (fn, asname))
        else:
            names.append(fn)
    return self.indent('import %s\n' % (
        ','.join(names)))
</t>
<t tx="ekr.20160126153212.58">
def get_import_names(self, node):
    '''Return a list of the the full file names in the import statement.'''
    result = []
    for ast2 in node.names:
        if self.kind(ast2) == 'alias':
            data = ast2.name, ast2.asname
            result.append(data)
        else:
            print('unsupported kind in Import.names list', self.kind(ast2))
    return result
</t>
<t tx="ekr.20160126153212.59">
def do_ImportFrom(self, node):
    names = []
    for fn, asname in self.get_import_names(node):
        if asname:
            names.append('%s as %s' % (fn, asname))
        else:
            names.append(fn)
    return self.indent('from %s import %s\n' % (
        node.module,
        ','.join(names)))
</t>
<t tx="ekr.20160126153212.6">
def visit(self, node):
    '''Return the formatted version of an Ast node, or list of Ast nodes.'''
    if isinstance(node, (list, tuple)):
        return ','.join([self.visit(z) for z in node])
    elif node is None:
        return 'None'
    else:
        assert isinstance(node, ast.AST), node.__class__.__name__
        method_name = 'do_' + node.__class__.__name__
        method = getattr(self, method_name)
        s = method(node)
        # pylint: disable=unidiomatic-typecheck
        assert type(s) == type('abc'), type(s)
        return s
</t>
<t tx="ekr.20160126153212.60">
def do_Pass(self, node):
    return self.indent('pass\n')
</t>
<t tx="ekr.20160126153212.61">
# Python 2.x only

def do_Print(self, node):
    vals = []
    for z in node.values:
        vals.append(self.visit(z))
    if getattr(node, 'dest', None):
        vals.append('dest=%s' % self.visit(node.dest))
    if getattr(node, 'nl', None):
        vals.append('nl=%s' % node.nl)
    return self.indent('print(%s)\n' % (
        ','.join(vals)))
</t>
<t tx="ekr.20160126153212.62">
def do_Raise(self, node):
    args = []
    for attr in ('type', 'inst', 'tback'):
        if getattr(node, attr, None) is not None:
            args.append(self.visit(getattr(node, attr)))
    if args:
        return self.indent('raise %s\n' % (
            ','.join(args)))
    else:
        return self.indent('raise\n')
</t>
<t tx="ekr.20160126153212.63">
def do_Return(self, node):
    if node.value:
        return self.indent('return %s\n' % (
            self.visit(node.value)))
    else:
        return self.indent('return\n')
</t>
<t tx="ekr.20160126153212.64">
def do_TryExcept(self, node):
    result = []
    result.append(self.indent('try:\n'))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.handlers:
        for z in node.handlers:
            result.append(self.visit(z))
    if node.orelse:
        result.append('else:\n')
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160126153212.65">
def do_TryFinally(self, node):
    result = []
    result.append(self.indent('try:\n'))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    result.append(self.indent('finally:\n'))
    for z in node.finalbody:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160126153212.66">
def do_While(self, node):
    result = []
    result.append(self.indent('while %s:\n' % (
        self.visit(node.test))))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        result.append('else:\n')
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160126153212.67">
def do_With(self, node):
    result = []
    result.append(self.indent('with '))
    if hasattr(node, 'context_expression'):
        result.append(self.visit(node.context_expresssion))
    vars_list = []
    if hasattr(node, 'optional_vars'):
        try:
            for z in node.optional_vars:
                vars_list.append(self.visit(z))
        except TypeError: # Not iterable.
            vars_list.append(self.visit(node.optional_vars))
    result.append(','.join(vars_list))
    result.append(':\n')
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    result.append('\n')
    return ''.join(result)
</t>
<t tx="ekr.20160126153212.68">
def do_Yield(self, node):
    if getattr(node, 'value', None):
        return self.indent('yield %s\n' % (
            self.visit(node.value)))
    else:
        return self.indent('yield\n')
</t>
<t tx="ekr.20160126153212.69">
# Utils...
</t>
<t tx="ekr.20160126153212.7">
# Contexts...
</t>
<t tx="ekr.20160126153212.70">
def kind(self, node):
    '''Return the name of node's class.'''
    return node.__class__.__name__
</t>
<t tx="ekr.20160126153212.71">
def indent(self, s):
    return '%s%s' % (' ' * 4 * self.level, s)
</t>
<t tx="ekr.20160126153212.72">
def op_name (self,node,strict=True):
    '''Return the print name of an operator node.'''
    d = {
        # Binary operators. 
        'Add':       '+',
        'BitAnd':    '&amp;',
        'BitOr':     '|',
        'BitXor':    '^',
        'Div':       '/',
        'FloorDiv':  '//',
        'LShift':    '&lt;&lt;',
        'Mod':       '%',
        'Mult':      '*',
        'Pow':       '**',
        'RShift':    '&gt;&gt;',
        'Sub':       '-',
        # Boolean operators.
        'And':   ' and ',
        'Or':    ' or ',
        # Comparison operators
        'Eq':    '==',
        'Gt':    '&gt;',
        'GtE':   '&gt;=',
        'In':    ' in ',
        'Is':    ' is ',
        'IsNot': ' is not ',
        'Lt':    '&lt;',
        'LtE':   '&lt;=',
        'NotEq': '!=',
        'NotIn': ' not in ',
        # Context operators.
        'AugLoad':  '&lt;AugLoad&gt;',
        'AugStore': '&lt;AugStore&gt;',
        'Del':      '&lt;Del&gt;',
        'Load':     '&lt;Load&gt;',
        'Param':    '&lt;Param&gt;',
        'Store':    '&lt;Store&gt;',
        # Unary operators.
        'Invert':   '~',
        'Not':      ' not ',
        'UAdd':     '+',
        'USub':     '-',
    }
    name = d.get(self.kind(node),'&lt;%s&gt;' % node.__class__.__name__)
    if strict: assert name,self.kind(node)
    return name
</t>
<t tx="ekr.20160126153212.73">

class StandAloneMakeStubFile:
    '''
    A class to make Python stub (.pyi) files in the ~/stubs directory for
    every file mentioned in the [Source Files] section of
    ~/stubs/make_stub_files.cfg.
    '''
    @others
</t>
<t tx="ekr.20160126153212.74">
def __init__ (self):
    '''Ctor for StandAloneMakeStubFile class.'''
    self.options = {}
    # Ivars set on the command line...
    self.config_fn = None
        # self.finalize('~/stubs/make_stub_files.cfg')
    self.enable_unit_tests = False
    self.files = [] # May also be set in the config file.
    # Ivars set in the config file...
    self.output_fn = None
    self.output_directory = self.finalize('.')
        # self.finalize('~/stubs')
    self.overwrite = False
    self.prefix_lines = []
    self.trace_matches = False
    self.trace_patterns = False
    self.trace_reduce = False
    self.trace_visitors = False
    self.update_flag = False
    self.verbose = False # Trace config arguments.
    self.warn = False
    # Pattern lists, set by config sections...
    self.section_names = (
        'Global', 'Def Name Patterns', 'General Patterns')
    self.def_patterns = [] # [Def Name Patterns]
    self.general_patterns = [] # [General Patterns]
    self.names_dict = {}
    self.op_name_dict = self.make_op_name_dict()
    self.patterns_dict = {}
</t>
<t tx="ekr.20160126153212.75">
def make_stub_file(self, fn):
    '''
    Make a stub file in ~/stubs for all source files mentioned in the
    [Source Files] section of ~/stubs/make_stub_files.cfg
    '''
    if not fn.endswith('.py'):
        print('not a python file', fn)
        return
    if not os.path.exists(fn):
        print('not found', fn)
        return
    base_fn = os.path.basename(fn)
    out_fn = os.path.join(self.output_directory, base_fn)
    out_fn = out_fn[:-3] + '.pyi'
    self.output_fn = os.path.normpath(out_fn)
    s = open(fn).read()
    node = ast.parse(s,filename=fn,mode='exec')
    StubTraverser(controller=self).run(node)
</t>
<t tx="ekr.20160126153212.76">
def run(self):
    '''
    Make stub files for all files.
    Do nothing if the output directory does not exist.
    '''
    if self.enable_unit_tests:
        self.run_all_unit_tests()
    if self.files:
        dir_ = self.output_directory
        if dir_:
            if os.path.exists(dir_):
                for fn in self.files:
                    self.make_stub_file(fn)
            else:
                print('output directory not found: %s' % dir_)
        else:
            print('no output directory')
    elif not self.enable_unit_tests:
        print('no input files')
</t>
<t tx="ekr.20160126153212.77">
def scan_command_line(self):
    '''Set ivars from command-line arguments.'''
    # This automatically implements the --help option.
    usage = "usage: make_stub_files.py [options] file1, file2, ..."
    parser = optparse.OptionParser(usage=usage)
    add = parser.add_option
    add('-c', '--config', dest='fn',
        help='full path to configuration file')
    add('-d', '--dir', dest='dir',
        help='full path to the output directory')
    add('-o', '--overwrite', action='store_true', default=False,
        help='overwrite existing stub (.pyi) files')
    add('-t', '--test', action='store_true', default=False,
        help='run unit tests on startup')
    add('--trace-matches', action='store_true', default=False,
        help='trace Pattern.matches')
    add('--trace-patterns', action='store_true', default=False,
        help='trace pattern creation')
    add('--trace-reduce', action='store_true', default=False,
        help='trace st.reduce_types')
    add('--trace-visitors', action='store_true', default=False,
        help='trace visitor methods')
    add('-u', '--update', action='store_true', default=False,
        help='update existing stub file')
    add('-v', '--verbose', action='store_true', default=False,
        help='verbose output in .pyi file')
    add('-w', '--warn', action='store_true', default=False,
        help='warn about unannotated args')
    # Parse the options
    options, args = parser.parse_args()
    # Handle the options...
    self.enable_unit_tests=options.test
    self.overwrite = options.overwrite
    self.trace_matches = options.trace_matches
    self.trace_patterns = options.trace_patterns
    self.trace_reduce = options.trace_reduce
    self.trace_visitors = options.trace_visitors
    self.update_flag = options.update
    self.verbose = options.verbose
    self.warn = options.warn
    if options.fn:
        self.config_fn = options.fn
    if options.dir:
        dir_ = options.dir
        dir_ = self.finalize(dir_)
        if os.path.exists(dir_):
            self.output_directory = dir_
        else:
            print('--dir: directory does not exist: %s' % dir_)
            print('exiting')
            sys.exit(1)
    # If any files remain, set self.files.
    if args:
        args = [self.finalize(z) for z in args]
        if args:
            self.files = args
</t>
<t tx="ekr.20160126153212.78">
def scan_options(self):
    '''Set all configuration-related ivars.'''
    trace = False
    if not self.config_fn:
        return
    self.parser = parser = self.create_parser()
    s = self.get_config_string()
    self.init_parser(s)
    if self.files:
        files_source = 'command-line'
        files = self.files
    elif parser.has_section('Global'):
        files_source = 'config file'
        files = parser.get('Global', 'files')
        files = [z.strip() for z in files.split('\n') if z.strip()]
    else:
        return
    files2 = []
    for z in files:
        files2.extend(glob.glob(self.finalize(z)))
    self.files = [z for z in files2 if z and os.path.exists(z)]
    if trace:
        print('Files (from %s)...\n' % files_source)
        for z in self.files:
            print(z)
        print('')
    if 'output_directory' in parser.options('Global'):
        s = parser.get('Global', 'output_directory')
        output_dir = self.finalize(s)
        if os.path.exists(output_dir):
            self.output_directory = output_dir
            if self.verbose:
                print('output directory: %s\n' % output_dir)
        else:
            print('output directory not found: %s\n' % output_dir)
            self.output_directory = None # inhibit run().
    if 'prefix_lines' in parser.options('Global'):
        prefix = parser.get('Global', 'prefix_lines')
        self.prefix_lines = prefix.split('\n')
            # The parser does not preserve leading whitespace.
        if trace:
            print('Prefix lines...\n')
            for z in self.prefix_lines:
                print(z)
            print('')
    self.def_patterns = self.scan_patterns('Def Name Patterns')
    self.general_patterns = self.scan_patterns('General Patterns')
    self.make_patterns_dict()
</t>
<t tx="ekr.20160126153212.79">
def scan_patterns(self, section_name):
    '''Parse the config section into a list of patterns, preserving order.'''
    trace = False or self.trace_patterns
    parser = self.parser
    aList = []
    if parser.has_section(section_name):
        seen = set()
        for key in parser.options(section_name):
            value = parser.get(section_name, key)
            # A kludge: strip leading \\ from patterns.
            if key.startswith(r'\\'):
                key = '[' + key[2:]
                if trace: g.trace('removing escapes', key)
            if key in seen:
                g.trace('duplicate key', key)
            else:
                seen.add(key)
                aList.append(Pattern(key, value))
        if trace:
            g.trace('%s...\n' % section_name)
            for z in aList:
                print(z)
            print('')
    # elif trace:
        # print('no section: %s' % section_name)
        # print(parser.sections())
        # print('')
    return aList
</t>
<t tx="ekr.20160126153212.8">
# ClassDef(identifier name, expr* bases, stmt* body, expr* decorator_list)

def do_ClassDef(self, node):
    result = []
    name = node.name # Only a plain string is valid.
    bases = [self.visit(z) for z in node.bases] if node.bases else []
    if bases:
        result.append(self.indent('class %s(%s):\n' % (name, ','.join(bases))))
    else:
        result.append(self.indent('class %s:\n' % name))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160126153212.80">

class StubFormatter (AstFormatter):
    '''
    Formats an ast.Node and its descendants,
    making pattern substitutions in Name and operator nodes.
    '''
    @others
</t>
<t tx="ekr.20160126153212.81">
# Return generic markers to allow better pattern matches.

def do_Bytes(self, node): # Python 3.x only.
    return 'bytes' # return str(node.s)

def do_Num(self, node):
    # make_patterns_dict treats 'number' as a special case.
    # return self.names_dict.get('number', 'number')
    return 'number' # return repr(node.n)

def do_Str(self, node):
    '''This represents a string constant.'''
    return 'str' # return repr(node.s)
</t>
<t tx="ekr.20160126153212.82">

class StubTraverser (ast.NodeVisitor):
    '''
    An ast.Node traverser class that outputs a stub for each class or def.
    Names of visitors must start with visit_. The order of traversal does
    not matter, because so few visitors do anything.
    '''
    @others
</t>
<t tx="ekr.20160126153212.83">
def __init__(self, controller):
    '''Ctor for StubTraverser class.'''
    self.controller = x = controller
        # A StandAloneMakeStubFile instance.
    # Internal state ivars...
    self.class_name_stack = []
    self.context_stack = []
    sf = StubFormatter(controller=controller,traverser=self)
    self.format = sf.format
    self.arg_format = AstArgFormatter().format
    self.level = 0
    self.output_file = None
    self.parent_stub = None
    self.raw_format = AstFormatter().format
    self.returns = []
    self.stubs_dict = {}
        # Keys are stub.full_name's.  Values are stubs.
    self.warn_list = []
    # Copies of controller ivars...
    self.output_fn = x.output_fn
    self.overwrite = x.overwrite
    self.prefix_lines = x.prefix_lines
    self.update_flag = x.update_flag
    self.trace_matches = x.trace_matches
    self.trace_patterns = x.trace_patterns
    self.trace_reduce = x.trace_reduce
    self.trace_visitors = x.trace_visitors
    self.verbose = x.verbose
    self.warn = x.warn
    # Copies of controller patterns...
    self.def_patterns = x.def_patterns
    self.names_dict = x.names_dict
    self.general_patterns = x.general_patterns
    self.patterns_dict = x.patterns_dict
    </t>
<t tx="ekr.20160126153212.84">
def indent(self, s):
    '''Return s, properly indented.'''
    # This version of indent *is* used.
    return '%s%s' % (' ' * 4 * self.level, s)

def out(self, s):
    '''Output the string to the console or the file.'''
    s = self.indent(s)
    if self.parent_stub:
        self.parent_stub.out_list.append(s)
    elif self.output_file:
        self.output_file.write(s+'\n')
    else:
        print(s)
</t>
<t tx="ekr.20160126153212.85">
def run(self, node):
    '''StubTraverser.run: write the stubs in node's tree to self.output_fn.'''
    fn = self.output_fn
    dir_ = os.path.dirname(fn)
    if os.path.exists(fn) and not self.overwrite:
        print('file exists: %s' % fn)
    elif not dir_ or os.path.exists(dir_):
        t1 = time.clock()
        # Delayed output allows sorting.
        self.parent_stub = Stub(kind='root', name='&lt;new-stubs&gt;')
        for z in self.prefix_lines or []:
            self.parent_stub.out_list.append(z)
        self.visit(node)
            # Creates parent_stub.out_list.
        if self.update_flag:
            self.parent_stub = self.update(fn, new_root=self.parent_stub)
        self.output_file = open(fn, 'w')
        self.output_time_stamp()
        self.output_stubs(self.parent_stub)
        self.output_file.close()
        self.output_file = None
        self.parent_stub = None
        t2 = time.clock()
        print('wrote: %s in %4.2f sec' % (fn, t2 - t1))
    else:
        print('output directory not not found: %s' % dir_)
</t>
<t tx="ekr.20160126153212.87">
# ClassDef(identifier name, expr* bases, stmt* body, expr* decorator_list)

def visit_ClassDef(self, node):
    
    # Create the stub in the old context.
    old_stub = self.parent_stub
    self.parent_stub = Stub('class', node.name,old_stub, self.context_stack)
    self.add_stub(self.stubs_dict, self.parent_stub)
    # Enter the new context.
    self.class_name_stack.append(node.name)
    self.context_stack.append(node.name)
    # Format...
    if not node.name.startswith('_'):
        if node.bases:
            s = '(%s)' % ', '.join([self.format(z) for z in node.bases])
        else:
            s = ''
        self.out('class %s%s:' % (node.name, s))
    # Visit...
    self.level += 1
    for z in node.body:
        self.visit(z)
    self.context_stack.pop()
    self.class_name_stack.pop()
    self.level -= 1
    self.parent_stub = old_stub
</t>
<t tx="ekr.20160126153212.88">
# FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list)

def visit_FunctionDef(self, node):

    # Create the stub in the old context.
    old_stub = self.parent_stub
    self.parent_stub = Stub('def', node.name, old_stub, self.context_stack)
    self.add_stub(self.stubs_dict, self.parent_stub)
    # Enter the new context.
    self.returns = []
    self.level += 1
    self.context_stack.append(node.name)
    for z in node.body:
        self.visit(z)
    self.context_stack.pop()
    self.level -= 1
    # Format *after* traversing
    self.out('def %s(%s) -&gt; %s' % (
        node.name,
        self.format_arguments(node.args),
        self.format_returns(node)))
    self.parent_stub = old_stub
</t>
<t tx="ekr.20160126153212.89">
# arguments = (expr* args, identifier? vararg, identifier? kwarg, expr* defaults)

def format_arguments(self, node):
    '''
    Format the arguments node.
    Similar to AstFormat.do_arguments, but it is not a visitor!
    '''
    assert isinstance(node,ast.arguments), node
    args = [self.raw_format(z) for z in node.args]
    defaults = [self.raw_format(z) for z in node.defaults]
    # Assign default values to the last args.
    result = []
    n_plain = len(args) - len(defaults)
    # pylint: disable=consider-using-enumerate
    for i in range(len(args)):
        s = self.munge_arg(args[i])
        if i &lt; n_plain:
            result.append(s)
        else:
            result.append('%s=%s' % (s, defaults[i - n_plain]))
    # Now add the vararg and kwarg args.
    name = getattr(node, 'vararg', None)
    if name: result.append('*' + name)
    name = getattr(node, 'kwarg', None)
    if name: result.append('**' + name)
    return ', '.join(result)
</t>
<t tx="ekr.20160126153212.9">
# FunctionDef(identifier name, arguments args, stmt* body, expr* decorator_list)

def do_FunctionDef(self, node):
    '''Format a FunctionDef node.'''
    result = []
    if node.decorator_list:
        for z in node.decorator_list:
            result.append('@%s\n' % self.visit(z))
    name = node.name # Only a plain string is valid.
    args = self.visit(node.args) if node.args else ''
    result.append(self.indent('def %s(%s):\n' % (name, args)))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    return ''.join(result)
</t>
<t tx="ekr.20160126153212.90">
def format_returns(self, node):
    '''
    Calculate the return type:
    - Return None if there are no return statements.
    - Patterns in [Def Name Patterns] override all other patterns.
    - Otherwise, return a list of return values.
    '''
    trace = False
    name = self.get_def_name(node)
    raw = [self.raw_format(z) for z in self.returns]
    r = [self.format(z) for z in self.returns]
        # Allow StubFormatter.do_Return to do the hack.
    # Step 1: Return None if there are no return statements.
    if trace and self.returns:
        g.trace('name: %s r:\n%s' % (name, r))
    if not [z for z in self.returns if z.value != None]:
        return 'None: ...'
    # Step 2: [Def Name Patterns] override all other patterns.
    for pattern in self.def_patterns:
        found, s = pattern.match(name)
        if found:
            if trace:
                g.trace('*name pattern %s: %s -&gt; %s' % (
                    pattern.find_s, name, s))
            return s + ': ...'
    # Step 3: remove recursive calls.
    raw, r = self.remove_recursive_calls(name, raw, r)
    # Step 4: Calculate return types.
    return self.format_return_expressions(name, raw, r)
</t>
<t tx="ekr.20160126153212.91">
def munge_arg(self, s):
    '''Add an annotation for s if possible.'''
    if s == 'self':
        return s
    for pattern in self.general_patterns:
        if pattern.match_entire_string(s):
            return '%s: %s' % (s, pattern.repl_s)
    if self.warn and s not in self.warn_list:
        self.warn_list.append(s)
        print('no annotation for %s' % s)
    return s + ': Any'
</t>
<t tx="ekr.20160126153212.99">
def visit_Return(self, node):

    self.returns.append(node)
        # New: return the entire node, not node.value.
</t>
<t tx="ekr.20160126153220.1">@language config

# A configuration file to make stubs for make_stub_files.py itself.

[Global]

files: make_stub_files.py
    
output_directory: .
    
prefix_lines:
    from typing import Any, Dict, Optional, Sequence, Tuple, Union
        # At present, I don't understand how to tell mypy about ast.Node
        # import ast
        # Node = ast.Node
    Node = Any

[Def Name Patterns]

# The returns are inherent in the design of make_stub_files.py:
AstFormatter.do_*: str
StubFormatter.do_*: str
StubTraverser.do_*: str

# Test of regex pattern.
.*__hash__$: int

# Pattern.all_matches: Sequence
# Pattern.full_balanced_match: Optional[int]
# Pattern.match_balanced: int
# Pattern.match_entire_string: bool
# StandAloneMakeStubFile.scan_types: Dict[str, str]

# StubTraverser.format_returns: str
# StubTraverser.match_return_patterns: Tuple[bool,str]
# StubTraverser.match_return_pattern: Optional[str]
# StubTraverser.match_balanced: int

[General Patterns]

# Declarations of names...
NotImplemented: bool
a: str
aList: List[Any]
comments: str
controller: StandAloneMakeStubFile
find_s: str
fn: str
found: str
general_patterns: List[Pattern]
group: str
i1: int
i2: int
i: int
j1: int
j2: int
j: int
n1: int
n2: int
n: int
name: str
ndots: int
node: Node
parser: optparse.OptionParser
patterns: List
repl_s: str
s: str
s1: str
s2: str
# s[1-2]?$: str
strict: bool
trace: bool
# New known functions
endswith(*): bool 

# Known functions...
os.path.basename(*): str
os.sep.join(*): str
sep.join(*): str
self.__eq__(*): bool
self.__ne__(*): bool
self.__gt__(*): bool
self.__lt__(*): bool
all(*): bool
any(*): bool

int(*): int
hash(*): int
len(*): int
repr(*): str
sorted(*): str
str%(*): str
str.join(*): str
str.join(*): str
r[*]: str
# Put this in the code.
str[*]: str
###.*\.__name__$: str
###.*\.hash()$: int
</t>
<t tx="ekr.20160126165907.1">
def finalize(self, fn):
    '''Finalize and regularize a filename.'''
    fn = os.path.expanduser(fn)
    fn = os.path.abspath(fn)
    fn = os.path.normpath(fn)
    return fn
</t>
<t tx="ekr.20160128041938.1">

class Pattern(object):
    '''
    A class representing regex or balanced patterns.
    
    Sample matching code, for either kind of pattern:
        
        for m in reversed(pattern.all_matches(s)):
            s = pattern.replace(m, s)
    '''
    @others
</t>
<t tx="ekr.20160128042705.1">
def all_matches(self, s):
    '''
    Return a list of match objects for all matches in s.
    These are regex match objects or (start, end) for balanced searches.
    '''
    trace = False
    if self.is_balanced():
        aList, i = [], 0
        while i &lt; len(s):
            progress = i
            j = self.full_balanced_match(s, i)
            if j is None:
                i += 1
            else:
                aList.append((i,j),)
                i = j
            assert progress &lt; i
        return aList
    else:
        return list(self.regex.finditer(s))
</t>
<t tx="ekr.20160128042857.1">
def is_balanced(self):
    '''Return True if self.find_s is a balanced pattern.'''
    s = self.find_s
    if s.endswith('*'):
        return True
    for pattern in ('(*)', '[*]', '{*}'):
        if s.find(pattern) &gt; -1:
            return True
    return False
</t>
<t tx="ekr.20160128045845.1">
def match_balanced(self, delim, s, i):
    '''
    delim == s[i] and delim is in '([{'
    Return the index of the end of the balanced parenthesized string, or len(s)+1.
    '''
    trace = False
    assert s[i] == delim, s[i]
    assert delim in '([{'
    delim2 = ')]}'['([{'.index(delim)]
    assert delim2 in ')]}'
    i1, level = i, 0
    while i &lt; len(s):
        progress = i
        ch = s[i]
        i += 1
        if ch == delim:
            level += 1
        elif ch == delim2:
            level -= 1
            if level == 0:
                if trace: g.trace('found: %s' % s[i1:i])
                return i
        assert progress &lt; i
    # Unmatched: a syntax error.
    print('***** unmatched %s in %s' % (delim, s))
    return len(s) + 1
</t>
<t tx="ekr.20160128051025.1">
def full_balanced_match(self, s, i):
    '''Return the index of the end of the match found at s[i:] or None.'''
    i1 = i
    trace = False
    if trace: g.trace(self.find_s, s[i:].rstrip())
    pattern = self.find_s
    j = 0 # index into pattern
    while i &lt; len(s) and j &lt; len(pattern) and pattern[j] in ('*', s[i]):
        progress = i
        if pattern[j:j+3] in ('(*)', '[*]', '{*}'):
            delim = pattern[j]
            i = self.match_balanced(delim, s, i)
            j += 3
        elif j == len(pattern)-1 and pattern[j] == '*':
            # A trailing * matches the rest of the string.
            j += 1
            i = len(s)
            break
        else:
            i += 1
            j += 1
        assert progress &lt; i
    found = i &lt;= len(s) and j == len(pattern)
    if trace and found:
        g.trace('%s -&gt; %s' % (pattern, s[i1:i]))
    return i if found else None
</t>
<t tx="ekr.20160128102557.1"># An example configuration file for make_stub_files.py.
# By default, make_stub_files.py uses ~/stubs/make_stub_files.cfg.
# Can be changed using the --config=path command-line option.

[Global]

files:
    
    # Files to be used *only* if no files are given on the command line.
    # glob.glob wildcards are supported.
    
output_directory: ~/stubs
    
prefix_lines:
    # Lines to be inserted at the start of each stub file.

    from typing import TypeVar
    T = TypeVar('T', int, float, complex)
    
# Notes about patterns used below:
#
#  **Balanced patterns** contain either (*), [*], or {*}.
#  Unlike regular expressions, balanced patterns match only balanced brackets.
#
#  Both regex and balanced patterns may appear in each section.
#  However, balanced patterns will never match argument names.
#
#  Patterns are matched in the order they appear in each section,
#  but the .* pattern (if present) will match last, regardless of its
#  position in the section.
    
[Def Name Patterns]

# These regex patterns give the return types of functions or methods.
#
# Patterns for methods should match class_name.method_name.
#
# Patterns in this section *override* all other patterns,
# so you should use these patterns only if:
#
# - No other pattern properly handles the function or method, or
#
# - The pattern specifies functions that should all return the same value.
#   For example, all ast tree traversers should have the same signatures.
#
# It may be unwise to use .* in this section, but the choice is yours.

[Argument Patterns]

# The regex patterns in this section apply only when assigning types
# to *arguments* to functions or methods. Patterns match argument names.
# Typically, most patterns can be put [General Patterns] section instead.

[General Patterns]

# The patterns in this section may be either regex or balanced patterns.
# Patterns in this section are applied both to arguments and return expressions.
# These patterns are applied *once* to argument names and *repeatedly* to
# return types until no further matches can be made.

aList[1-3]?: Sequence
i: int
j: int
k: int
node: ast.Ast
s[1-3]?: str

[Return Patterns]

# The patterns in this section may be either regex or balanced patterns.
# Patterns in this section are applied only to return expressions.
# These patterns are applied *repeatedly* to return expressions
# until no further matches can be made.

# Balanced patterns...

repr(*): str
str.join(*): str
str.replace(*): str
str%(*): str
str%str: str

# Regex patterns...

.*__name__: str
</t>
<t tx="ekr.20160128104639.1">@language config

# A configuration file to make stubs for make_stub_files.py itself.

[Global]

files: make_stub_files.py
    
output_directory: .
    
prefix_lines:
    from typing import Any, Dict, Optional, Sequence, Tuple, Union
        # At present, I don't understand how to tell mypy about ast.Node
        # import ast
        # Node = ast.Node
    Node = Any

[Def Name Patterns]

# The returns are inherent in the design of make_stub_files.py:
AstFormatter.do_*: str
StubFormatter.do_*: str
StubTraverser.do_*: str

# Test of regex pattern.
.*__hash__$: int

# Pattern.all_matches: Sequence
# Pattern.full_balanced_match: Optional[int]
# Pattern.match_balanced: int
# Pattern.match_entire_string: bool
# StandAloneMakeStubFile.scan_types: Dict[str, str]

# StubTraverser.format_returns: str
# StubTraverser.match_return_patterns: Tuple[bool,str]
# StubTraverser.match_return_pattern: Optional[str]
# StubTraverser.match_balanced: int

[General Patterns]

# Declarations of names...
NotImplemented: bool
a: str
aList: List[Any]
comments: str
controller: StandAloneMakeStubFile
find_s: str
fn: str
found: str
general_patterns: List[Pattern]
group: str
i1: int
i2: int
i: int
j1: int
j2: int
j: int
n1: int
n2: int
n: int
name: str
ndots: int
node: Node
parser: optparse.OptionParser
patterns: List
repl_s: str
s: str
s1: str
s2: str
# s[1-2]?$: str
strict: bool
trace: bool
# New known functions
endswith(*): bool 

# Known functions...
os.path.basename(*): str
os.sep.join(*): str
sep.join(*): str
self.__eq__(*): bool
self.__ne__(*): bool
self.__gt__(*): bool
self.__lt__(*): bool
all(*): bool
any(*): bool

int(*): int
hash(*): int
len(*): int
repr(*): str
sorted(*): str
str%(*): str
str.join(*): str
str.join(*): str
r[*]: str
# Put this in the code.
str[*]: str
###.*\.__name__$: str
###.*\.hash()$: int
</t>
<t tx="ekr.20160128104714.1"></t>
<t tx="ekr.20160128105006.1"></t>
<t tx="ekr.20160128113859.1">
def __init__ (self, find_s, repl_s=''):
    '''Ctor for the Pattern class.'''
    self.find_s = find_s
    self.repl_s = repl_s
    if self.is_regex():
        self.regex = re.compile(find_s)
    elif self.is_balanced():
        self.regex = None
    else:
        # Escape all dangerous characters.
        result = []
        for ch in find_s:
            if ch == '_' or ch.isalnum():
                result.append(ch)
            else:
                result.append('\\'+ch)
        self.regex = re.compile(''.join(result))
</t>
<t tx="ekr.20160128113914.1">
def __repr__(self):
    '''Pattern.__repr__'''
    return 'Pattern: %s ==&gt; %s' % (self.find_s, self.repl_s)
    
__str__ = __repr__
</t>
<t tx="ekr.20160128114726.1">
def match_entire_string(self, s):
    '''Return True if s matches self.find_s'''
    if self.is_balanced():
        j = self.full_balanced_match(s, 0)
        return j is not None
    else:
        m = self.regex.match(s)
        return m and m.group(0) == s
</t>
<t tx="ekr.20160128122410.1">
def get_def_name(self, node):
    '''Return the representaion of a function or method name.'''
    if self.class_name_stack:
        name = '%s.%s' % (self.class_name_stack[-1], node.name)
        # All ctors should return None
        if node.name == '__init__':
            name = 'None'
    else:
        name = node.name
    return name
</t>
<t tx="ekr.20160128154243.1">
def run_all_unit_tests(self):
    
    # pylint: disable=relative-import
    from test import test_msf
    import unittest
    loader = unittest.TestLoader()
    suite = loader.loadTestsFromTestCase(test_msf.TestMakeStubFiles)
    unittest.TextTestRunner(verbosity=0).run(suite)
</t>
<t tx="ekr.20160128154704.1"></t>
<t tx="ekr.20160128154715.1">import pdb
import unittest
import make_stub_files as msf

class TestMakeStubFiles(unittest.TestCase):
    '''Main test class.'''
    @others
    
if __name__ == '__main__':
    unittest.main()</t>
<t tx="ekr.20160128190112.1">
def test_pattern_class(self):
    table = (
        # regex tests. The pattern must end with $
        ('[str]', r'\[str\]$', 'xxx', 'xxx'), # Guido bug.
        ('s3', r's[1-3]?$', 'str', 'str'), # lengthening bug.
        ('s', 's', 'str', 'str'),
        ('abc', 'abc', 'ABC', 'ABC'),
        ('str(str)', 'str(*)', 'str', 'str'),
        ('[whatever]', '[*]', 'List[*]', 'List[whatever]'), # * on the RHS.
        ('(int,str)', '(*)', 'Tuple[*]', 'Tuple[int,str]'), # Guido bug 2.
        ('abcxyz', 'abc*', 'xxx', 'xxx'), # New test for trailing *.
        ('list(self.regex.finditer(str))','list(*)','List[*]',
         'List[self.regex.finditer(str)]'),
    )
    for s, find, repl, expected in table:
        # pdb.set_trace()
        pattern = msf.Pattern(find, repl)
        result = pattern.match_entire_string(s)
        assert result, (result, s, find, repl, expected)
        aList = pattern.all_matches(s)
        assert len(aList) == 1, aList
        found, s2 = pattern.match(s)
        assert found, 'after pattern.match(s)'
        assert s2 == expected, ('expected', expected, 'got', s2)
    p1 = msf.Pattern('abc','xyz')
    p2 = msf.Pattern('abc','xyz')
    p3 = msf.Pattern('abc','pdq')
    assert p1 == p2
    assert p1 != p3
    assert p2 != p3
    aSet = set()
    aSet.add(p1)
    assert p1 in aSet
    assert p2 in aSet
    assert p3 not in aSet
    assert list(aSet) == [p1] == [p2]
    aSet.add(p3)
</t>
<t tx="ekr.20160128190224.1">
def test_is_known_type(self):
    '''Test that is_known_type handles brackets reasonably.'''
    good = (
        'Any', 'Sequence',
        'Sequence[]',
        'Sequence[List]',
        'Sequence[List[Any]]',
        'Tuple[int,str]',
    )
    bad = (
        'Huh', 'Sequence(List)',
        'List+a',
        'List+List',
    )
    c = msf.StandAloneMakeStubFile()
    for s in good:
        assert msf.is_known_type(s), s
    for s in bad:
        assert not msf.is_known_type(s), s
</t>
<t tx="ekr.20160128190252.1">
# def setUp(self):
    # '''Called before each test.'''
</t>
<t tx="ekr.20160128225533.1">*.pyc
test/*.pyc</t>
<t tx="ekr.20160130032546.1">
def format_return_expressions(self, name, raw_returns, reduced_returns):
    '''
    aList is a list of maximally reduced return expressions.
    For each expression e in Alist:
    - If e is a single known type, add e to the result.
    - Otherwise, add Any # e to the result.
    Return the properly indented result.
    '''
    assert len(raw_returns) == len(reduced_returns)
    lws =  '\n' + ' '*4
    n = len(raw_returns)
    known = all([is_known_type(e) for e in reduced_returns])
    if not known or self.verbose:
        # First, generate the return lines.
        aList = []
        for i in range(n):
            e, raw = reduced_returns[i], raw_returns[i]
            known = ' ' if is_known_type(e) else '?'
            aList.append('# %s %s: %s' % (' ', i, raw))
            aList.append('# %s %s: return %s' % (known, i, e))
        results = ''.join([lws + self.indent(z) for z in aList])
        # Put the return lines in their proper places.
        if known:
            s = reduce_types(reduced_returns, name, self.trace_reduce)
                # newlines=True,        
            return s + ': ...' + results
        else:
            return 'Any: ...' + results
    else:
        s = reduce_types(reduced_returns, name, self.trace_reduce)
                # newlines=True,       
        return s + ': ...'
</t>
<t tx="ekr.20160130034812.1">
def is_known_type(s):
    '''
    Return True if s is nothing but a single known type.
    Recursively test inner types in square brackets.
    '''
    trace = False
    s1 = s
    s = s.strip()
    table = (
        # None,
        'None', 
        'complex', 'float', 'int', 'long', 'number',
        'dict', 'list', 'tuple',
        'bool', 'bytes', 'str', 'unicode',
    )
    for s2 in table:
        if s2 == s:
            return True
        elif Pattern(s2+'(*)', s).match_entire_string(s):
            return True
    if s.startswith('[') and s.endswith(']'):
        inner = s[1:-1]
        return is_known_type(inner) if inner else True
    elif s.startswith('(') and s.endswith(')'):
        inner = s[1:-1]
        return is_known_type(inner) if inner else True
    elif s.startswith('{') and s.endswith('}'):
        return True ### Not yet.
        # inner = s[1:-1]
        # return is_known_type(inner) if inner else True
    table = (
        # Pep 484: https://www.python.org/dev/peps/pep-0484/
        # typing module: https://docs.python.org/3/library/typing.html
        'AbstractSet', 'Any', 'AnyMeta', 'AnyStr',
        'BinaryIO', 'ByteString',
        'Callable', 'CallableMeta', 'Container',
        'Dict', 'Final', 'Generic', 'GenericMeta', 'Hashable',
        'IO', 'ItemsView', 'Iterable', 'Iterator',
        'KT', 'KeysView', 'List',
        'Mapping', 'MappingView', 'Match',
        'MutableMapping', 'MutableSequence', 'MutableSet',
        'NamedTuple', 'Optional', 'OptionalMeta',
        # 'POSIX', 'PY2', 'PY3',
        'Pattern', 'Reversible',
        'Sequence', 'Set', 'Sized',
        'SupportsAbs', 'SupportsFloat', 'SupportsInt', 'SupportsRound',
        'T', 'TextIO', 'Tuple', 'TupleMeta',
        'TypeVar', 'TypingMeta',
        'Undefined', 'Union', 'UnionMeta',
        'VT', 'ValuesView', 'VarBinding',
    )
    for s2 in table:
        if s2 == s:
            return True
        pattern = Pattern(s2+'[*]', s)
        if pattern.match_entire_string(s):
            # Look inside the square brackets.
            # if s.startswith('Dict[List'): g.pdb()
            brackets = s[len(s2):]
            assert brackets and brackets[0] == '[' and brackets[-1] == ']'
            s3 = brackets[1:-1]
            if s3:
                return all([is_known_type(z.strip())
                    for z in split_types(s3)])
            else:
                return True
    if trace: g.trace('Fail:', s1)
    return False
</t>
<t tx="ekr.20160131174909.1">@language rest
@wrap

* show is too kludgy. Probably should never split long return hints.

- --update should prepend a timestamp in the .pyi file.

*** What to do about non-comment lines between subs??
    I fear the user will be surprised.

- Warn if regex pattern used in general patterns?

- Create views for startup, operators, type reduction, --update.
</t>
<t tx="ekr.20160131175042.1">

class TestClass:
    '''
    A class containing constructs that have caused difficulties.
    This is in the make_stub_files directory, not the test directory.
    '''
    # pylint: disable=no-member
    # pylint: disable=undefined-variable
    # pylint: disable=no-self-argument
    # pylint: disable=no-method-argument
    @others</t>
<t tx="ekr.20160131175118.1">
def return_list(self, a):
    return [a]</t>
<t tx="ekr.20160131180118.1">

class LeoGlobals:
    '''A class supporting g.pdb and g.trace for compatibility with Leo.'''
    @others
</t>
<t tx="ekr.20160131180244.1">
def pdb(self):
    try:
        import leo.core.leoGlobals as leo_g
        leo_g.pdb()
    except ImportError:
        import pdb
        pdb.set_trace()
</t>
<t tx="ekr.20160131180306.1">
def trace(self, *args, **keys):
    try:
        import leo.core.leoGlobals as leo_g
        leo_g.trace(caller_level=2, *args, **keys)
    except ImportError:
        print(args, keys)
</t>
<t tx="ekr.20160131192406.1">
def return_all(self):
    return all([is_known_type(z) for z in s3.split(',')])
    # return all(['abc'])</t>
<t tx="ekr.20160131192735.1">
def return_array():
    return f(s[1:-1])</t>
<t tx="ekr.20160131204607.1">
def replace_balanced(self, s1, start, end):
    '''
    Use m (returned by all_matches) to replace s by the string implied by repr_s.
    Within repr_s, * star matches corresponding * in find_s
    '''
    trace = False
    s = s1[start:end]
    f, r = self.find_s, self.repl_s
    i1 = f.find('(*)')
    i2 = f.find('[*]')
    i3 = f.find('{*}')
    if -1 == i1 == i2 == i3:
        return s1[:start] + r + s1[end:]
    j = r.find('*')
    if j == -1:
        return s1[:start] + r + s1[end:]
    i = min([z for z in [i1, i2, i3] if z &gt; -1])
    assert i &gt; -1 # i is an index into f AND s
    delim = f[i]
    if trace: g.trace('head', s[:i], f[:i])
    assert s[:i] == f[:i], (s[:i], f[:i])
    if trace: g.trace('delim',delim)
    k = self.match_balanced(delim, s, i)
    s_star = s[i+1:k-1]
    if trace: g.trace('s_star',s_star)
    repl = r[:j] + s_star + r[j+1:]
    if trace: g.trace('repl',self.repl_s,'==&gt;',repl)
    return s1[:start] + repl + s1[end:]
</t>
<t tx="ekr.20160201125349.1">
def parse_group(group):
    if len(group) &gt;= 3 and group[-2] == 'as':
        del group[-2:]
    ndots = 0
    i = 0
    while len(group) &gt; i and group[i].startswith('.'):
        ndots += len(group[i])
        i += 1
    assert ''.join(group[:i]) == '.'*ndots, group
    del group[:i]
    assert all(g == '.' for g in group[1::2]), group
    return ndots, os.sep.join(group[::2])
</t>
<t tx="ekr.20160201194801.1">
def do_Return(self, node):
    '''
    StubFormatter ast.Return vsitor.
    Return only the return expression itself.
    '''
    s = AstFormatter.do_Return(self, node)
    assert s.startswith('return'), repr(s)
    return s[len('return'):].strip()
</t>
<t tx="ekr.20160202061118.1">
seen_patterns = []

def visit(self, node):
    '''
    Return the formatted version of an Ast node after
    applying all general patterns.
    '''
    # This is the heart of this script.
    trace = False
    s = AstFormatter.visit(self, node)
    if self.fast_match:
        # Match only the patterns associated with this node.
        name = node.__class__.__name__
        for pattern in self.patterns_dict.get(name, []):
            found, s = pattern.match(s)
            if trace and found and pattern not in self.seen_patterns:
                self.seen_patterns.append(pattern)
                g.trace('%10s %s' % (name, pattern))
        if trace:
            # This finds and reports all missed patterns.
            for pattern in self.general_patterns:
                found, s = pattern.match(s)
                if True and found and pattern not in self.seen_patterns:
                    self.seen_patterns.append(pattern)
                    g.trace('**** %5s %s' % (name, pattern))
    else: # Match all general patterns.
        for pattern in self.general_patterns:
            found, s = pattern.match(s)
    return s
</t>
<t tx="ekr.20160202061329.1">
def __init__(self, controller, traverser):
    '''Ctor for StubFormatter class.'''
    self.controller = x = controller
    self.traverser = traverser
        # 2016/02/07: to give the formatter access to the class_stack.
    self.def_patterns = x.def_patterns
    self.general_patterns = x.general_patterns
    self.names_dict = x.names_dict
    self.patterns_dict = x.patterns_dict
    self.trace_matches = x.trace_matches
    self.trace_patterns = x.trace_patterns
    self.trace_reduce = x.trace_reduce
    self.trace_visitors = x.trace_visitors
    self.verbose = x.verbose
</t>
<t tx="ekr.20160202064553.1">
def match(self, patterns, s):
    '''Return s with at most one pattern matched.'''
    assert False, g.callers()
    for pattern in patterns:
        found, s = pattern.match(s)
        if found:
            break
    return s
</t>
<t tx="ekr.20160202070025.1">
def match(self, s, trace=False):
    '''
    Perform the match on the entire string if possible.
    Return (found, new s)
    '''
    trace = False or trace
    if self.is_balanced():
        j = self.full_balanced_match(s, 0)
        if j is None:
            return False, s
        else:
            s1 = s
            start, end = 0, len(s)
            s = self.replace_balanced(s, start, end)
            if trace: g.trace('%50s' % (truncate(s1,50)), self)
            return True, s
    else:
        m = self.regex.match(s)
        if m and m.group(0) == s:
            s1 = s
            s = self.replace_regex(m, s)
            if trace: g.trace('%50s' % (truncate(s1,50)), self)
            return True, s
        else:
            return False, s
</t>
<t tx="ekr.20160202165117.1">

class AstArgFormatter (AstFormatter):
    '''
    Just like the AstFormatter class, except it prints the class
    names of constants instead of actual values.
    '''
    @others</t>
<t tx="ekr.20160202165143.1">
# Return generic markers to allow better pattern matches.

def do_BoolOp(self, node): # Python 2.x only.
    return 'bool'

def do_Bytes(self, node): # Python 3.x only.
    return 'bytes' # return str(node.s)

def do_Name(self, node):
    return 'bool' if node.id in ('True', 'False') else node.id

def do_Num(self, node):
    return 'number' # return repr(node.n)

def do_Str(self, node):
    '''This represents a string constant.'''
    return 'str' # return repr(node.s)
</t>
<t tx="ekr.20160202170529.1">
def cls(self):
    '''Clear the screen.'''
    if sys.platform.lower().startswith('win'):
        os.system('cls')
</t>
<t tx="ekr.20160203073604.1">

class Stub(object):
    '''
    A class representing all the generated stub for a class or def.
    stub.full_name should represent the complete context of a def.
    '''
    @others
</t>
<t tx="ekr.20160203074843.1">
def init_parser(self, s):
    '''Add double back-slashes to all patterns starting with '['.'''
    trace = False
    if not s: return
    aList = []
    for s in s.split('\n'):
        if self.is_section_name(s):
            aList.append(s)
        elif s.strip().startswith('['):
            aList.append(r'\\'+s[1:])
            if trace: g.trace('*** escaping:',s)
        else:
            aList.append(s)
    s = '\n'.join(aList)+'\n'
    if trace: g.trace(s)
    file_object = StringIO.StringIO(s)
    self.parser.readfp(file_object)</t>
<t tx="ekr.20160203075612.1">import ast
from collections import OrderedDict
    # Requires Python 2.7 or above. Without OrderedDict
    # the configparser will give random order for patterns.
try:
    import ConfigParser as configparser # Python 2
except ImportError:
    import configparser # Python 3
import glob
import optparse
import os
import re
import sys
import time
try:
    import io.StringIO as StringIO # Python 3
except ImportError:
    import StringIO
</t>
<t tx="ekr.20160203094439.1">
def is_section_name(self, s):
    
    def munge(s):
        return s.strip().lower().replace(' ','')
    
    s = s.strip()
    if s.startswith('[') and s.endswith(']'):
        s = munge(s[1:-1])
        for s2 in self.section_names:
            if s == munge(s2):
                return True
    return False
</t>
<t tx="ekr.20160203095618.1">
def callers(self, n=4, count=0, excludeCaller=True, files=False):
    '''Return a list containing the callers of the function that called g.callerList.

    If the excludeCaller keyword is True (the default), g.callers is not on the list.

    If the files keyword argument is True, filenames are included in the list.
    '''
    # sys._getframe throws ValueError in both cpython and jython if there are less than i entries.
    # The jython stack often has less than 8 entries,
    # so we must be careful to call g._callerName with smaller values of i first.
    result = []
    i = 3 if excludeCaller else 2
    while 1:
        s = self._callerName(i, files=files)
        # print(i,s)
        if s:
            result.append(s)
        if not s or len(result) &gt;= n: break
        i += 1
    result.reverse()
    if count &gt; 0: result = result[: count]
    sep = '\n' if files else ','
    return sep.join(result)
</t>
<t tx="ekr.20160203095618.2">
def _callerName(self, n=1, files=False):
    # print('_callerName: %s %s' % (n,files))
    try: # get the function name from the call stack.
        f1 = sys._getframe(n) # The stack frame, n levels up.
        code1 = f1.f_code # The code object
        name = code1.co_name
        if name == '__init__':
            name = '__init__(%s,line %s)' % (
                self.shortFileName(code1.co_filename), code1.co_firstlineno)
        if files:
            return '%s:%s' % (self.shortFileName(code1.co_filename), name)
        else:
            return name # The code name
    except ValueError:
        # print('g._callerName: ValueError',n)
        return '' # The stack is not deep enough.
    except Exception:
        # es_exception()
        return '' # "&lt;no caller name&gt;"
</t>
<t tx="ekr.20160203105356.1">
def create_parser(self):
    '''Create a RawConfigParser and return it.'''
    parser = configparser.RawConfigParser(dict_type=OrderedDict)
        # Requires Python 2.7
    parser.optionxform = str
    return parser
</t>
<t tx="ekr.20160203105721.1">
def get_config_string(self):
    
    fn = self.finalize(self.config_fn)
    if os.path.exists(fn):
        if self.verbose:
            print('\nconfiguration file: %s\n' % fn)
        f = open(fn, 'r')
        s = f.read()
        f.close()
        return s
    else:
        print('\nconfiguration file not found: %s' % fn)
        return ''
    </t>
<t tx="ekr.20160203130235.1">
def __eq__(self, obj):
    '''
    Stub.__eq__. Return whether two stubs refer to the same method.
    Do *not* test parent links. That would interfere with --update logic.
    '''
    if isinstance(obj, Stub):
        return self.full_name == obj.full_name and self.kind == obj.kind
    else:
        return NotImplemented

def __ne__(self, obj):
    """Stub.__ne__"""
    return not self.__eq__(obj)
</t>
<t tx="ekr.20160203130717.1">
def __eq__(self, obj):
    """Return True if two Patterns are equivalent."""
    if isinstance(obj, Pattern):
        return self.find_s == obj.find_s and self.repl_s == obj.repl_s
    else:
        return NotImplemented

def __ne__(self, obj):
    """Return True if two Patterns are not equivalent."""
    return not self.__eq__(obj)

def __hash__(self):
    '''Pattern.__hash__'''
    return len(self.find_s) + len(self.repl_s)</t>
<t tx="ekr.20160203134203.1">
# Ordering among Patterns is not important.

# def __gt__(self, obj):
    # '''Return True if self appears after other in outline order.'''
    # if isinstance(obj, Pattern):
        # return self.find_s &gt; self.obj_s:
    # else:
        # return NotImplemented

# def __lt__(self, other):
    # return not self.__eq__(other) and not self.__gt__(other)
    
# def __ge__(self, other):
    # return self.__eq__(other) or self.__gt__(other)

# def __le__(self, other):
    # return self.__eq__(other) or self.__lt__(other)
</t>
<t tx="ekr.20160203134611.1">
def __gt__(self, obj):
    '''Stub.__eq__. Return ordering among siblings..'''
    if isinstance(obj, Stub):
        return self.name &gt; obj.name
    else:
        return NotImplemented

def __lt__(self, other):
    return not self.__eq__(other) and not self.__gt__(other)
    
def __ge__(self, other):
    return self.__eq__(other) or self.__gt__(other)

def __le__(self, other):
    return self.__eq__(other) or self.__lt__(other)
</t>
<t tx="ekr.20160203140342.1">
def __hash__(self):
    '''Stub.__hash__. Equality depends *only* on full_name and kind.'''
    return len(self.kind) + sum([ord(z) for z in self.full_name])</t>
<t tx="ekr.20160203154154.1">
    name1 = self.parent.full_name() if self.parent else None
    name2 = obj.parent.full_name() if obj.parent else None
    if name1 == name2:
        return self.name &gt; obj.name
    elif name1 and name2:
        return name1 &gt; name2
    else:
        return bool(name1)</t>
<t tx="ekr.20160203183228.1">
def output_stubs(self, stub):
    '''Output this stub and all its descendants.'''
    for s in stub.out_list or []:
        # Indentation must be present when an item is added to stub.out_list.
        if self.output_file:
            self.output_file.write(s+'\n')
        else:
            print(s)
    # Recursively print all children.
    for child in stub.children:
        self.output_stubs(child)
</t>
<t tx="ekr.20160203183934.1">
def shortFileName(self,fileName, n=None):
    if n is None or n &lt; 1:
        return os.path.basename(fileName)
    else:
        return '/'.join(fileName.replace('\\', '/').split('/')[-n:])
</t>
<t tx="ekr.20160204113206.1">
def make_patterns_dict(self):
    '''Assign all patterns to the appropriate ast.Node.'''
    trace = False or self.trace_patterns
    for pattern in self.general_patterns:
        ops = self.find_pattern_ops(pattern)
        if ops:
            for op in ops:
                # Add the pattern to op's list.
                op_names = self.op_name_dict.get(op)
                for op_name in op_names:
                    aList = self.patterns_dict.get(op_name, [])
                    aList.append(pattern)
                    self.patterns_dict[op_name] = aList
        else:
            # Enter the name in self.names_dict.
            name = pattern.find_s
            # Special case for 'number'
            if name == 'number':
                aList = self.patterns_dict.get('Num', [])
                aList.append(pattern)
                self.patterns_dict['Num'] = aList
            elif name in self.names_dict:
                g.trace('duplicate pattern', pattern)
            else:
                self.names_dict [name] = pattern.repl_s
    if 0:
        g.trace('names_dict...')
        for z in sorted(self.names_dict):
            print('  %s: %s' % (z, self.names_dict.get(z)))
    if 0:
        g.trace('patterns_dict...')
        for z in sorted(self.patterns_dict):
            aList = self.patterns_dict.get(z)
            print(z)
            for pattern in sorted(aList):
                print('  '+repr(pattern))
    # Note: retain self.general_patterns for use in argument lists.
</t>
<t tx="ekr.20160204153904.1">
seen_names = []

def do_Name(self, node):
    '''StubFormatter ast.Name visitor.'''
    trace = False
    d = self.names_dict
    name = d.get(node.id, node.id)
    s = 'bool' if name in ('True', 'False') else name
    if trace and node.id not in self.seen_names:
        self.seen_names.append(node.id)
        if d.get(node.id):
            g.trace(node.id, '==&gt;', d.get(node.id))
        elif node.id == 'aList':
            g.trace('**not found**', node.id)
    return s
</t>
<t tx="ekr.20160204170443.1">
def find_pattern_ops(self, pattern):
    '''Return a list of operators in pattern.find_s.'''
    trace = False or self.trace_patterns
    if pattern.is_regex():
        return []
            # The special characters in the regex
            # do not correspond to Python operators!
    d = self.op_name_dict
    keys1, keys2, keys3, keys9 = [], [], [], []
    for op in d:
        aList = d.get(op)
        if op.replace(' ','').isalnum():
            # an alpha op, like 'not, 'not in', etc.
            keys9.append(op)
        elif len(op) == 3:
            keys3.append(op)
        elif len(op) == 2:
            keys2.append(op)
        elif len(op) == 1:
            keys1.append(op)
        else:
            g.trace('bad op', op)
    ops = []
    s = s1 = pattern.find_s
    for aList in (keys3, keys2, keys1):
        for op in aList:
            # Must match word here!
            if s.find(op) &gt; -1:
                s = s.replace(op, '')
                ops.append(op)
    # Handle the keys9 list very carefully.
    for op in keys9:
        target = ' %s ' % op
        if s.find(target) &gt; -1:
            ops.append(op)
            break # Only one match allowed.
            
    if trace and ops: g.trace(s1, ops)
    return ops
</t>
<t tx="ekr.20160204170921.1">
def make_op_name_dict(self):
    '''
    Make a dict whose keys are operators ('+', '+=', etc),
    and whose values are lists of values of ast.Node.__class__.__name__.
    '''
    d = {
        '.':   ['Attr',],
        '(*)': ['Call', 'Tuple',],
        '[*]': ['List', 'Subscript',],
        '{*}': ['???',],
        ### 'and': 'BoolOp',
        ### 'or':  'BoolOp',
    }
    for op in (
        '+', '-', '*', '/', '%', '**', '&lt;&lt;',
        '&gt;&gt;', '|', '^', '&amp;', '//',
    ):
        d[op] = ['BinOp',]
    for op in (
        '==', '!=', '&lt;', '&lt;=', '&gt;', '&gt;=',
        'is', 'is not', 'in', 'not in',
    ):
        d[op] = ['Compare',]
    return d
</t>
<t tx="ekr.20160204224242.1">
def update(self, fn, new_root, testing=True):
    '''
    Merge the new_root tree with the old_root tree in fn (a .pyi file).

    new_root is the root of the stub tree from the .py file.
    old_root (read below) is the root of stub tree from the .pyi file.
    
    Return old_root, or new_root if there are any errors.
    '''
    s = self.get_stub_file(fn)
    if not s or not s.strip():
        return new_root
    if '\t' in s:
        # Tabs in stub files make it impossible to parse them reliably.
        g.trace('Can not update stub files containing tabs.')
        return new_root
    # Read old_root from the .pyi file.
    old_d, old_root = self.parse_stub_file(s, root_name='&lt;old-stubs&gt;')
    if not old_root:
        return new_root
    print('***** updating stubs from %s *****' % fn)
    # self.trace_stubs(old_root, header='old_root')
    # self.trace_stubs(new_root, header='new_root')
    if testing:
        return new_root ###
    # Merge new stubs into the old tree.
    self.merge_stubs(new_stubs = self.stubs_dict.values(),
                     old_root= old_root)
    return old_root
</t>
<t tx="ekr.20160205053641.1">
# StubFormatter visitors for operators...
</t>
<t tx="ekr.20160205053641.2">
# BinOp(expr left, operator op, expr right)

def do_BinOp(self, node):
    '''StubFormatter.BinOp visitor.'''
    trace = False or self.trace_reduce
    numbers = ['number', 'complex', 'float', 'long', 'int',]
    op = self.op_name(node.op)
    lhs = self.visit(node.left)
    rhs = self.visit(node.right)
    if op.strip() in ('is', 'is not', 'in', 'not in'):
        s = 'bool'
    elif lhs == rhs:
        s = lhs
            # Perhaps not always right,
            # but it is correct for Tuple, List, Dict.
    elif lhs in numbers and rhs in numbers:
        s = reduce_types([lhs, rhs], trace=trace)
            # reduce_numbers would be wrong: it returns a list.
    elif lhs == 'str' and op in '%*':
        s = 'str'
    else:
        if trace and lhs == 'str':
            g.trace('***** unknown string op', lhs, op, rhs)
        # Fall back to the base-class behavior.
        s = '%s%s%s' % (
            self.visit(node.left),
            op,
            self.visit(node.right))
    s = self.match_all(node, s)
    self.trace_visitor(node, op, s)
    return s
</t>
<t tx="ekr.20160205053641.3">
# BoolOp(boolop op, expr* values)

def do_BoolOp(self, node): # Python 2.x only.
    '''StubFormatter.BoolOp visitor for 'and' and 'or'.'''
    trace = False or self.trace_reduce
    op = self.op_name(node.op)
    values = [self.visit(z).strip() for z in node.values]
    s = reduce_types(values, trace=trace)
    s = self.match_all(node, s)
    self.trace_visitor(node, op, s)
    return s
</t>
<t tx="ekr.20160205053641.4">
# Compare(expr left, cmpop* ops, expr* comparators)

def do_Compare(self, node):
    '''
    StubFormatter ast.Compare visitor for these ops:
    '==', '!=', '&lt;', '&lt;=', '&gt;', '&gt;=', 'is', 'is not', 'in', 'not in',
    '''
    s = 'bool' # Correct regardless of arguments.
    ops = ','.join([self.op_name(z) for z in node.ops])
    self.trace_visitor(node, ops, s)
    return s
</t>
<t tx="ekr.20160205053641.5">
# UnaryOp(unaryop op, expr operand)

def do_UnaryOp(self, node):
    '''StubFormatter.UnaryOp for unary +, -, ~ and 'not' operators.'''
    op = self.op_name(node.op)
    s = 'bool' if op.strip() is 'not' else self.visit(node.operand)
    s = self.match_all(node, s)
    self.trace_visitor(node, op, s)
    return s
</t>
<t tx="ekr.20160205053641.6">
# If(expr test, stmt* body, stmt* orelse)

def do_IfExp(self, node):
    '''StubFormatterIfExp (ternary operator).'''
    trace = False or self.trace_reduce
    aList = [
        self.match_all(node, self.visit(node.body)),
        self.match_all(node, self.visit(node.orelse)),
    ]
    s = reduce_types(aList, trace=trace)
    s = self.match_all(node, s)
    self.trace_visitor(node, 'if', s)
    return s
</t>
<t tx="ekr.20160205053705.1">
# StubFormatter visitors for operands...</t>
<t tx="ekr.20160205060709.1">
def get_stub_file(self, fn):
    '''Read the stub file into s.'''
    if os.path.exists(fn):
        try:
            s = open(fn, 'r').read()
        except Exception:
            print('--update: error reading %s' % fn)
            s = None
        return s
    else:
        print('--update: not found: %s' % fn)
        return None
</t>
<t tx="ekr.20160205060807.1">
def parse_stub_file(self, s, root_name):
    '''
    Parse s, the contents of a stub file, into a tree of Stubs.
    
    Parse by hand, so that --update can be run with Python 2.
    '''
    trace = False
    assert '\t' not in s
    d = {}
    root = Stub(kind='root', name=root_name)
    indent_stack = [-1] # To prevent the root from being popped.
    stub_stack = [root]
    lines = []
    pat = re.compile(r'^([ ]*)(def|class)\s+([a-zA-Z_]+)(.*)')
    for line in g.splitLines(s):
        m = pat.match(line)
        if m:
            indent, kind, name, rest = (
                len(m.group(1)), m.group(2), m.group(3), m.group(4))
            old_indent = indent_stack[-1]
            # Terminate any previous lines.
            old_stub = stub_stack[-1]
            old_stub.out_list = lines
            if trace:
                for s in lines:
                    g.trace('  '+s.rstrip())
            lines = []
            # Adjust the stacks.
            if indent == old_indent:
                stub_stack.pop()
            elif indent &gt; old_indent:
                indent_stack.append(indent)
            else: # indent &lt; old_indent
                # The indent_stack can't underflow because
                # indent &gt;= 0 and indent_stack[0] &lt; 0
                assert indent &gt;= 0
                while indent &lt;= indent_stack[-1]:
                    indent_stack.pop()
                    old_stub = stub_stack.pop()
                    assert old_stub != root
                indent_stack.append(indent)
            # Create and push the new stub *after* adjusting the stacks.
            assert stub_stack
            parent = stub_stack[-1]
            stack = [z.name for z in stub_stack[1:]]
            parent = stub_stack[-1]
            stub = Stub(kind, name, parent, stack)
            self.add_stub(d, stub)
            stub_stack.append(stub)
            if trace:
                g.trace('%s%5s %s %s' % (' '*indent, kind, name, rest))
        elif not line.startswith('#'):
            parent = stub_stack[-1]
            if parent != root:
                lines.append(line)
    # Terminate the last stub.
    old_stub = stub_stack[-1]
    old_stub.out_list = lines
    if trace:
        for s in lines:
            g.trace('  '+s.rstrip())
    return d, root
</t>
<t tx="ekr.20160205072101.1">
def reduce_types(aList, name=None, trace=False):
    '''
    Return a string containing the reduction of all types in aList.
    The --trace-reduce command-line option sets trace=True.
    If present, name is the function name or class_name.method_name.
    '''
    trace = False or trace
    aList1 = aList[:]
    &lt;&lt; define show &gt;&gt;
    while None in aList:
        aList.remove(None)
    if not aList:
        return show('None')
    r = sorted(set(aList))
    if not all([is_known_type(z) for z in r]):
        return show('Any', known=False)
    elif len(r) == 1:
        return show(r[0])
    if 'None' in r:
        kind = 'Optional'
        while 'None' in r:
            r.remove('None')
        return show('Optional[%s]' % r[0])
    r = reduce_numbers(r)
    if len(r) == 1:
        return show(r[0])
    else:
        return show('Union[%s]' % (', '.join(sorted(r))))
</t>
<t tx="ekr.20160205101134.1">
def reduce_numbers(aList):
    '''
    Return aList with all number types in aList replaced by the most
    general numeric type in aList.
    '''
    found = None
    numbers = ('number', 'complex', 'float', 'long', 'int')
    for kind in numbers:
        for z in aList:
            if z == kind:
                found = kind
                break
        if found:
            break
    if found:
        assert found in numbers, found
        aList = [z for z in aList if z not in numbers]
        aList.append(found)
    return aList
</t>
<t tx="ekr.20160205103604.4">
# Attribute(expr value, identifier attr, expr_context ctx)

attrs_seen = []

def do_Attribute(self, node):
    '''StubFormatter.do_Attribute.'''
    trace = False
    s = '%s.%s' % (
        self.visit(node.value),
        node.attr) # Don't visit node.attr: it is always a string.
    s2 = self.names_dict.get(s)
    if trace and s2 and s2 not in self.attrs_seen:
        self.attrs_seen.append(s2)
        g.trace(s, '==&gt;', s2)
    return s2 or s
</t>
<t tx="ekr.20160205103604.6">
# Call(expr func, expr* args, keyword* keywords, expr? starargs, expr? kwargs)

def do_Call(self, node):
    '''StubFormatter.Call visitor.'''
    func = self.visit(node.func)
    args = [self.visit(z) for z in node.args]
    for z in node.keywords:
        # Calls f.do_keyword.
        args.append(self.visit(z))
    if getattr(node, 'starargs', None):
        args.append('*%s' % (self.visit(node.starargs)))
    if getattr(node, 'kwargs', None):
        args.append('**%s' % (self.visit(node.kwargs)))
    args = [z for z in args if z] # Kludge: Defensive coding.
    # Explicit pattern:
    if func in ('dict', 'list', 'set', 'tuple',):
        s = '%s[%s]' % (func.capitalize(), ', '.join(args))
    else:
        s = '%s(%s)' % (func, ', '.join(args))
    s = self.match_all(node, s)
    self.trace_visitor(node, 'call', s)
    return s
</t>
<t tx="ekr.20160205103604.7">
# keyword = (identifier arg, expr value)

def do_keyword(self, node):
    # node.arg is a string.
    value = self.visit(node.value)
    # This is a keyword *arg*, not a Python keyword!
    return '%s=%s' % (node.arg, value)
</t>
<t tx="ekr.20160205103604.9">
def do_Dict(self, node):
    result = []
    keys = [self.visit(z) for z in node.keys]
    values = [self.visit(z) for z in node.values]
    if len(keys) == len(values):
        result.append('{')
        items = []
        for i in range(len(keys)):
            items.append('%s:%s' % (keys[i], values[i]))
        result.append(', '.join(items))
        result.append('}')
    else:
        print('Error: f.Dict: len(keys) != len(values)\nkeys: %s\nvals: %s' % (
            repr(keys), repr(values)))
    # return ''.join(result)
    return 'Dict[%s]' % ''.join(result)
</t>
<t tx="ekr.20160205131910.1">
matched_d = {}

def match_all(self, node, s):
    '''Match all the patterns for the given node.'''
    trace = False or self.trace_matches
    d = self.matched_d
    name = node.__class__.__name__
    for pattern in self.patterns_dict.get(name, []):
        s1 = s
        found, s = pattern.match(s,trace=trace)
        if found:
            if trace:
                aList = d.get(name, [])
                if pattern not in aList:
                    aList.append(pattern)
                    d [name] = aList
                    g.trace('%46s %s' % (name, pattern))
            break
    return s</t>
<t tx="ekr.20160205133120.1"></t>
<t tx="ekr.20160205142626.1">
# Subscript(expr value, slice slice, expr_context ctx)

def do_Subscript(self, node):
    '''StubFormatter.Subscript.'''
    s = '%s[%s]' % (
        self.visit(node.value),
        self.visit(node.slice))
    s = self.match_all(node, s)
    self.trace_visitor(node, '[]', s)
    return s
</t>
<t tx="ekr.20160205143923.1">
def do_Tuple(self, node):
    elts = [self.visit(z) for z in node.elts]
    return '(%s)' % ', '.join(elts)
</t>
<t tx="ekr.20160205161341.1">
def return_two_lists(s):
    if 1:
        return aList
    else:
        return list(self.regex.finditer(s))
</t>
<t tx="ekr.20160206095102.1">&lt;&lt; docstring &gt;&gt;
# **Note**: this is a Leo script.
# It **does** have access to c, g and p.
import os
@others
test_dir = os.path.dirname(c.fileName())+os.sep+'test'
assert os.path.exists(test_dir), test_dir
assert os.path.isdir(test_dir), test_dir

if 1:
    # Writes each test to a separate file in the test directory.
    TestWriter(c,path=test_dir).run(fn=None)    
if 0:
    # Writes all tests to a single file: test/unit_tests.py
    TestWriter(c,path=test_dir).run(fn='unit_tests.py')
</t>
<t tx="ekr.20160206095102.2">@
@language rest
'''
This script transliterates @test nodes into .py file. The two main ways of
using this script are as follows::

    TestWriter(c,path='test').run(fn='unit_tests.py') # writes one file
    TestWriter(c,path='test').run(fn=None)            # writes separate files.
     
The first writes all tests to test/unit_tests.py; the second writes each
unit test to a separate .py file in the test directory.

The script imports each written file and reports any syntax errors.

This is a straightforward script; it should be easy to modify it to suit
individual needs.

The &lt;\&lt; file_template &gt;&gt; and &lt;\&lt; test_template &gt;&gt; sections in the TestWriter
class determines exactly what this script writes.
'''
</t>
<t tx="ekr.20160206101140.1">
def splitLines(self, s):
    '''Split s into lines, preserving trailing newlines.'''
    return s.splitlines(True) if s else []
</t>
<t tx="ekr.20160206101802.10">
def test(self,fn):
    '''Test the newly created file.'''
    import imp
    import sys

    if self.path not in sys.path:
        sys.path.append(self.path)
    assert fn.endswith('.py')
    name = fn[:-3]
    try:
        f,path,desc = imp.find_module(name,[self.path])
        imp.load_module(name,f,path,desc)
        # print('imported %s' % (name))
    except Exception:
        print('can not import: %s' % (name))
        g.es_print_exception()
</t>
<t tx="ekr.20160206101802.11">
def write_file(self,fn):

    assert g.os_path_exists(self.path),self.path
    fn = g.os_path_finalize_join(self.path,fn)
    f = open(fn,'w')
    f.write(self.file_template)
    for p in self.nodes:
        f.write(self.test_template % (self.clean(p.h),self.get_body(p)))
    f.close()
</t>
<t tx="ekr.20160206101802.3">

class TestWriter:
    
    &lt;&lt; define file_template &gt;&gt;
    &lt;&lt; define test_template &gt;&gt;

    @others
</t>
<t tx="ekr.20160206101802.4"># Add any other common imports here.

file_template = '''\
import unittest
'''

file_template = g.adjustTripleString(file_template,c.tab_width)
</t>
<t tx="ekr.20160206101802.5">test_template = '''
class %s (unittest.TestCase):
    def runTest(self):
%s
'''

test_template = g.adjustTripleString(test_template,c.tab_width)
</t>
<t tx="ekr.20160206101802.6">
def __init__(self,c,path=''):
    '''TestWriter ctor.'''
    self.c = c
    load_dir = g.os_path_dirname(c.fileName())
    self.path = g.os_path_finalize_join(load_dir,path)
    self.nodes = []
    assert g.os_path_exists(self.path),self.path
</t>
<t tx="ekr.20160206101802.7">
def clean(self,s):
    '''Munge s so that it can be used as a file name.'''
    result,tag = [],'@test'
    if s.startswith(tag):
        s = s[len(tag):]
    for ch in s.strip():
        if ch.isalnum():
            result.append(ch)
        elif ch.isspace():
            result.append('_')
    s = ''.join(result)
    if s.endswith('.py'):
        s = s[:-3]
    return s.strip()
</t>
<t tx="ekr.20160206101802.8">
def get_body(self,p):
    '''Convert p.b to a valid script.'''
    s = g.getScript(c,p,
                    useSelectedText=False,
                    forcePythonSentinels=True,
                    useSentinels=False)
    s = ''.join([' '*8+z for z in g.splitLines(s) if z.strip()])
        # Add leading indentation needed by test_template.
    return s.rstrip()
</t>
<t tx="ekr.20160206101802.9">
def run(self,fn=None):
    
    n, p = 0, c.rootPosition()
    while p:
        if p.h.startswith('@ignore '):
            p.moveToNodeAfterTree()
        elif p.h.startswith('@test '):
            self.nodes.append(p.copy())
            if not fn:
                fn2 = self.clean(p.h)+'.py'
                self.write_file(fn2)
                self.test(fn2)
                self.nodes=[]
            n += 1
            p.moveToThreadNext()
        else:
            p.moveToThreadNext()
    if n == 0:
        print('no @file or @suite nodes found.')
    else:
        if fn:
            self.write_file(fn)
            self.test(fn)
        dest = g.os_path_join(self.path, fn) if fn else self.path
        print('wrote %s test%s to %s' % (n,self.plural(n), dest))
</t>
<t tx="ekr.20160206103417.1">
def plural(self, n):
    return 's' if n &gt; 1 else ''
</t>
<t tx="ekr.20160206104033.1"># pylint: disable=relative-import
g.cls()
import test_msf
import unittest
loader = unittest.TestLoader()
suite = loader.loadTestsFromTestCase(test_msf.TestMakeStubFiles)
unittest.TextTestRunner(verbosity=0).run(suite)
</t>
<t tx="ekr.20160206104634.1">
# Top-level functions</t>
<t tx="ekr.20160206110004.1">@others
import re
    
table = (
    # s,  Pattern.find_s, Pattern.repl_s, expected
    # Passed...
    ('aabbcc', '(a+)(b+)(c+)$', r'\3\2\1', 'ccbbaa'),
    ('[str]', r'\[str\]$', 'xxx', 'xxx'), # Guido bug.
    ('s3', r's[1-3]?\b$', 'str', 'str'), # lengthening bug.
    ('s', 's', 'str', 'str'),
    ('abc', 'abc', 'ABC', 'ABC'),
    ('str(str)', 'str(*)', 'str', 'str'),
    ('[whatever]', '[*]', 'List[*]', 'List[whatever]'), # * on the RHS.
    ('(int,str)', '(*)', 'Tuple[*]', 'Tuple[int,str]'), # Guido bug 2.
    ('abcxyz', 'abc*', 'xxx', 'xxx'), # New test for trailing *.
    ('list(self.regex.finditer(str))','list(*)','List[*]',
     'List[self.regex.finditer(str)]'),
)
for s, find, repl, expected in table:
    pattern = Pattern(find, repl)
    result = pattern.match_entire_string(s)
    assert result, (result, s, find, repl, expected)
    aList = pattern.all_matches(s)
    assert len(aList) == 1, aList
    found, s2 = pattern.match(s)
    assert found, 'after pattern.match(s)'
    assert s2 == expected, (s, pattern, 'expected', expected, 'got', s2)
p1 = Pattern('abc','xyz')
p2 = Pattern('abc','xyz')
p3 = Pattern('abc','pdq')
assert p1 == p2
assert p1 != p3
assert p2 != p3
aSet = set()
aSet.add(p1)
assert p1 in aSet
assert p2 in aSet
assert p3 not in aSet
assert list(aSet) == [p1] == [p2]
aSet.add(p3)
</t>
<t tx="ekr.20160206120522.1">
def pdb(self):
    '''Invoke a debugger during unit testing.'''
    try:
        import leo.core.leoGlobals as leo_g
        leo_g.pdb()
    except ImportError:
        import pdb
        pdb.set_trace()
</t>
<t tx="ekr.20160206165507.1">@language config

# A configuration file to make stubs for make_stub_files.py itself.

[Global]

files: test/test.py
output_directory: ./test
# prefix_lines:

[Def Name Patterns]

[General Patterns]

# Declarations of names..
a: Any
s: str
aList: List[Any]
</t>
<t tx="ekr.20160206165656.1">'''A test file containing code that caused mypy errors.'''

def is_known_type(s):
    '''
    Return True if s is nothing but a single known type.
    Recursively test inner types in square brackets.
    '''
    trace = False
    s1 = s
    s = s.strip()
    table = (
        # None,
        'None', 
        'complex', 'float', 'int', 'long', 'number',
        'dict', 'list', 'tuple',
        'bool', 'bytes', 'str', 'unicode',
    )
    for s2 in table:
        if s2 == s:
            return True
        elif Pattern(s2+'(*)', s).match_entire_string(s):
            return True
    if s.startswith('[') and s.endswith(']'):
        inner = s[1:-1]
        return is_known_type(inner) if inner else True
    elif s.startswith('(') and s.endswith(')'):
        inner = s[1:-1]
        return is_known_type(inner) if inner else True
    elif s.startswith('{') and s.endswith('}'):
        return True ### Not yet.
        # inner = s[1:-1]
        # return is_known_type(inner) if inner else True
    table = (
        # Pep 484: https://www.python.org/dev/peps/pep-0484/
        # typing module: https://docs.python.org/3/library/typing.html
        'AbstractSet', 'Any', 'AnyMeta', 'AnyStr',
        'BinaryIO', 'ByteString',
        'Callable', 'CallableMeta', 'Container',
        'Dict', 'Final', 'Generic', 'GenericMeta', 'Hashable',
        'IO', 'ItemsView', 'Iterable', 'Iterator',
        'KT', 'KeysView', 'List',
        'Mapping', 'MappingView', 'Match',
        'MutableMapping', 'MutableSequence', 'MutableSet',
        'NamedTuple', 'Optional', 'OptionalMeta',
        # 'POSIX', 'PY2', 'PY3',
        'Pattern', 'Reversible',
        'Sequence', 'Set', 'Sized',
        'SupportsAbs', 'SupportsFloat', 'SupportsInt', 'SupportsRound',
        'T', 'TextIO', 'Tuple', 'TupleMeta',
        'TypeVar', 'TypingMeta',
        'Undefined', 'Union', 'UnionMeta',
        'VT', 'ValuesView', 'VarBinding',
    )
    for s2 in table:
        if s2 == s:
            return True
        pattern = Pattern(s2+'[*]', s)
        if pattern.match_entire_string(s):
            # Look inside the square brackets.
            # if s.startswith('Dict[List'): g.pdb()
            brackets = s[len(s2):]
            assert brackets and brackets[0] == '[' and brackets[-1] == ']'
            s3 = brackets[1:-1]
            if s3:
                return all([is_known_type(z.strip())
                    for z in split_types(s3)])
            else:
                return True
    if trace: g.trace('Fail:', s1)
    return False


def return_every_kind(a, b):
    # pylint: disable=unreachable
    return 1
    return 1.0
    return float(1.0)
    return complex(2.0,3.0)
    return long(1)
    return ('a','b')
    return [1, 2]
    return {}
    return {'x': 'y',}
    return dict(['p', 'q'])
    return list(1,2)
    return int(0.5)
    return tuple('a1', 'b1')
    return True and False
    return True or False
    return 1 and 0
    return 1 or -1
    return not True
    return not 1
    return 1 if False else 2
    
def match_entire_string(self, s):
    '''Return True if s matches self.find_s'''
    if self.is_balanced():
        j = self.full_balanced_match(s, 0)
        return j is not None
    else:
        m = self.regex.match(s)
        return m and m.group(0) == s

def splitLines(self, s):
    '''Split s into lines, preserving trailing newlines.'''
    return s.splitlines(True) if s else []
    
def sum(n):
    '''An common recursive pattern.'''
    if n == 1:
        return 1
    else:
        return 1 + sum(n-1)
</t>
<t tx="ekr.20160206170515.1">a, c, f, i, l, n = ('Any', 'complex', 'float', 'int', 'long', 'number')
table = (
    ([i,i],     [i]),
    ([i],       [i]),
    ([f, i],    [f]),
    ([c, i],    [c]),
    ([l, a],    [a, l]),
)
@others
for aList, expected in table:
    got = reduce_numbers(aList)
    assert expected == got,  (aList, 'expected:', expected, 'got', got)
</t>
<t tx="ekr.20160206171945.1"></t>
<t tx="ekr.20160206173343.1">a, c, f, i, l, n = ('Any', 'complex', 'float', 'int', 'long', 'number')
none = 'None'
table = (
    ([i,i],     i),
    ([i],       i),
    ([f, i],    f),
    ([c, i],    c),
    ([l, a],    'Union[Any, long]'),
    # Handle None
    ([None],        none),
    ([None, None],  none),
    ([None, a, c],  'Union[Any, complex]'),
)
@others
for aList, expected in table:
    got = reduce_types(aList)
    assert expected == got, (aList, 'expected:', expected, 'got', got)
</t>
<t tx="ekr.20160206174054.1">
def is_regex(self):
    '''
    Return True if self.find_s is a regular pattern.
    For now a kludgy convention suffices.
    '''
    return self.find_s.endswith('$')
        # A dollar sign is not valid in any Python expression.
</t>
<t tx="ekr.20160206174547.1">
def replace_regex(self, m, s):
    '''Do the replacement in s specified by m.'''
    s = self.repl_s
    for i in range(9):
        group = '\\%s' % i
        if s.find(group) &gt; -1:
            # g.trace(i, m.group(i))
            s = s.replace(group, m.group(i))
    return s</t>
<t tx="ekr.20160206174740.1">
def replace(self, m, s):
    '''Perform any kind of replacement.'''
    if self.is_balanced():
        start, end = m
        return self.replace_balanced(s, start, end)
    else:
        return self.replace_regex(m, s)
</t>
<t tx="ekr.20160206203133.1">
def visit(self, node):
    '''StubFormatter.visit: supports --verbose tracing.'''
    s = AstFormatter.visit(self, node)
    # if self.verbose:
        # g.trace('%12s %s' % (node.__class__.__name__,s))
    return s</t>
<t tx="ekr.20160206204452.1">
def do_List(self, node):
    '''StubFormatter.List.'''
    elts = [self.visit(z) for z in node.elts]
    elst = [z for z in elts if z] # Defensive.
    # g.trace('=====',elts)
    return 'List[%s]' % ', '.join(elts)
</t>
<t tx="ekr.20160206212123.1">
def split_types(s):
    '''Split types on *outer level* commas.'''
    aList, i1, level = [], 0, 0
    for i, ch in enumerate(s):
        if ch == '[':
            level += 1
        elif ch == ']':
            level -= 1
        elif ch == ',' and level == 0:
            aList.append(s[i1:i])
            i1 = i+1
    aList.append(s[i1:].strip())
    return aList</t>
<t tx="ekr.20160207051316.1">
def merge_types(a1, a2):
    '''
    a1 and a2 may be strings or lists.
    return a list containing both of them, flattened, without duplicates.
    '''
    # Not used at present, and perhaps never.
    # Only useful if visitors could return either lists or strings.
    assert a1 is not None
    assert a2 is not None
    r1 = a1 if isinstance(a1, (list, tuple)) else [a1]
    r2 = a2 if isinstance(a2, (list, tuple)) else [a2]
    return sorted(set(r1 + r2))
</t>
<t tx="ekr.20160207051429.1">a, c, f, i, l, n = ('Any', 'complex', 'float', 'int', 'long', 'number')
none = 'None'
La, Lc = ['Any'], ['complex']
Lac, Lai, Lan = ['Any', 'complex'], ['Any', 'int'], ['Any', 'None']
Laci = ['Any', 'complex', 'int']
Lnone = ['None']
table = (
    (none, Lnone,   Lnone),
    (none, none,    Lnone),
    (a, none,       Lan),
    (a, a,          La),
    (La, a,         La),
    (Lac, a,        Lac),
    (Lac, i,        Laci),
    (Lac, Lai,      Laci),
)
@others
for a1, a2, expected in table:
    got = merge_types(a1, a2)
    assert expected == got, (a1, a2, 'expected:', expected, 'got', got)
</t>
<t tx="ekr.20160207105647.1"></t>
<t tx="ekr.20160207105710.1">for p1 in c.all_unique_positions():
    if p1.h.startswith('@clean'):
        for p in p1.subtree():
            if (not p.h.strip().startswith('&lt;&lt;') and
                p.b.strip() and not p.b.startswith('\n')
            ):
                print(repr(p.b[:3]), p.h)
print('done')
</t>
<t tx="ekr.20160207115604.1">
def truncate(s, n):
    '''Return s truncated to n characers.'''
    return s if len(s) &lt;= n else s[:n-3] + '...'
</t>
<t tx="ekr.20160207115947.1">table = (
    ('abc',     'abc'),
    ('abcd',    'abcd'),
    ('abcde',   'abcde'),
    ('abcdef',  'ab...'),
    ('abcdefg', 'ab...'),
)
@others  
for s1, s2 in table:
    got = truncate(s1, 5)
    assert s2 == got, (s1, 'expected', s2, 'got', got)</t>
<t tx="ekr.20160207133035.1">
def show(s, known=True):
    '''Show the result of the reduction.'''
    s = s.strip()
    if trace:
        r = sorted(set([z.replace('\n',' ') for z in aList1]))
        if len(''.join(r)) &gt;= 35:
            r = truncate(repr(r), 35)
        if len(s) &gt;= 25:
            s = truncate(s, 25)
        if len(r) &gt; 1:
            caller = g.callers(2).split(',')[0]
            sep = ' ' if known else '?'
            g.trace('%20s %25s %s &lt;== %-35s %s' % (name or '', s, sep, r, caller))
    return s
</t>
<t tx="ekr.20160207162818.1">table = (
    ('list',                    ['list']),
    ('List[a,b]',               ['List[a,b]']),
    ('List[a,b], List[c,d]',    ['List[a,b]', 'List[c,d]']),
)
@others
for s, expected in table:
    got = split_types(s)
    assert expected == got, (s, 'expected', expected, 'got', got)
</t>
<t tx="ekr.20160207165031.1"># In reduce_types
# Tuple[unknown] should be Tuple[Any] *not* Any.</t>
<t tx="ekr.20160207165240.1"># Finish the work in do_Call at least.
# This simply requires the computation of class_name.method_name.</t>
<t tx="ekr.20160207181637.1"></t>
<t tx="ekr.20160207181648.1"></t>
<t tx="ekr.20160207181710.1">pylint
clone-find-all-flattened
clone-to-at-spot
beautify-tree
sort-lines
</t>
<t tx="ekr.20160207181843.1">@language python

c.cloneFindAllFlattenedAtNode('@clean make_stub_files.py',top_level=True)
</t>
<t tx="ekr.20160207182535.1"></t>
<t tx="ekr.20160207190840.1">
def remove_recursive_calls(self, name, raw, reduced):
    '''Remove any recursive calls to name from both lists.'''
    # At present, this works *only* if the return is nothing but the recursive call.
    assert len(raw) == len(reduced)
    pattern = Pattern('%s(*)' % name)
    n = len(reduced)
    raw_result, reduced_result = [], []
    for i in range(n):
        if pattern.match_entire_string(reduced[i]):
            g.trace('****', name, pattern, reduced[i])
        else:
            raw_result.append(raw[i])
            reduced_result.append(reduced[i])
    return raw_result, reduced_result</t>
<t tx="ekr.20160208060210.1">@language rest
@wrap

The **startup code** parses the config files and creates two main dicts: the patterns_dict and the names_dict. The theory of operation will discuss the startup code in more detail.

Here, I'll focus only on the code that reduces a return expression to a valid pep 484 type hint. (The typing module is also useful). Having a clear **target language** has been a great help.


So the visitors for BoolOp and IfExp *must* return strings. And here type hints come to the rescue. In the above examples, visitors should return (the string):

    'Union[hint(a), hint(b)]'
    
if both a and b have known types. *Note* hint(a) and hint(b) merely represent the actual hints. If a and b have the same, known type, the visitor should return:

    'hint(a)' # same as hint(b)
    
If either a or b has an unknown type, the script could return either

    'Any'
    
or one of the following:

    'Union[a, hint(b)]'
    'Union[hint(b), a]'
    'Union[a, b]'
    
In other words, we could allow expressions with unknown types to be part of the Union. In fact, iirc, unions containing unknowns become Any.

**Discuss all traverser classes**

The StubTraverser and StubFormatter classes are both tree traversers. The StubTraverser class ignores all nodes except ClassDef and FunctionDef nodes. The StubFormatter class visits Return nodes and all possible descendants, which is essentially all kinds of expression nodes.


**Producing type hints**

- Discuss do_BinOp, etc.

- Dicuss reduce_types and split_types.
</t>
<t tx="ekr.20160208093906.1">
def trace_visitor(self, node, op, s):
    '''Trace node's visitor.'''
    if self.trace_visitors:
        caller = g.callers(2).split(',')[1]
        s1 = AstFormatter().format(node).strip()
        print('%12s %6s: %s ==&gt; %s' % (caller, op.strip(), s1, s))
</t>
<t tx="ekr.20160208161113.1"></t>
<t tx="ekr.20160208162138.1">
    # First, look at the [Def Name Patterns]
    if 0: # This never seems to match anything.
        stack = self.traverser.class_name_stack
        if stack:
            name = '%s.%s' % (stack[-1], func)
        else:
            name = func
        for pattern in self.def_patterns:
            found, s = pattern.match(name)
            if found:
                if trace: g.trace('%s: %s -&gt; %s' % (pattern.find_s, name, s))
                return s</t>
<t tx="ekr.20160209063927.1">@language rest
@wrap

All future maintainers of this code should study this posting carefully. It contains the highest-possible view of this script, and the most practically useful view. This post will be pre-writing for part of the theory of operation.

I mentioned in the previous thread that an Aha showed me that code was more complete than I had thought.  There, I described the Aha this way:

    All StubTraverser visitors must return strings.  Lists are not allowed.
    This was a true Aha, despite the fact that they have always only ever returned strings!

Why is this surprising?

Well, in fact, one would naively expect that the visitors for BoolOp and IfExp (ternary operator) should return lists of possible types. It seems natural to return the list [hint(a), hint(b)] in the following examples:

    a and b
    a if c else b
   
However, a quick look at the StubFormatter visitors (and especially the visitors of the base AstFormatter class!) shows that returning lists would be clumsy. Allowing visitors to return either lists or strings would be much worse. That would instantly ruin the code--if statements would proliferate like weeds.

The reduce_types top-level function prevents this code explosion.  It takes a list of strings (type hints or python expressions of unknown type) and returns a type hint, which will be Any if any of the strings passed to it have unknown type. But this means that:

    There are no real choices in the code!

1. The syntax and semantics of type hints (Pep 484 and the typing module) pre-determine the output of reduce_types.

2. The format of type stubs, including explanatory comments produced by --verbose, pre-determines the output of StubTraverser.visit_FunctionDef. In fact, this method ends up calling (via helpers) reduce_types for all return statements in the visited function. Again, there are no alternatives.

3. Because StubFormatter visitors must return strings, all StubFormatter visitors remain quite similar to the (very simple!) visitors in the base AstFormatter class.  The only differences from the base class are additional code that:

A. Apply user-defined patterns to the visitors return string:

    s = self.match_all(node, s)

B. Trace the results of the visitor:

    self.trace_visitor(node, op, s)

C. Apply hard-coded patterns. Most such patterns will be in StubFormatter.do_BinOp. Such code is easy!

In retrospect, this lack of choice is what has kept the code simple, in spite of so much initial confusion. Heh, you could call it the invisible hand :-) Seriously, having no choice really does prevent bad choices.

Imo, this is the proper way to understand the script. It is actually *very* simple.</t>
<t tx="ekr.20160209103842.1"></t>
<t tx="ekr.20160209104843.1">
def trace_stubs(self, stub, aList=None, header=None, level=-1):
    '''Return a trace of the given stub and all its descendants.'''
    indent = ' '*4*max(0,level)
    if level == -1:
        aList = ['===== %s...\n' % (header) if header else '']
    if level &gt; -1:
        aList.append('%s%s %s' % (indent, stub.kind, stub.name))
    for s in stub.out_list:
        aList.append('%s%s' % (indent, s.rstrip()))
    for child in stub.children:
        self.trace_stubs(child, level=level+1, aList=aList)
    if level == -1:
        return '\n'.join(aList) + '\n'
</t>
<t tx="ekr.20160209105448.1">
def output_time_stamp(self):
    '''Put a time-stamp in the output file.'''
    if self.output_file:
        self.output_file.write('# make_stub_files: %s\n' %
            time.strftime("%a %d %b %Y at %H:%M:%S"))
</t>
<t tx="ekr.20160209194832.1">
def add_stub(self, d, stub):
    '''Add the stub to d, checking that it does not exist.'''
    trace = False ; verbose = False
    key = stub.full_name
    assert key
    if key in d:
        caller = g.callers(2).split(',')[1]
        g.trace('Ignoring duplicate entry for %s in %s' % (stub, caller))
    else:
        d [key] = stub
        if trace and verbose:
            caller = g.callers(2).split(',')[1]
            g.trace('%17s %s' % (caller, stub.full_name))
        elif trace:
            g.trace(stub.full_name)</t>
<t tx="ekr.20160210041431.1">
def merge_stubs(self, new_stubs, old_root):
    '''
    Merge the new_stubs *list* into the old_root *tree*.
    - new_stubs is a list of Stubs from the .py file.
    - old_root is the root of the tree of Stubs from the .pyi file.
    '''
    # Remove all new stubs that exist in the old tree.
    aList = [z for z in new_stubs if not self.find_stub(z, old_root)]
    # Order the new stubs so that parents are created before children.
    aList = self.sort_stubs_by_hierarchy(aList)
    for stub in aList:
        g.trace('***** inserting', stub)
        parent = self.find_parent_stub(stub, old_root) or old_root
        parent.children.append(stub)
        assert self.find_stub(stub, old_root), stub</t>
<t tx="ekr.20160210043910.1">
def find_parent_stub(self, stub, root):
    '''Return stub's parent **in root's tree**.'''
    return self.find_stub(stub.parent, root) if stub.parent else None
</t>
<t tx="ekr.20160210043933.1">
def find_stub(self, stub, root):
    '''Return the stub **in root's tree** that matches stub.'''
    if stub == root: # Must use Stub.__eq__!
        return root # not stub!
    for child in root.children:
        stub2 = self.find_stub(stub, child)
        if stub2: return stub2
    return None
</t>
<t tx="ekr.20160210043957.1">
def sort_stubs_by_hierarchy(self, stubs1):
    '''
    Sort the list of Stubs so that parents appear before all their
    descendants.
    '''
    stubs, result = stubs1[:], []
    for i in range(50):
        if stubs:
            # Add all stubs with i parents to the results.
            found = [z for z in stubs if z.level() == i]
            result.extend(found)
            for z in found:
                stubs.remove(z)
        else:
            return result
    g.trace('can not happen: unbounded stub levels.')
    return [] # Abort the merge.
</t>
<t tx="ekr.20160210080720.1">'''Test framework for st.update and helpers.'''
# To do:
# - Test between-stub lines and leading lines.
# - Round-trip tests!
&lt;&lt; imports &gt;&gt;
&lt;&lt; old_stubs &gt;&gt;
&lt;&lt; new_stubs &gt;&gt;
@others
leo_g = g # needed only to adjust for Leo's indentation.
g = LeoGlobals() # Use the g available to the script.
# g.cls()
st = StubTraverser(controller=g.NullObject())
old_s = leo_g.adjustTripleString(old_s, tab_width=-4)
new_s = leo_g.adjustTripleString(new_s, tab_width=-4)
# dump('old_s', old_s)
# dump('new_s', new_s)
old_d, old_stubs = st.parse_stub_file(old_s, root_name='&lt;old-root&gt;')
new_d, new_stubs = st.parse_stub_file(new_s, root_name='&lt;new-root&gt;')
if 0:
    dump_dict(old_d, 'old_d')
    dump_dict(new_d, 'new_d')
    print(st.trace_stubs(old_stubs, header='trace_stubs(old_stubs)'))
    print(st.trace_stubs(new_stubs, header='trace_stubs(new_stubs)'))
if 0: # separate unit test. Passed.
    aList = st.sort_stubs_by_hierarchy(new_stubs)
    dump_list(aList, 'after sort_stubs_by_hierarcy')
new_stubs = new_d.values()
st.merge_stubs(new_stubs, old_stubs)
if 0:
    print(st.trace_stubs(old_stubs, header='trace_stubs(old_stubs)'))
</t>
<t tx="ekr.20160210081628.1"># def is_known_type(s: str) -&gt; Union[Any,bool]: ...
# def reduce_numbers(aList: List[Any]) -&gt; List[Any]: ...
# class AstFormatter:
    # def format(self, node: Node) -&gt; Union[Any,str]: ...
    # def visit(self, node: Node) -&gt; str: ...
    # def do_ClassDef(self, node: Node) -&gt; str: ...
    # def do_FunctionDef(self, node: Node) -&gt; str: ...
old_s = '''\
def main() -&gt; None: ...
def merge_types(a1: Any, a2: Any) -&gt; str: ...
def pdb(self) -&gt; None: ...
def reduce_types(aList: List[Any], name: str=None, trace: bool=False) -&gt; Any: ...
'''
</t>
<t tx="ekr.20160210082857.1"></t>
<t tx="ekr.20160210083825.1">
def dump(title, s=None):
    if s:
        print('===== %s...\n%s\n' % (title, s.rstrip()))
    else:
        print('===== %s...\n' % title)
</t>
<t tx="ekr.20160210111955.1">
def __repr__(self):
    '''Stub.__repr__.'''
    return 'Stub: %s %s' % (id(self), self.full_name)
    
def __str__(self):
    '''Stub.__repr__.'''
    return 'Stub: %s' % self.full_name
</t>
<t tx="ekr.20160210112634.1"></t>
<t tx="ekr.20160210112711.1">Later: improve type reduction:
- 2-pass reduce_types? More tests that patterns work in expected places.
- Merge Tuple and List interiors in reduce_types.
- Add more binop patterns.

</t>
<t tx="ekr.20160210112727.1">* When complete, fold this script back into Leo.
    Put make_stub_files.py in leo/external folder!

* Use this script on more Leo files.

** How to show git diffs involving Leo files?</t>
<t tx="ekr.20160210112748.1">--update announcement: take precausions: it's more dangerous.

*** Task oriented docs **after** --update.

- Post: how to run unit tests.

- Post: Rough edges re number types. Is reduce_numbers correct?

- Post: study this script with Leo.

- Post: thanks!
        
Update readme file with examples of return comments.
- With and without --verbose.
- The script is useful even without patterns.</t>
<t tx="ekr.20160210112945.1">&lt;&lt; imports &gt;&gt;
@others
g = LeoGlobals() # Use the g available to the script.
# g.cls()
# Test equality...
stub1 = Stub(kind='def', name='foo')
stub2 = Stub(kind='class', name='foo')
stub3 = Stub(kind='def', name='bar')
stub4 = Stub(kind='def', name='foo')
stub4.out_list = ['xyzzy']
    # Contents of out_list must not affect equality!
aList = [stub1, stub3]
assert stub1 != stub2
assert stub1 != stub3
assert stub1 == stub4
assert stub1 in aList
assert stub2 not in aList
assert stub3 in aList
# Test __hash__
d = {stub1: 'stub1'}
assert stub1 in d
assert stub2 not in d
# Test parents and level.
stub_1 = Stub(kind='def', name='stub_1')
stub_2 = Stub(kind='def', name='stub_2', parent=stub_1, stack=['stub_1'])
stub_3 = Stub(kind='def', name='stub_3', parent=stub_2, stack=['stub_1', 'stub_2'])
assert stub_1.parents() == [], stub_1.parents()
assert stub_2.parents() == ['stub_1'], stub_2.parents()
assert stub_3.parents() == ['stub_1', 'stub_2'], stub_3.parents()
assert stub_1.level() == 0
assert stub_2.level() == 1
assert stub_3.level() == 2
</t>
<t tx="ekr.20160210132520.1">
def level(self):
    '''Return the number of parents.'''
    return len(self.parents())
    
def parents(self):
    '''Return a list of this stub's parents.'''
    return self.full_name.split('.')[:-1]
</t>
<t tx="ekr.20160210134702.1">
def __init__(self, kind, name, parent=None, stack=None):
    '''Stub ctor. Equality depends only on full_name and kind.'''
    self.children = []
    self.full_name = '%s.%s' % ('.'.join(stack), name) if stack else name
    self.kind = kind
    self.name = name
    self.out_list = []
    self.parent = parent
    self.stack = stack # StubTraverser.context_stack.
    if stack:
        assert stack[-1] == parent.name, (stack[-1], parent.name)
    if parent:
        assert isinstance(parent, Stub)
        parent.children.append(self)
</t>
<t tx="ekr.20160210141342.1">
def dump_dict(d, tag):
    '''Dump a dictionary with a header.'''
    dump(tag)
    for z in sorted(d):
        print('%30s %s' % (z, d.get(z)))
    print('')</t>
<t tx="ekr.20160210141651.1">
def dump_list(aList, tag):
    '''Dump a list with a header.'''
    dump(tag)
    for z in aList:
        print(z)
    print('')
</t>
<t tx="ekr.20160210143802.1">
class NullObject:
    """
    An object that does nothing, and does it very well.
    From the Python cookbook, recipe 5.23
    """
    def __init__(self, *args, **keys): pass
    def __call__(self, *args, **keys): return self
    def __repr__(self): return "NullObject"
    def __str__(self): return "NullObject"
    def __bool__(self): return False
    def __nonzero__(self): return 0
    def __delattr__(self, attr): return self
    def __getattr__(self, attr): return self
    def __setattr__(self, attr, val): return self
</t>
<t tx="ekr.20160210144515.1">new_s = '''\
def is_known_type(s: str) -&gt; Union[Any,bool]: ...
def main() -&gt; None: ...
def merge_types(a1: Any, a2: Any) -&gt; str: ...
def pdb(self) -&gt; None: ...
def reduce_numbers(aList: List[Any]) -&gt; List[Any]: ...
def reduce_types(aList: List[Any], name: str=None, trace: bool=False) -&gt; Any: ...

class AstFormatter:
    def format(self, node: Node) -&gt; Union[Any,str]: ...
    def visit(self, node: Node) -&gt; str: ...
    def do_ClassDef(self, node: Node) -&gt; str: ...
    def do_FunctionDef(self, node: Node) -&gt; str: ...
'''</t>
<t tx="ekr.20160210145128.1">&lt;&lt; imports &gt;&gt;
&lt;&lt; define s &gt;&gt;
@others
leo_g = g # needed only to adjust for Leo's indentation.
g = LeoGlobals() # Use the g available to the script.
# g.cls()
st = StubTraverser(controller=g.NullObject())
s = leo_g.adjustTripleString(s, tab_width=-4)
d, root = st.parse_stub_file(s, root_name='&lt;root&gt;')
print(st.trace_stubs(root, header='root'))
stub1 = Stub(kind='class', name='AstFormatter')
stub2 = Stub(kind='def', name='format', parent=stub1, stack=['AstFormatter'])
stub3 = Stub(kind='def', name='helper', parent = stub2, stack=['AstFormatter', 'format'])
# stub4 = Stub(kind='def', name='main')
for stub in (stub1, stub2, stub3,): # (stub1, stub2, stub3):
    found = st.find_stub(stub, root)
    id_found = found and id(found) or None
    print('found  %s =&gt; %9s %35s ==&gt; %s' % (id(stub), id_found, stub, found))
    found = st.find_parent_stub(stub, root)
    id_found = found and id(found) or None
    print('parent %s =&gt; %9s %35s ==&gt; %s' % (id(stub), id_found, stub, found))</t>
<t tx="ekr.20160210164250.1">s = '''\
def is_known_type(s: str) -&gt; Union[Any,bool]: ...
def main() -&gt; None: ...
def merge_types(a1: Any, a2: Any) -&gt; str: ...

class AstFormatter:
    def format(self, node: Node) -&gt; Union[Any,str]: ...
        def helper(self): -&gt; None
    def visit(self, node: Node) -&gt; str: ...
    def do_ClassDef(self, node: Node) -&gt; str: ...
    def do_FunctionDef(self, node: Node) -&gt; str: ...
'''</t>
<t tx="ekr.20160210184122.1">
def reduce_types(aList, name=None, newlines=False, trace=False):
    '''
    Return a string containing the reduction of all types in aList.
    The --trace-reduce command-line option sets trace=True.
    If present, name is the function name or class_name.method_name.
    '''
    trace = False or trace
    aList1 = aList[:]
    &lt;&lt; define show &gt;&gt;

    while None in aList:
        aList.remove(None)
    if not aList:
        return show('None')
    r = sorted(set(aList))
    if not all([is_known_type(z) for z in r]):
        return show('Any', known=False)
    elif len(r) == 1:
        return show(r[0])
    if 'None' in r:
        kind = 'Optional'
        while 'None' in r:
            r.remove('None')
        return show('Optional[%s]' % r[0])
    r = reduce_numbers(r)
    if len(r) == 1:
        return show(r[0])
    elif newlines:
        return show('Union[\n    %s,\n]' % (',\n    '.join(sorted(r))))
    else:
        return show('Union[%s]' % (', '.join(sorted(r))))
</t>
<t tx="ekr.20160210184122.2">
def show(s, known=True):
    '''Show the result of the reduction.'''
    s = s.strip()
    # s2 = s.replace('\n','').replace(' ','').replace(',]',']').strip()
    s2 = s.replace('\n',' ').replace(',]',']').strip()
        # Undo newline option if possible.
    if trace:
        r = sorted(set([z.replace('\n',' ') for z in aList1]))
        if len(''.join(r)) &gt;= 35:
            r = truncate(repr(r), 35)
        if len(s2) &gt;= 25:
            s2 = truncate(s2, 25)
        if len(r) &gt; 1:
            sep = ' ' if known else '?'
            if 1:
                caller = g.callers(2).split(',')[0]
                g.trace('%20s %25s %s &lt;== %-35s %s' % (name or '', s2, sep, r, caller))
            else:
                g.trace('%20s %25s %s &lt;== %s' % (name or '', s2, sep, r))
    return s2 if len(s2) &lt; 25 else s</t>
<t tx="ekr.20160210190143.1">def merge_stubs(self, new_stubs, old_stubs):
    '''
    Merge the new_stubs *list* into the old_stubs *tree*.
    - new_stubs is a list of Stubs from the .py file.
    - old_stubs is the root of the tree of Stubs from the .pyi file.
    '''
    # Order the new stubs so that parents are created before children.
    aList = self.sort_stubs_by_hierarchy(new_stubs)
    for stub in aList:
        # Initially, stub must not exist in the tree.
        # assert not self.find_stub(stub, old_stubs), stub
        parent = self.find_parent_stub(stub, old_stubs)
        assert parent, stub
        parent.children.append(stub)
        # Now stub must exist in the tree.
        assert self.find_stub(self, old_stubs), stub
</t>
<t tx="ekr.20160210193834.1"></t>
</tnodes>
</leo_file>
